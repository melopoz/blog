<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/Elasticsearch/"/>
    <url>/blog/2021/03/22/Elasticsearch/</url>
    
    <content type="html"><![CDATA[<p>ELK</p><p>elasticsearch + Logstash + Kibana</p><p>在加上kafka更好</p><p>Elasticsearch基于Lucene</p><p>下载elasticsearch并安装 port9200</p><p>下载head (Node.js) port9100</p><p>config中配置跨域</p><pre><code class="hljs yaml"><span class="hljs-attr">http.cors.enable:</span> <span class="hljs-literal">true</span><span class="hljs-attr">http.cors.allow-origin:</span> <span class="hljs-string">&quot;*&quot;</span></code></pre><p>Kibana下载 要和Elasticsearch的版本一致  可以汉化</p><p>使用了Lucene倒排索引</p><p>分片就是倒排索引</p><p>下载ik分词器</p><p>在kibana中使用rest请求</p><pre><code class="hljs json">GET _analyze&#123;  <span class="hljs-attr">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;ik_smart&quot;</span>,  <span class="hljs-attr">&quot;text&quot;</span>: <span class="hljs-string">&quot;java大数据行业&quot;</span>&#125;GET _analyze&#123;  <span class="hljs-attr">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;ik_max_word&quot;</span>,  <span class="hljs-attr">&quot;text&quot;</span>: <span class="hljs-string">&quot;java大数据行业&quot;</span>&#125;GET _analyze&#123;  <span class="hljs-attr">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;standard&quot;</span>,  <span class="hljs-attr">&quot;text&quot;</span>: <span class="hljs-string">&quot;↑这个是标准的分词器&quot;</span>&#125;GET _analyze&#123;  <span class="hljs-attr">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;keyword&quot;</span>,  <span class="hljs-attr">&quot;text&quot;</span>: <span class="hljs-string">&quot;这个不会拆分text&quot;</span>&#125;</code></pre><p>字典中没有的词需要自己加入到字典中， 在ik中增加自己的配置，新增.dic文件</p><p>字段如果是keyword类型，就不会被分词器拆分，如果是text才可以</p><p>version 0-6 一个索引下有可以有多个type</p><p>version 7     一个索引下只有一个type</p><p>version 8      索引下直接使用documentId，没有type</p><ul><li>查看所有索引 GET /_cat/indices</li><li>查看集群是否健康 GET /_cat/health</li><li>查看集群节点 GET /_cat/nodes</li></ul><h3 id="CRUD"><a href="#CRUD" class="headerlink" title="CRUD"></a>CRUD</h3><ol><li><p>创建一个库  创建规则</p><pre><code class="hljs json">PUT /索引名&#123;  <span class="hljs-attr">&quot;mappings&quot;</span>: &#123;    <span class="hljs-attr">&quot;properties&quot;</span>: &#123;      <span class="hljs-attr">&quot;name&quot;</span>: &#123;        <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>      &#125;,      <span class="hljs-attr">&quot;height&quot;</span>: &#123;        <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-string">&quot;double&quot;</span>      &#125;,      <span class="hljs-attr">&quot;birthday&quot;</span>: &#123;        <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-string">&quot;date&quot;</span>      &#125;    &#125;  &#125;&#125;</code></pre></li><li><p>查看索引下所有数据</p><pre><code class="hljs json">GET /team/_search?pretty<span class="hljs-comment">// _doc</span><span class="hljs-comment">// _search</span><span class="hljs-comment">// _mapping...</span>结果&#123;  <span class="hljs-attr">&quot;took&quot;</span> : <span class="hljs-number">0</span>,  <span class="hljs-attr">&quot;timed_out&quot;</span> : <span class="hljs-literal">false</span>,<span class="hljs-comment">// 超时</span>  <span class="hljs-attr">&quot;_shards&quot;</span> : &#123;<span class="hljs-comment">//分区信息</span>    <span class="hljs-attr">&quot;total&quot;</span> : <span class="hljs-number">1</span>,    <span class="hljs-attr">&quot;successful&quot;</span> : <span class="hljs-number">1</span>,    <span class="hljs-attr">&quot;skipped&quot;</span> : <span class="hljs-number">0</span>,    <span class="hljs-attr">&quot;failed&quot;</span> : <span class="hljs-number">0</span>  &#125;,  <span class="hljs-attr">&quot;hits&quot;</span> : &#123;    <span class="hljs-attr">&quot;total&quot;</span> : &#123;      <span class="hljs-attr">&quot;value&quot;</span> : <span class="hljs-number">3</span>,      <span class="hljs-attr">&quot;relation&quot;</span> : <span class="hljs-string">&quot;eq&quot;</span>    &#125;,    <span class="hljs-attr">&quot;max_score&quot;</span> : <span class="hljs-number">1.0</span>,    <span class="hljs-attr">&quot;hits&quot;</span> : [ <span class="hljs-comment">// 全部数据</span>      &#123;        <span class="hljs-attr">&quot;_index&quot;</span> : <span class="hljs-string">&quot;team&quot;</span>,<span class="hljs-comment">//索引</span>        <span class="hljs-attr">&quot;_type&quot;</span> : <span class="hljs-string">&quot;_doc&quot;</span>,        <span class="hljs-attr">&quot;_id&quot;</span> : <span class="hljs-string">&quot;1&quot;</span>,        <span class="hljs-attr">&quot;_score&quot;</span> : <span class="hljs-number">1.0</span>,<span class="hljs-comment">//分值</span>        <span class="hljs-attr">&quot;_source&quot;</span> : &#123;<span class="hljs-comment">//source数据</span>          <span class="hljs-attr">&quot;name&quot;</span> : <span class="hljs-string">&quot;Thunders&quot;</span>,          <span class="hljs-attr">&quot;area&quot;</span> : <span class="hljs-string">&quot;north-west&quot;</span>,          <span class="hljs-attr">&quot;address&quot;</span> : <span class="hljs-string">&quot;Oklahoma City&quot;</span>,          <span class="hljs-attr">&quot;Coach&quot;</span> : <span class="hljs-string">&quot;Mitchell Donovan&quot;</span>        &#125;      &#125;,      &#123;        <span class="hljs-attr">&quot;_index&quot;</span> : <span class="hljs-string">&quot;team&quot;</span>,        <span class="hljs-attr">&quot;_type&quot;</span> : <span class="hljs-string">&quot;_doc&quot;</span>,        <span class="hljs-attr">&quot;_id&quot;</span> : <span class="hljs-string">&quot;2&quot;</span>,        <span class="hljs-attr">&quot;_score&quot;</span> : <span class="hljs-number">1.0</span>,        <span class="hljs-attr">&quot;_source&quot;</span> : &#123;          <span class="hljs-attr">&quot;name&quot;</span> : <span class="hljs-string">&quot;Warriors&quot;</span>,          <span class="hljs-attr">&quot;area&quot;</span> : <span class="hljs-string">&quot;north-west&quot;</span>,          <span class="hljs-attr">&quot;address&quot;</span> : <span class="hljs-string">&quot;Golden State&quot;</span>,          <span class="hljs-attr">&quot;Coach&quot;</span> : <span class="hljs-string">&quot;Steve Kerr&quot;</span>        &#125;      &#125;,      &#123;        <span class="hljs-attr">&quot;_index&quot;</span> : <span class="hljs-string">&quot;team&quot;</span>,        <span class="hljs-attr">&quot;_type&quot;</span> : <span class="hljs-string">&quot;_doc&quot;</span>,        <span class="hljs-attr">&quot;_id&quot;</span> : <span class="hljs-string">&quot;3&quot;</span>,        <span class="hljs-attr">&quot;_score&quot;</span> : <span class="hljs-number">1.0</span>,        <span class="hljs-attr">&quot;_source&quot;</span> : &#123;          <span class="hljs-attr">&quot;name&quot;</span> : <span class="hljs-string">&quot;Clippers&quot;</span>,          <span class="hljs-attr">&quot;area&quot;</span> : <span class="hljs-string">&quot;north-west&quot;</span>,          <span class="hljs-attr">&quot;address&quot;</span> : <span class="hljs-string">&quot;Los Angeles&quot;</span>,          <span class="hljs-attr">&quot;Coach&quot;</span> : <span class="hljs-string">&quot;Doc Rivers&quot;</span>        &#125;      &#125;    ]  &#125;&#125;</code></pre></li><li><p>增加一条索引</p><pre><code class="hljs json">PUT /索引名/type名/id&#123;  <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;melopoz&quot;</span>,  <span class="hljs-attr">&quot;height&quot;</span>: <span class="hljs-string">&quot;190&quot;</span>&#125;</code></pre></li><li><p>修改一条索引  每次version会+1</p><pre><code class="hljs json"><span class="hljs-comment">//如果缺少字段，更新之后就会丢失</span>PUT /索引/type/id&#123;  <span class="hljs-attr">&quot;doc&quot;</span>: &#123;    <span class="hljs-attr">&quot;feildName&quot;</span>: <span class="hljs-string">&quot;newValue&quot;</span>     &#125;&#125;<span class="hljs-comment">//不会丢失字段 在id后加update。</span>POST /索引/type/id/_update&#123;  <span class="hljs-attr">&quot;doc&quot;</span>: &#123;    <span class="hljs-attr">&quot;feildName&quot;</span>: <span class="hljs-string">&quot;newValue&quot;</span>  &#125;&#125;</code></pre></li><li><p>删除  DELETE</p></li></ol><h3 id="复杂查询"><a href="#复杂查询" class="headerlink" title="复杂查询"></a>复杂查询</h3><ul><li>match 使用分词器解析</li></ul><pre><code class="hljs json">GET /../../..&#123;  <span class="hljs-attr">&quot;query&quot;</span>: &#123;    <span class="hljs-attr">&quot;match&quot;</span>: &#123;      <span class="hljs-attr">&quot;字段名&quot;</span>: <span class="hljs-string">&quot;值&quot;</span>,      ...    &#125;  &#125;,  <span class="hljs-comment">//字段过滤</span>  &quot;_source&quot;: [&quot;name&quot;, &quot;height&quot;],   <span class="hljs-comment">//排序 多种写法</span>  &quot;sort&quot;: [    &#123;      <span class="hljs-attr">&quot;height&quot;</span>: <span class="hljs-string">&quot;asc&quot;</span>    &#125;,&#123;&#125;  ]  <span class="hljs-comment">//分页</span>  &quot;from&quot;: 0,  &quot;size&quot;: 20&#125;</code></pre><ul><li>boolean查询</li></ul><pre><code class="hljs json">GET /../../..&#123;  <span class="hljs-attr">&quot;query&quot;</span>: &#123;    <span class="hljs-attr">&quot;bool&quot;</span>: &#123;      <span class="hljs-attr">&quot;must&quot;</span>: [<span class="hljs-comment">//should(or) must(and) must_not(!=)</span>        &#123;          <span class="hljs-attr">&quot;match&quot;</span>: &#123;            <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;melopoz&quot;</span>          &#125;        &#125;,&#123;          <span class="hljs-attr">&quot;match&quot;</span>: &#123;            <span class="hljs-attr">&quot;height&quot;</span>: <span class="hljs-number">190</span>          &#125;        &#125;      ],      <span class="hljs-attr">&quot;filter&quot;</span>: &#123;        <span class="hljs-attr">&quot;range&quot;</span>: &#123;          <span class="hljs-attr">&quot;height&quot;</span>: &#123;            <span class="hljs-attr">&quot;gt&quot;</span>: <span class="hljs-number">185</span> <span class="hljs-comment">//gt gte lt lte</span>          &#125;        &#125;      &#125;    &#125;  &#125;&#125;</code></pre><ul><li>term 直接精确查询 若果存储的value首字母大写了，查询时的参数首字母也要小写。因为分词器分析出的都是小写。 standard</li></ul><pre><code class="hljs json">GET /../../..&#123;  <span class="hljs-attr">&quot;query&quot;</span>: &#123;    <span class="hljs-attr">&quot;term&quot;</span>: &#123;      <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;melopoz&quot;</span> <span class="hljs-comment">//如果name字段的type为keyword，有name=melopoz2的数据，也不会被查询到</span>    &#125;  &#125;&#125;</code></pre><ul><li>高亮查询</li></ul><pre><code class="hljs awk">GET <span class="hljs-regexp">/../</span>../..&#123;  <span class="hljs-string">&quot;query&quot;</span>: &#123;    <span class="hljs-string">&quot;match&quot;</span>: &#123;      <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;melopoz&quot;</span>    &#125;  &#125;,  <span class="hljs-string">&quot;highlight&quot;</span>: &#123;    <span class="hljs-string">&quot;pre_tags&quot;</span>: <span class="hljs-string">&quot;&lt;hl class=&quot;</span>highlight_word<span class="hljs-string">&quot;&gt;&quot;</span>    <span class="hljs-string">&quot;post_tags&quot;</span>: <span class="hljs-string">&quot;&lt;/h1&gt;&quot;</span>    <span class="hljs-string">&quot;name&quot;</span>:&#123;&#125;  &#125;&#125;</code></pre><h3 id="聚合索引"><a href="#聚合索引" class="headerlink" title="聚合索引"></a>聚合索引</h3><pre><code class="hljs awk"><span class="hljs-regexp">//</span>查询<span class="hljs-number">20</span>-<span class="hljs-number">30</span>,<span class="hljs-number">0</span>-<span class="hljs-number">40</span>,<span class="hljs-number">40</span>-<span class="hljs-number">50</span>这三个年龄段分别有多少人GET /..&#123;  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-regexp">//</span> size=<span class="hljs-number">0</span>则不显示数据只显示聚合结果，每个阶段的人数  <span class="hljs-string">&quot;user&quot;</span>: &#123;    <span class="hljs-string">&quot;age&quot;</span>: &#123;      <span class="hljs-string">&quot;range&quot;</span>: &#123;        <span class="hljs-string">&quot;field&quot;</span>: <span class="hljs-string">&quot;age&quot;</span>,        <span class="hljs-string">&quot;ranges&quot;</span>: [          &#123;            <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-number">20</span>,            <span class="hljs-string">&quot;to&quot;</span>: <span class="hljs-number">30</span>          &#125;,&#123;            <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-number">30</span>,            <span class="hljs-string">&quot;to&quot;</span>: <span class="hljs-number">40</span>          &#125;,&#123;            <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-number">40</span>,            <span class="hljs-string">&quot;to&quot;</span>: <span class="hljs-number">50</span>          &#125;        ]      &#125;    &#125;  &#125;&#125;</code></pre><h3 id="tokenizer分词器"><a href="#tokenizer分词器" class="headerlink" title="tokenizer分词器"></a>tokenizer分词器</h3><ul><li>keyword分词器</li></ul><pre><code class="hljs json">GET /kibana_sample_data_ecommerce/_analyze&#123;  <span class="hljs-attr">&quot;text&quot;</span>: [<span class="hljs-string">&quot;Happy Birthday&quot;</span>],  <span class="hljs-attr">&quot;tokenizer&quot;</span>: <span class="hljs-string">&quot;keyword&quot;</span>&#125;结果：&#123;  <span class="hljs-attr">&quot;tokens&quot;</span> : [    &#123;      <span class="hljs-attr">&quot;token&quot;</span> : <span class="hljs-string">&quot;Happy Birthday&quot;</span>,      <span class="hljs-attr">&quot;start_offset&quot;</span> : <span class="hljs-number">0</span>,      <span class="hljs-attr">&quot;end_offset&quot;</span> : <span class="hljs-number">14</span>,      <span class="hljs-attr">&quot;type&quot;</span> : <span class="hljs-string">&quot;word&quot;</span>,      <span class="hljs-attr">&quot;position&quot;</span> : <span class="hljs-number">0</span>    &#125;  ]&#125;</code></pre><ul><li>standard标准分词器</li></ul><pre><code class="hljs awk">GET <span class="hljs-regexp">/kibana_sample_data_ecommerce/</span>_analyze&#123;  <span class="hljs-string">&quot;text&quot;</span>: [<span class="hljs-string">&quot;Happy Birthday&quot;</span>],  <span class="hljs-string">&quot;tokenizer&quot;</span>: <span class="hljs-string">&quot;standard&quot;</span>, <span class="hljs-regexp">//</span>使用standard  标准分词器  <span class="hljs-string">&quot;filter&quot;</span>: [<span class="hljs-string">&quot;lowercase&quot;</span>] <span class="hljs-regexp">//</span>转换为小写&#125;结果：&#123;  <span class="hljs-string">&quot;tokens&quot;</span> : [    &#123;      <span class="hljs-string">&quot;token&quot;</span> : <span class="hljs-string">&quot;happy&quot;</span>,      <span class="hljs-string">&quot;start_offset&quot;</span> : <span class="hljs-number">0</span>,      <span class="hljs-string">&quot;end_offset&quot;</span> : <span class="hljs-number">5</span>,      <span class="hljs-string">&quot;type&quot;</span> : <span class="hljs-string">&quot;&lt;ALPHANUM&gt;&quot;</span>,      <span class="hljs-string">&quot;position&quot;</span> : <span class="hljs-number">0</span>    &#125;,    &#123;      <span class="hljs-string">&quot;token&quot;</span> : <span class="hljs-string">&quot;birthday&quot;</span>,      <span class="hljs-string">&quot;start_offset&quot;</span> : <span class="hljs-number">6</span>,      <span class="hljs-string">&quot;end_offset&quot;</span> : <span class="hljs-number">14</span>,      <span class="hljs-string">&quot;type&quot;</span> : <span class="hljs-string">&quot;&lt;ALPHANUM&gt;&quot;</span>,      <span class="hljs-string">&quot;position&quot;</span> : <span class="hljs-number">1</span>    &#125;  ]&#125;</code></pre><h3 id="Spring-Data-Elasticsearch"><a href="#Spring-Data-Elasticsearch" class="headerlink" title="Spring Data Elasticsearch"></a>Spring Data Elasticsearch</h3><p>​    可以使用RestClient(RestHighLevelClient)、Jest、SpringDataElasticsearch</p><h4 id="RestHighLevelClient"><a href="#RestHighLevelClient" class="headerlink" title="RestHighLevelClient"></a>RestHighLevelClient</h4><p>_My Project.spring-elasticsearch</p><h4 id="Jest"><a href="#Jest" class="headerlink" title="Jest"></a>Jest</h4><p>引入依赖 （就不需要再引入elasticsearch的依赖了）</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/io.searchbox/jest --&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>io.searchbox<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jest<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>6.3.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><p>直接注入bean，不需要自己配置bean</p><pre><code class="hljs java"><span class="hljs-meta">@Autowired</span>JestClient jestClient;</code></pre><p>添加索引</p><pre><code class="hljs java"><span class="hljs-keyword">import</span> io.searchbox.core.Index;</code></pre><pre><code class="hljs java">Player player = <span class="hljs-keyword">new</span> Player(...);Index index = <span class="hljs-keyword">new</span> Index.Builder(player).index(<span class="hljs-string">&quot;索引&quot;</span>).type(<span class="hljs-string">&quot;类型&quot;</span>).build();<span class="hljs-keyword">try</span>&#123;jestClient.execute(index);&#125;<span class="hljs-keyword">catch</span> (IOException e)&#123;e.printStackTrace();&#125;</code></pre><p>…</p><h4 id="SpringDataElasticsearch"><a href="#SpringDataElasticsearch" class="headerlink" title="SpringDataElasticsearch"></a>SpringDataElasticsearch</h4><p>依赖</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-data-elasticsearch<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><span class="hljs-comment">&lt;!--需要使用json--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.google.code.gson<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>gson<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.8.5<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><p>实体类</p><pre><code class="hljs java"><span class="hljs-meta">@Document(indexName=&quot;nba&quot;, type=&quot;player&quot;)</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Player</span></span>&#123;...&#125;</code></pre><p>repository接口</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">PlayerRepo</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ElasticsearchRepository</span>&lt;<span class="hljs-title">Player</span>, <span class="hljs-title">Integer</span>&gt;</span>&#123;&#125;</code></pre><p>注入bean即可使用</p><pre><code class="hljs java"><span class="hljs-meta">@Autowired</span>PlayerRepo playerRepo;</code></pre><p>添加索引</p><pre><code class="hljs java">playerRepo.index(<span class="hljs-keyword">new</span> Player(...));</code></pre><p>使用接口的方法即可</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/HDFS/"/>
    <url>/blog/2021/03/22/HDFS/</url>
    
    <content type="html"><![CDATA[<p>目录树结构</p><p>角色namenode datanode 角色即进程</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><h4 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h4><p>基于内存存储文件元数据、目录结构、文件block的映射</p><p>需要持久化方案提供数据可靠性</p><p>提供副本放置策略</p><h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><p>基于本地磁盘存储block（块）（以文件形式）</p><p>保存block的校验和数据 保证block的可靠性</p><p>和NameNode保持心跳，汇报block的列表状态</p><h3 id="数据恢复策略："><a href="#数据恢复策略：" class="headerlink" title="数据恢复策略："></a>数据恢复策略：</h3><ul><li><p>日志文件(记录所有操作，恢复时重新执行一遍)</p><blockquote><p>恢复慢 数据全</p></blockquote></li><li><p>镜像 快照 dump db 序列化</p><blockquote><p>恢复快 数据不全(因为只能间隔一段时间备份一下)</p></blockquote></li></ul><h4 id="HDFS的数据恢复策略："><a href="#HDFS的数据恢复策略：" class="headerlink" title="HDFS的数据恢复策略："></a>HDFS的数据恢复策略：</h4><ul><li>EditsLog  日志</li><li>FsImage  镜像、快照</li></ul><blockquote><p>EditsLog和FsImage存储在本地磁盘</p></blockquote><p>HDFS采用最近时间点的FsImage + 增量的EditsLog</p><blockquote><p>任何修改文件系统元数据的操作，NameNode都会使用EditsLog记录到事务日志</p><p>使用FsImage存储内存中所有元数据状态</p></blockquote><h3 id="Block的副本放置策略"><a href="#Block的副本放置策略" class="headerlink" title="Block的副本放置策略"></a>Block的副本放置策略</h3><p>默认为每个数据块放3个副本，按照部署在NameNode上的默认机架感知策略存放数据副本。</p><ul><li><p>第一个block副本放在上传文件的datanode，如果是集群外上传文件到hdfs，则随机挑选一个磁盘剩余空间大，cpu比较轻松的datanode；</p></li><li><p>第二个block副本放在和第一个副本 不同机架 中的另一个datanode（随机选择）；</p></li><li><p>第三个block副本放在和第二个副本 相同机架 中的节点；</p><blockquote><p>这样就只通过一个交换机(当前机架的交换机)，如果放在其他机架，就要通过更多交换机传输，效率会变低</p></blockquote></li><li><p>第n个block副本放在 随机节点。</p></li></ul><p><img src="images%5Chdfs-%E5%89%AF%E6%9C%AC%E4%BD%8D%E7%BD%AE.pngx" alt="hdfs-副本位置"></p><h3 id="HDFS写流程"><a href="#HDFS写流程" class="headerlink" title="HDFS写流程"></a>HDFS写流程</h3><p><img src="images%5Chdfs-%E5%86%99%E6%B5%81%E7%A8%8B.pngx" alt="hdfs-写流程"></p><blockquote><p>block 块  packet小包(64kb)  chunk大块(512kb)</p><p>写入数据的时候DN以chunk为单位进行数据校验。</p></blockquote><p>想NN请求上传文件，NN返回是否可以上传，client对文件进行切分(比如一个block64M，200M的文件就会分成64 64 64 8)，client向NN请求第一个block应该存储到的DN服务器，NN返回第一个DN服务器，client请求第一个DN(RPC调用，建立pipeline)，client发送第一个packet到DN1，传输完成像DN1发送第二个packet，同时DN1向DN2发送第一个packet… …  以此类推。</p><blockquote><p> 这样就比client发送整个大包到DN1，传输完成DN1发送打包到DN2… 效率要高很多</p></blockquote><p>第一个block传输完成，client再次请求NN上传第二个block</p><h3 id="HDFS读流程"><a href="#HDFS读流程" class="headerlink" title="HDFS读流程"></a>HDFS读流程</h3><ol><li>跟NN通信查询元数据(block所在的DN的节点)，找到文件块所在的DN的服务器。</li><li>挑选一台DN（就近原则，然后随机）服务器，请求建立socket流。</li><li>DN开始发送数据（从磁盘里读取数据放入流，以packet为单位做校验）</li><li>客户端以packet为单位接收，先在本地缓存，然后写入目标文件中，后面的block块就相当于append到前面的block块，最后合成最终需要的文件</li></ol><h4 id="读取某个指定的block"><a href="#读取某个指定的block" class="headerlink" title="读取某个指定的block"></a>读取某个指定的block</h4><p>下载一个文件：（获取文件的所有block元数据）</p><ul><li>client和NN交互文件元数据获取fileBlockLocation</li><li>NN按距离策略排序返回</li><li>client尝试下载block并校验数据完整性</li></ul><p>”下载一个文件“的子集：获取某些block</p><blockquote><p> HDFS支持client给出我文件的offset，自定义连接某个block所在的DN，自定义获取数据.</p><p>这是支持计算层分治、并行计算的核心</p></blockquote>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"/>
    <url>/blog/2021/03/22/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>简单说 IO：读取/写入 若干字节 从/到 <strong>单个文件描述符</strong></p><ul><li><p>阻塞 / 非阻塞</p><ul><li><p>阻塞：如果文件描述符不处于就绪状态则<strong>阻塞直到其就绪</strong></p></li><li><p>非阻塞：如果文件描述符不处于就绪状态则<strong>返回一个错误码</strong>，比如 <code>EAGAIN</code></p></li></ul></li><li><p>同步 / 异步</p><blockquote><p>同步和异步 是指 函数返回之时， 能不能保证任务完成。</p><p>比如调用了read()直接返回了一个Future对象，你需要再调Future的函数来获取read()的结果。</p></blockquote><ul><li>同步 IO 操作将导致请求的进程一直被阻塞，直到 IO 操作完成。从这个层次来，阻塞 IO、非阻塞 IO 操作、IO 多路复用都是同步 IO</li><li>异步 IO 操作不会导致请求的进程被阻塞。当发出 IO 操作请求，直接返回，等待 IO 操作完成后，再通知调用进程。</li></ul></li><li><p>I/O多路复用</p><p>比如Linux的select/poll/epoll，macOS的kqueue</p><p>I/O多路复用是通过一种机制，可以<strong>监视多个fd</strong>，一旦某个fd就绪（读就绪/写就绪），能够通知程序进行相应的读写操作。</p><blockquote><p>通知 也就是线程间的通信了，像future那种也就是通过共享变量喽</p></blockquote></li></ul><h4 id="几种IO多路复用"><a href="#几种IO多路复用" class="headerlink" title="几种IO多路复用"></a>几种IO多路复用</h4><p>阻塞IO 处理一个IO就阻塞，所以一个线程只能处理一个fd，如果想要同时处理多个就得开多个线程， 效率不高消耗还大。</p><p>非阻塞IO 就得轮询所有你关注的fd，查看他们是否准备好了</p><ul><li><p>忙轮询</p><p>无一例外从头到尾闷头轮询，如果长时间没有fd就绪，就相当于一直空轮询了</p></li><li><p>无差别轮询</p><p>让一个代理去轮询，如果没有就绪的事件，就阻塞当前线程，直到关注的fd中有就绪事件，在linux中这个代理就是 select/poll</p><pre><code class="hljs c"><span class="hljs-keyword">while</span> <span class="hljs-literal">true</span> &#123;    select(streams[]) <span class="hljs-comment">// 这里如果没有就绪的时间就阻塞</span>    <span class="hljs-keyword">for</span> i in streams[] &#123;        <span class="hljs-keyword">if</span> i has data            read until unavailable<span class="hljs-comment">//这里处理fd的时候还要注意 是不是已经处理过了 如果read()可能会一直阻塞下去，因为可能已经被其他人处理</span>    &#125;&#125;</code></pre><p>如果streams[]中有就绪的流，就会唤醒当前线程，如果100个stream中只有1个stream就绪了，我们还是要遍历这100个stream，时间复杂度永远是O(n)，处理的流越多，性能就越慢。</p></li><li><p>最小轮询 epoll</p><p>可以比 无差别轮询 监听更多的fd</p><pre><code class="hljs c"><span class="hljs-keyword">while</span> <span class="hljs-literal">true</span> &#123;    active_stream[] = epoll_wait(epollfd)<span class="hljs-comment">// 阻塞 直到有事件就绪；只返回已经就绪的事件；epollfd-关注的文件描述符</span>    <span class="hljs-keyword">for</span> i in active_stream[] &#123;        read <span class="hljs-keyword">or</span> write till unavailable    &#125;&#125;</code></pre></li></ul><h4 id="I-O多路复用的优势"><a href="#I-O多路复用的优势" class="headerlink" title="I/O多路复用的优势"></a>I/O多路复用的优势</h4><p>并不是对于单个连接能处理的更快，而是在于可以在单个线程/进程中处理更多的连接。</p><blockquote><p>异步处理的是比较快，但是整体性能来看，上下文切换的损耗不得不考虑一下</p></blockquote><h4 id="本质还是同步IO"><a href="#本质还是同步IO" class="headerlink" title="本质还是同步IO"></a>本质还是同步IO</h4><p>IO多路复用(select/poll/epoll) 本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的</p><blockquote><p><a href="https://blog.csdn.net/chewbee/article/details/78108223">https://blog.csdn.net/chewbee/article/details/78108223</a></p><p>有更详细的 select/poll/epoll 函数原型的介绍</p></blockquote><h4 id="使用epoll的例子"><a href="#使用epoll的例子" class="headerlink" title="使用epoll的例子"></a>使用epoll的例子</h4><p>可以监视多个fd上发生的指定的n种事件，获取到这些事件然后做相应的处理，比如epoll的使用一般都是这个框架</p><pre><code class="hljs c++"><span class="hljs-keyword">for</span>( ; ; )    &#123;        nfds = <span class="hljs-built_in">epoll_wait</span>(epfd,events,<span class="hljs-number">20</span>,<span class="hljs-number">500</span>);<span class="hljs-comment">//阻塞 直到有事件（就绪的io）</span>        <span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>;i&lt;nfds;++i)        &#123;            <span class="hljs-keyword">if</span>(events[i].data.fd==listenfd) <span class="hljs-comment">//有新的连接</span>            &#123;                connfd = <span class="hljs-built_in">accept</span>(listenfd,(sockaddr *)&amp;clientaddr, &amp;clilen); <span class="hljs-comment">//accept这个连接</span>                ev.data.fd=connfd;                ev.events=EPOLLIN|EPOLLET;                <span class="hljs-built_in">epoll_ctl</span>(epfd,EPOLL_CTL_ADD,connfd,&amp;ev); <span class="hljs-comment">//将新的fd添加到epoll的监听队列中</span>            &#125;            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>( events[i].events&amp;EPOLLIN ) <span class="hljs-comment">//接收到数据，读socket</span>            &#123;                n = <span class="hljs-built_in">read</span>(sockfd, line, MAXLINE)) &lt; <span class="hljs-number">0</span>    <span class="hljs-comment">//读</span>                ev.data.ptr = md;     <span class="hljs-comment">//md为自定义类型，添加数据</span>                ev.events=EPOLLOUT|EPOLLET;                <span class="hljs-built_in">epoll_ctl</span>(epfd,EPOLL_CTL_MOD,sockfd,&amp;ev);<span class="hljs-comment">//修改标识符，等待下一个循环时发送数据，异步处理的精髓</span>            &#125;            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(events[i].events&amp;EPOLLOUT) <span class="hljs-comment">//有数据待发送，写socket</span>            &#123;                struct myepoll_data* md = (myepoll_data*)events[i].data.ptr;    <span class="hljs-comment">//取数据</span>                sockfd = md-&gt;fd;                <span class="hljs-built_in">send</span>( sockfd, md-&gt;ptr, <span class="hljs-built_in">strlen</span>((<span class="hljs-keyword">char</span>*)md-&gt;ptr), <span class="hljs-number">0</span> );        <span class="hljs-comment">//发送数据</span>                ev.data.fd=sockfd;                ev.events=EPOLLIN|EPOLLET;                <span class="hljs-built_in">epoll_ctl</span>(epfd,EPOLL_CTL_MOD,sockfd,&amp;ev); <span class="hljs-comment">//修改标识符，等待下一个循环时接收数据</span>            &#125;            <span class="hljs-keyword">else</span>            &#123;                <span class="hljs-comment">//其他的处理</span>            &#125;        &#125;    &#125;</code></pre><blockquote><p>这里也有关于epoll的参数介绍 <a href="https://www.cnblogs.com/fnlingnzb-learner/p/5835573.html">https://www.cnblogs.com/fnlingnzb-learner/p/5835573.html</a></p></blockquote><h4 id="关于linux-select-的一个问题"><a href="#关于linux-select-的一个问题" class="headerlink" title="关于linux select()的一个问题"></a>关于linux select()的一个问题</h4><p>问题  <a href="https://www.zhihu.com/question/37271342">https://www.zhihu.com/question/37271342</a></p><blockquote><p>假如我调用了一个 select 函数，并且关注了几个fd， select 函数就会一直阻塞直到我关注的事件发生. 假如当有套接口可读时， select 函数就返回了，告诉我们套接口已经可读，然后我们去读这个套接口，可以用阻塞的read或者非阻塞的 read，阻塞 read 是无数据可读就阻塞进程，非阻塞 read是无数据可读就返回一个 EWOULDBLOCK 错误。那么问题来了：既然 select 都返回可读了，那就表示一定能读了，阻塞函数read也就能读取了也就不会阻塞了，非阻塞read的话，也有数据读了，也不会返回错误了，那么这俩不都一样了？一样直接读取数据知道读完，为什么还得用非阻塞函数？还有 Reactor 模式也是用的 IO 多路复用与非阻塞 IO，这是什么道理呢？</p></blockquote><p>答案</p><blockquote><ol><li><blockquote><p>Under Linux, select() may report a socket file descriptor as “ready for reading”, while nevertheless a subsequent read blocks.  This could for example happen when data has arrived but upon examination has wrong checksum and is discarded.  There may be other circumstances in which a file descriptor is spuriously reported  as ready.  Thus it  may be safer to use O_NONBLOCK on sockets that should not block.</p><p>链接：<a href="https://www.zhihu.com/question/37271342/answer/81808421">https://www.zhihu.com/question/37271342/answer/81808421</a></p></blockquote><p>Linux环境下, select()可能收到socket fd回复的“读就绪”, 紧接着read()会阻塞。这可能因为数据准备完成之后发生了错误被丢弃了。 其他情况下fd可能被错误地报告为“读就绪”。所以在不该阻塞的IO操作中 还是用非阻塞比较安全。</p></li><li><p>select()返回可读之后就直接去read()并不一定能读取到数据，select()内部调用fd是否就绪 和 调用read() 是两次系统调用，这之间是可能有其他事件发生的，</p><p>举个例子： 惊群现象，投一粒米，所有鸽子都来吃，只有一个吃到，然后所有鸽子都得回去睡觉。</p><p>这个可读的数据可能就是已经被其他进程/线程读完了。</p><p>链接：<a href="https://www.zhihu.com/question/37271342/answer/81757593">https://www.zhihu.com/question/37271342/answer/81757593</a></p></li></ol></blockquote>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/git/"/>
    <url>/blog/2021/03/22/git/</url>
    
    <content type="html"><![CDATA[<h5 id="初始化成git仓库"><a href="#初始化成git仓库" class="headerlink" title="初始化成git仓库"></a>初始化成git仓库</h5><p><code>git init</code></p><h5 id="绑定到远程仓库"><a href="#绑定到远程仓库" class="headerlink" title="绑定到远程仓库"></a>绑定到远程仓库</h5><p><code>git remote add origin https://xxx.git</code></p><h5 id="第一次push-的时候携带的参数"><a href="#第一次push-的时候携带的参数" class="headerlink" title="第一次push 的时候携带的参数"></a>第一次push 的时候携带的参数</h5><p><code>git push -u origin master</code></p><h2 id="revert"><a href="#revert" class="headerlink" title="revert"></a>revert</h2><p><code>git revert HEAD^</code>  <code>git revert HEAD^^</code>  <code>git revert HEAD~3</code>   一个^就是前1次commit </p><p><code>git revert &lt;commitId&gt;</code>  revert 到指定的commit版本</p><p>会再生成一次commit，并且当前代码和指定的那次commit的代码一致。</p><h2 id="reset"><a href="#reset" class="headerlink" title="reset"></a>reset</h2><p>用<code>reset</code>回滚，参数：</p><blockquote><ul><li>git reset –soft                          保留工作目录，并把新的全部差异放进暂存区</li></ul><blockquote><p>原节点和Reset节点之间的所有差异都会放到暂存区中</p></blockquote><ul><li><p>git reset (git reset –mixed)    保留工作目录，清空暂存区</p></li><li><p>git reset –hard                         清空工作目录，清空暂存区，全部和git log 中的上n次commit内容相同</p><blockquote><p>然后push的话会报错，‘必须先pull’ 才能push， 但是pull，会把刚才回退的commit又带出来，所以得 push -f   （强制）</p></blockquote></li></ul></blockquote><blockquote><p> soft 和 mixed 区别应该就是 mixed 不需要再手动 add 而 soft 需要自己再手动 add 然后 commit。</p></blockquote><h2 id="修改commit的msg"><a href="#修改commit的msg" class="headerlink" title="修改commit的msg"></a>修改commit的msg</h2><p><code>git commit --amend</code><br>会进入vim，修改保存就行了</p><h3 id="如果commit已经被覆盖"><a href="#如果commit已经被覆盖" class="headerlink" title="如果commit已经被覆盖"></a>如果commit已经被覆盖</h3><p><code>git rebase -i HEAD^</code> </p><p><code>git rebase -i HEAD~n</code> n是逆推几次</p><pre><code class="hljs awk">pick <span class="hljs-number">07</span>bca843 添加 广告线索来源构成分析、概览 接口 <span class="hljs-regexp">/source-ad/</span>constitute、<span class="hljs-regexp">/source-ad/</span>listpick <span class="hljs-number">67</span>d1e638 移除<span class="hljs-regexp">/income/</span>top</code></pre><p>将开头的pick修改为edit就可以编辑了<br>然后git会提示</p><pre><code class="hljs sql">You can amend the <span class="hljs-keyword">commit</span> now, <span class="hljs-keyword">with</span>  git <span class="hljs-keyword">commit</span> <span class="hljs-comment">--amend</span>Once you <span class="hljs-keyword">are</span> satisfied <span class="hljs-keyword">with</span> your changes, run  git rebase <span class="hljs-comment">--continue</span></code></pre><p><code>git commit --amend</code> 进入修改<br>完事continue rebase 即可<br><code>git rebase --continue</code></p><p>​             </p><h2 id="git-diff"><a href="#git-diff" class="headerlink" title="git diff"></a>git diff</h2><p><code>git diff --cached</code> 查看本地分支和当前代码的区别</p><h2 id="统计git-log"><a href="#统计git-log" class="headerlink" title="统计git log"></a>统计git log</h2><pre><code class="hljs apache"><span class="hljs-attribute">git</span> log --author=<span class="hljs-string">&quot;$(git config --get user.name)&quot;</span> --since=<span class="hljs-number">2021</span>-<span class="hljs-number">01</span>-<span class="hljs-number">01</span> --until=<span class="hljs-number">2021</span>-<span class="hljs-number">03</span>-<span class="hljs-number">30</span> --pretty=tformat: --numstat | gawk &#x27;&#123; add += $<span class="hljs-number">1</span> ; subs += $<span class="hljs-number">2</span> ; loc += $<span class="hljs-number">1</span> - $<span class="hljs-number">2</span> &#125; END &#123; printf <span class="hljs-string">&quot;增加的行数:%s 删除的行数:%s 总行数: %s\n&quot;</span>,add,subs,loc &#125;&#x27;</code></pre>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/hadoop/"/>
    <url>/blog/2021/03/22/hadoop/</url>
    
    <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>yarn 主要包括ResourceManager、NodeManager</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>安装好jdk1.8的linux系统下</p><ol><li><p>创建hadoop用户</p><pre><code class="hljs sh">$ sudo useradd -m hadoop -s /bin/bash  <span class="hljs-comment">#创建hadoop用户，并使用/bin/bash作为shell</span>$ sudo passwd hadoop                   <span class="hljs-comment">#为hadoop用户设置密码，之后需要连续输入两次密码</span>$ sudo adduser hadoop sudo             <span class="hljs-comment">#为hadoop用户增加管理员权限</span>$ su - hadoop                          <span class="hljs-comment">#切换当前用户为用户hadoop</span>$ sudo apt-get update                  <span class="hljs-comment">#更新hadoop用户的apt,方便后面的安装</span></code></pre></li><li><p>设置ssh和无密码登陆</p><pre><code class="hljs sh">$ sudo apt-get install openssh-server   <span class="hljs-comment">#安装SSH server</span><span class="hljs-comment">#需要版本对应，安装报依赖不合格的话就apt install 对应版本的client即可</span>$ ssh localhost                         <span class="hljs-comment">#登陆SSH，第一次登陆输入yes</span>$ <span class="hljs-built_in">exit</span>                                  <span class="hljs-comment">#退出登录的ssh localhost</span>$ <span class="hljs-built_in">cd</span> ~/.ssh/                            <span class="hljs-comment">#如果没法进入该目录，执行一次ssh localhost</span>$ ssh-keygen -t rsa　<span class="hljs-comment">#然后的三次输入都确定即可 直接回车</span>$ cat ./id_rsa.pub &gt;&gt; ./authorized_keys <span class="hljs-comment">#加入授权</span>$ ssh localhost                         <span class="hljs-comment">#此时已不需密码即可登录localhost，如果失败则可以搜索SSH免密码登录来寻求答案</span></code></pre></li><li><p>下载hadoop-xxx.tar.gz解压到/usr/local/hadoop…</p><pre><code class="hljs sh">   sudo tar -zxvf hadoop-xxx.tar.gz -C /usr/<span class="hljs-built_in">local</span>   <span class="hljs-built_in">cd</span> /usr/<span class="hljs-built_in">local</span>mv hadoop-xxx/ hadoop/ <span class="hljs-comment">#将/usr/local/hadoop-xxx 改名为 /usr/local/hadoop</span>   sudo chown -R hadoop ./hadoop <span class="hljs-comment">#授权  </span>sudo chmod 777 /usr/<span class="hljs-built_in">local</span>/hadoop</code></pre></li><li><p>配置环境变量 (已配置JAVA的环境变量)</p><pre><code class="hljs shell">sudo vim /etc/profile</code></pre><pre><code class="hljs sh"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/<span class="hljs-built_in">local</span>/jdk1.8<span class="hljs-built_in">export</span> HADOOP_HOME=/usr/<span class="hljs-built_in">local</span>/hadoop<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_HOME</span>/bin:<span class="hljs-variable">$HADOOP_HOME</span>/sbin:<span class="hljs-variable">$JAVA_HOME</span>/bin<span class="hljs-comment">#export CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$CLASSPATH</span><span class="hljs-built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/lib/native<span class="hljs-comment">#export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib:$HADOOP_COMMON_LIB_NATIVE_DIR&quot;</span></code></pre><pre><code class="hljs sh"><span class="hljs-built_in">source</span> /etc/profile <span class="hljs-comment">#使配置文件生效</span></code></pre></li><li><p><code>hadoop version</code>即可查看版本</p></li></ol><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>可以在官网下查看各配置作用,左下角config</p><pre><code class="hljs http">https://hadoop.apache.org/docs/r2.10.0/</code></pre><p>hadoop有默认配置文件和自定义配置文件，jar包中可以找到default.xml文件</p><ul><li><p>默认配置文件</p><table><thead><tr><th>默认文件</th><th align="left">jar包</th></tr></thead><tbody><tr><td>core-default.xml</td><td align="left">hadoop-common-x.x.x.jar</td></tr><tr><td>hdfs-default.xml</td><td align="left">hadoop-hdfs-x.x.x.jar</td></tr><tr><td>yarn-default.xml</td><td align="left">hadoop-yarn-common-x.x.x.jar</td></tr><tr><td>mapred-default.xml</td><td align="left">hadoop-mapreduce-client-core-.x.x.x.jar</td></tr></tbody></table></li><li><p>自定义配置文件</p><table><thead><tr><th>默认文件</th><th align="left">jar包</th></tr></thead><tbody><tr><td>core-site.xml</td><td align="left">hadoop-common-x.x.x.jar</td></tr><tr><td>hdfs-site.xml</td><td align="left">hadoop-hdfs-x.x.x.jar</td></tr><tr><td>yarn-site.xml</td><td align="left">hadoop-yarn-common-x.x.x.jar</td></tr><tr><td>mapred-site.xml</td><td align="left">hadoop-mapreduce-client-core-.x.x.x.jar</td></tr></tbody></table></li></ul><h3 id="伪分布式配置"><a href="#伪分布式配置" class="headerlink" title="伪分布式配置"></a>伪分布式配置</h3><blockquote><p>cd /usr/local/hadoop</p></blockquote><ol><li><p>配置hadoop-env.sh,添加环境变量</p><pre><code class="hljs sh"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/<span class="hljs-built_in">local</span>/jdk1.8</code></pre></li><li><p>修改core-site.xml文件</p><blockquote><p>file:/  本地模式使用的协议</p><p>hdfs://  分布式模式使用的协议</p></blockquote><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><span class="hljs-comment">&lt;!--其他临时目录--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>Abase for other temporary directories.<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-comment">&lt;!--默认文件系统的名称。一个URI，其模式和权限决定文件系统的实现。uri的模式决定了命名文件系统实现类的配置属性(fs. schema .impl)。uri的权限用于确定文件系统的主机、端口等。默认file:///--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://localhost:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre></li><li><p>修改hdfs-site.xml</p><blockquote><p> dfs.replication副本数：默认3</p></blockquote><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><span class="hljs-comment">&lt;!--默认的块复制。可以在创建文件时指定复制的实际数目。如果在创建时未指定复制，则使用默认值 3--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-comment">&lt;!-- 确定DFS数据节点应该将其块存储在本地文件系统的哪个位置。如果这是一个以逗号分隔的目录列表，那么数据将存储在所有命名的目录中，通常在不同的设备上。对于HDFS存储策略，目录应该使用相应的存储类型([SSD]/[DISK]/[ARCHIVE]/[RAM_DISK])进行标记。如果目录没有显式标记的存储类型，则默认存储类型为DISK。如果本地文件系统权限允许，将创建不存在的目录。默认值 file://$&#123;hadoop.tmp.dir&#125;/dfs/data --&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre></li><li><p>格式化NameNode</p><pre><code class="hljs sh">bin/hdfs namenode -format</code></pre><blockquote><p>有数据的时候格式化namenode会使/usr/local/hadoop/tmp/dfs/data/name/current/VERSION中的clusterID会和datanode的clusterID不一致,所以必须先删除DataNode中的数据</p></blockquote></li><li><p>启动</p><pre><code class="hljs shell">sbin/start-all.sh</code></pre><p>启动完成可以使用jps查看进程</p><blockquote><p>DataNode</p><p>NameNode</p><p>NodeManager</p><p>ResourceManager</p><p>SecondaryNameNode</p></blockquote></li><li><p>配置yarn (非必须)  重启</p><blockquote><ol><li><p>在/usr/local/hadoop-xxx/etc/hadoop目录下</p><pre><code class="hljs shell">cp mapred-site.xml.template mapred-site.xml</code></pre></li><li><p>修改mapred-site.xml</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><span class="hljs-comment">&lt;!-- 用于执行MapReduce作业的运行时框架。可以是local, classic 或者 yarn --&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre></li><li><p>修改yarn-site.xml</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><span class="hljs-comment">&lt;!-- 一个逗号分隔的服务列表，其中服务名应该只包含A- z a - z 0 -9_，并且不能以数字开头。 shuffle混洗重组模式 --&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre></li><li><p>单独启动resourcemanager 和 nodemaneger</p><pre><code class="hljs shell">sbin/yarn-daemon.sh start resourcemanagersbin/yarn-daemon.sh start nodemanager</code></pre></li></ol></blockquote></li><li><p>启动历史资源管理器</p><blockquote><p> 就能在8088的记录中点击<u>history</u>链接，展示对历史mp的history链接中显示详细信息</p></blockquote><ul><li><p>配置mapred-site.xml</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>localhost:10020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>localhost:19888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></code></pre></li><li><p>启动/关闭 历史服务器</p><pre><code class="hljs shell">sbin/mr-jobhistory-daemon.sh start historyserversbin/mr-jobhistory-daemon.sh stop historyserver</code></pre></li></ul></li><li><p>配置日志聚集 (需要重启NodeNanager ResourceNanager HistoryNanager)</p><blockquote><p>应用运行完成之后，将运行日志信息上传到hdfs。方便开发调试。</p></blockquote><ul><li><p>配置yarn-site.xml</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-comment">&lt;!--日志保留7天--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>604800<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></code></pre></li></ul></li></ol><h6 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h6><pre><code class="hljs sh">bin/hadoop dfsadmin -safemode leave<span class="hljs-comment">#enter - 进入安全模式</span><span class="hljs-comment">#leave - 强制NameNode离开安全模式</span><span class="hljs-comment">#get - 返回安全模式是否开启的信息</span><span class="hljs-comment">#wait - 等待，一直到安全模式结束。</span></code></pre><h2 id="hadoop-example"><a href="#hadoop-example" class="headerlink" title="hadoop example"></a>hadoop example</h2><h3 id="词频统计-wordcount"><a href="#词频统计-wordcount" class="headerlink" title="词频统计 wordcount"></a>词频统计 wordcount</h3><ol><li><p>本地创建words.txt并写入一些单词</p><blockquote><p>touch ~/test/words.txt</p></blockquote></li><li><p>上传到hdfs</p><blockquote><p>hdfs dfs -put ~/test /input</p></blockquote></li><li><p>map reduce</p><pre><code class="hljs sh">hadoop jar /usr/<span class="hljs-built_in">local</span>/hadoop-2.10.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar wordcount /input /output</code></pre></li><li><p>查看结果</p><blockquote><p>hdfs dfs -cat /output/part-r-00000</p></blockquote></li></ol><h3 id="正则抽取-grep"><a href="#正则抽取-grep" class="headerlink" title="正则抽取 grep"></a>正则抽取 grep</h3><pre><code class="hljs gradle">hadoop jar <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/hadoop-2.10.0/</span>share<span class="hljs-regexp">/hadoop/m</span>apreduce<span class="hljs-regexp">/hadoop-mapreduce-examples-2.10.0.jar grep /i</span>nput /output-<span class="hljs-keyword">grep</span> <span class="hljs-string">&#x27;正则表达式&#x27;</span></code></pre><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h3><ul><li><p>创建文件夹</p><blockquote><p>hdfs dfs -mkdir [xx] /…</p><p>​    -p 多级创建  可以-mkdir -p /first/second/xx</p></blockquote></li><li><p>查看ls</p><blockquote><p>hdfs dfs -ls [xx] /…</p><p>​    -R 多级查看  可以将父目录下的子目录也显示出来</p></blockquote></li><li><p>上传到hdfs</p><blockquote><p>hdfs dfs -put 本地路径 hdfs路径、</p></blockquote></li><li><p>删除</p><blockquote><p>hdfs dfs -rm -r /xx  #删除文件夹</p><p>hdfs dfs -rm /xxx/xx.text  #删除文件</p></blockquote></li></ul><h3 id="安全模式-1"><a href="#安全模式-1" class="headerlink" title="安全模式"></a>安全模式</h3><pre><code class="hljs sh">bin/hadoop dfsadmin -safemode leave<span class="hljs-comment">#enter - 进入安全模式</span><span class="hljs-comment">#leave - 强制NameNode离开安全模式</span><span class="hljs-comment">#get - 返回安全模式是否开启的信息</span><span class="hljs-comment">#wait - 等待，一直到安全模式结束。</span></code></pre><h2 id="shuffle"><a href="#shuffle" class="headerlink" title="shuffle"></a>shuffle</h2><p>混洗重组</p><h2 id="分布式搭建"><a href="#分布式搭建" class="headerlink" title="分布式搭建"></a>分布式搭建</h2><ol><li>克隆4台虚拟机，并分别配置ip</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/tail%20%E5%85%B3%E9%94%AE%E5%AD%97%E9%AB%98%E4%BA%AE/"/>
    <url>/blog/2021/03/22/tail%20%E5%85%B3%E9%94%AE%E5%AD%97%E9%AB%98%E4%BA%AE/</url>
    
    <content type="html"><![CDATA[<pre><code class="hljs apache"><span class="hljs-attribute">tail</span> -f system.log |grep <span class="hljs-string">&quot;/write-down&quot;</span> |grep <span class="hljs-string">&quot;payload=&quot;</span> | perl -pe &#x27;s/(visitType)|(visitTerminal)|(operateType)/\e[<span class="hljs-number">1</span>;<span class="hljs-number">33</span>m$<span class="hljs-number">1</span>\e[<span class="hljs-number">0</span>m\e[<span class="hljs-number">1</span>;<span class="hljs-number">33</span>m$<span class="hljs-number">2</span>\e[<span class="hljs-number">0</span>m\e[<span class="hljs-number">1</span>;<span class="hljs-number">33</span>m$<span class="hljs-number">3</span>\e[<span class="hljs-number">0</span>m/g&#x27;</code></pre><p><code>perl</code>命令 进行动态替换，格式：</p><pre><code class="hljs apache"><span class="hljs-attribute">perl</span> -pe &#x27;s/([关键词<span class="hljs-number">1</span>])|([关键词<span class="hljs-number">2</span>])/\e</code></pre><p>关键词部分：<code>s/([关键词1])|([关键词2])/</code><br>颜色部分：<code>\e[1;颜色1$1\e[背景颜色</code> <code>\e[1;颜色2$2\e[背景颜色</code></p><pre><code class="hljs subunit">字体颜色：30m：黑31m：红32m：绿33m：黄34m：蓝35m：紫36m：青37m：白背景颜色设置40<span class="hljs-string">-47</span> 黑、红、绿、黄、蓝、紫、青、白40：黑41：红42：绿43：黄44：蓝45：紫46：青47：白</code></pre>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/zookeeper/"/>
    <url>/blog/2021/03/22/zookeeper/</url>
    
    <content type="html"><![CDATA[<h1 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h1><p>分布式协调服务，为其他分布式应用程序提供基本的同步和组服务</p><p>为了可靠性，不能一个宕机就完蛋，也要搭建集群，搭建集群就分布式，分布式就要保证一致性，一致性的解决方案。。又是Paxos</p><p>选举一个leader，发送提案，多半同意则发送提交，</p><blockquote><p>这里会有个问题 <a href="https://www.zhihu.com/question/324291664">https://www.zhihu.com/question/324291664</a></p><p><a href="https://www.zhihu.com/question/324291664/answer/909822937">https://www.zhihu.com/question/324291664/answer/909822937</a> 这个答案很清楚。 （就是依靠 最少半数节点+读时检测 保证的一致性）</p></blockquote><p>因为要保证一致性，所以节点越多性能就越低，一般3、5个节点即可</p><blockquote><p>奇数就是因为 保证节点一致性需要超过半数同意提案嘛， 5个节点和6个节点都需要3个节点同意才行，所以六个节点多出来那个没必要，还会增加节点通信的开销。</p></blockquote><h2 id="ZAB-zookeeper原子广播协议"><a href="#ZAB-zookeeper原子广播协议" class="headerlink" title="ZAB zookeeper原子广播协议"></a>ZAB zookeeper原子广播协议</h2><p>Paxos的简单实现吧</p><h2 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h2><p>镜像下载链接：</p><p><a href="https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.14/">https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.14/</a></p><p>zookeeper读取/conf/zoo.cfg文件作为配置文件，可复制zoo_simple.cfg在修改</p><pre><code class="hljs mipsasm"><span class="hljs-keyword">bin/zkServer.sh </span>start <span class="hljs-comment">#启动zk服务</span><span class="hljs-keyword">bin/zkServer.sh </span>status <span class="hljs-comment">#查看zk服务的状态</span><span class="hljs-keyword">bin/zkServer.sh </span>restart <span class="hljs-comment">#重启</span><span class="hljs-keyword">bin/zkServer.sh </span>stop <span class="hljs-comment">#停止</span><span class="hljs-keyword">bin/zkCli.sh </span><span class="hljs-comment">#连接zk服务  -server host:port</span></code></pre><pre><code class="hljs jboss-cli"><span class="hljs-keyword">ls</span> / <span class="hljs-comment">#查看根目录下的内容</span><span class="hljs-keyword">ls</span>2 / <span class="hljs-comment">#查看根目录下的内容和更新次数等具体信息</span>create <span class="hljs-string">/test</span> <span class="hljs-string">&quot;info1&quot;</span> <span class="hljs-comment">#创建一个新的znode节点，和关联的字符串</span>get <span class="hljs-string">/test</span><span class="hljs-keyword">set</span> <span class="hljs-string">/test</span> <span class="hljs-string">&quot;info-update&quot;</span>delete <span class="hljs-string">/test</span> <span class="hljs-comment">#删除节点</span><span class="hljs-keyword">quit</span> <span class="hljs-comment">#退出客户端</span></code></pre><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-built_in">stat</span> | nc 127.0.0.1 2181 <span class="hljs-comment">#来查看哪个节点被选择作为follower或者leader</span><span class="hljs-built_in">echo</span> ruok | nc 127.0.0.1 2181 <span class="hljs-comment">#测试是否启动了该Server，若回复imok表示已经启动。</span><span class="hljs-built_in">echo</span> dump | nc 127.0.0.1 2181 <span class="hljs-comment">#列出未经处理的会话和临时节点。</span><span class="hljs-built_in">echo</span> <span class="hljs-built_in">kill</span> | nc 127.0.0.1 2181 <span class="hljs-comment">#关掉server</span><span class="hljs-built_in">echo</span> conf | nc 127.0.0.1 2181 <span class="hljs-comment">#输出相关服务配置的详细信息。</span><span class="hljs-built_in">echo</span> cons | nc 127.0.0.1 2181 <span class="hljs-comment">#列出所有连接到服务器的客户端的完全的连接 / 会话的详细信息。</span><span class="hljs-built_in">echo</span> envi | nc 127.0.0.1 2181 <span class="hljs-comment">#输出关于服务环境的详细信息（区别于 conf 命令）。</span><span class="hljs-built_in">echo</span> reqs | nc 127.0.0.1 2181 <span class="hljs-comment">#列出未经处理的请求。</span><span class="hljs-built_in">echo</span> wchs | nc 127.0.0.1 2181 <span class="hljs-comment">#列出服务器 watch 的详细信息。</span><span class="hljs-built_in">echo</span> wchc | nc 127.0.0.1 2181 <span class="hljs-comment">#通过 session 列出服务器 watch 的详细信息，它的输出是一个与 watch 相关的会话的列表。</span><span class="hljs-built_in">echo</span> wchp | nc 127.0.0.1 2181 <span class="hljs-comment">#通过路径列出服务器 watch 的详细信息。它输出一个与 session 相关的路径。</span></code></pre>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/%E4%B8%80%E8%87%B4%E6%80%A7hash/"/>
    <url>/blog/2021/03/22/%E4%B8%80%E8%87%B4%E6%80%A7hash/</url>
    
    <content type="html"><![CDATA[<h1 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h1><p><a href="https://blog.csdn.net/cywosp/article/details/23397179">https://blog.csdn.net/cywosp/article/details/23397179</a></p><p>哈希算法<code>Hash</code>，也叫摘要算法<code>Digest</code></p><blockquote><p>输入一组任意长度的数据，计算得到一个固定长度的摘要数据。</p></blockquote><pre><code class="hljs applescript">java中重写<span class="hljs-keyword">equals</span>()方法,为什么要重写hashCode()?如果只是重写<span class="hljs-keyword">equals</span>(), <span class="hljs-keyword">equals</span>()=<span class="hljs-literal">true</span>，但hashCode()==<span class="hljs-literal">false</span>,这有悖于<span class="hljs-keyword">equals</span>()和hashCode()方法的关系，以及hashCode的规则:两个对象相等，hashcode一定相等两个对象不等，hashcode不一定不等hashcode相等，两个对象不一定相等hashcode不等，两个对象一定不等Object<span class="hljs-comment">#hashCode是用对象的内存地址作为哈希算法的输入，所以重写hashCode()时要用对象的属性值作为入参</span></code></pre><p>哈希碰撞，也就是会产生两个对象不等，hashCode可能相等的情况。这种情况不能避免，毕竟哈希算法是把一个无限的输入集合映射到有限的输出集合。</p><table><thead><tr><th>常用的哈希算法</th><th>输出bit长度</th><th>输出byte长度</th></tr></thead><tbody><tr><td>MD5</td><td>128bits</td><td>16bytes</td></tr><tr><td>RipeMD-160</td><td>160bits</td><td>20</td></tr><tr><td>SHA-1</td><td>160bits</td><td>20</td></tr><tr><td>SHA-256</td><td>256bits</td><td>32</td></tr><tr><td>SHA-512</td><td>512bits</td><td>64</td></tr></tbody></table><p>java中的hash算法：<a href="https://docs.oracle.com/en/java/javase/14/docs/specs/security/standard-names.html#messagedigest-algorithms">https://docs.oracle.com/en/java/javase/14/docs/specs/security/standard-names.html#messagedigest-algorithms</a></p><p>想要破解哈希算法，只能暴力穷举，想要提高穷举效率可以用<strong>彩虹表</strong></p><blockquote><p>彩虹表攻击：提前把一些常见的值生成hashCode存储起来，拿到要破解的hashCode之后先从表里查一遍，这就可能直接拿到该明文。</p></blockquote><p>解决的办法也就是加盐了。计算hashCode时入参添加salt，并且可以进行n次哈希计算。</p><h1 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h1><p>一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：</p><blockquote><ol><li>平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</li><li>单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他(已失效)缓冲区。 </li><li>分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 </li><li>负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</li></ol></blockquote><p>在P2P环境、分布式环境中若使用常见的<code>hash(object)%N</code>算法来分配数据的存储位置，那么在有机器宕机或者删除后，很多原有的数据就无法找到了，这严重的违反了单调性原则。</p><h4 id="环形hash空间"><a href="#环形hash空间" class="headerlink" title="环形hash空间"></a>环形hash空间</h4><p>用常用的hash算法，会得到一个固定长度的数，比如<code>CRC-16</code>产生的hash值是16bit，那么就有 2^16 = 65536 个值，</p><p>将这65536个值连成一个环形，就形成了一个hash环，有65536个hash槽。</p><blockquote><p>比如redis的hash槽数量是16384，没用65536是因为节点之间ping-pong消息需要携带节点配置信息，节点越多消息体内容就越大。而节点应该不会超过1000，所以综合考虑使用了16384。</p></blockquote><p>把所有机器的标识（id/唯一标识）进行hash得到环上的一点。</p><p>在计算数据要分配到哪个节点的时候，对这个数据进行hash，也得到环上的一点，然后只需要确定一个规则（比如把这个数据放在顺时针方向离它最近的一个hash槽）就能将这些数据分配到集群中的节点（机器）。</p><h4 id="节点宕机-删除节点"><a href="#节点宕机-删除节点" class="headerlink" title="节点宕机/删除节点"></a>节点宕机/删除节点</h4><p>只需要把这个节点的数据转移到顺时针方向最近的一个节点上。</p><h4 id="节点恢复-添加节点"><a href="#节点恢复-添加节点" class="headerlink" title="节点恢复/添加节点"></a>节点恢复/添加节点</h4><p>只需要把   新增节点-&gt;逆时针方向临近节点   之间所有的数据放到新增节点上。</p><h4 id="机器分布不均匀怎么办？-这算法的分散性怎样得到高分"><a href="#机器分布不均匀怎么办？-这算法的分散性怎样得到高分" class="headerlink" title="机器分布不均匀怎么办？ 这算法的分散性怎样得到高分"></a>机器分布不均匀怎么办？ 这算法的分散性怎样得到高分</h4><p>使用虚拟节点，让一个机器不止对应一个hash槽，比如一个机器对应的hash槽可能是<code>192.168.1.1#1</code> <code>192.168.1.1#2</code> <code>192.168.1.1#3</code>等三个hash槽</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>about Spring transaction</title>
    <link href="/blog/2021/03/22/%E5%85%B3%E4%BA%8Espring%E4%BA%8B%E5%8A%A1/"/>
    <url>/blog/2021/03/22/%E5%85%B3%E4%BA%8Espring%E4%BA%8B%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="关于Spring事务"><a href="#关于Spring事务" class="headerlink" title="关于Spring事务"></a>关于Spring事务</h1><p><a href="https://my.oschina.net/u/4579410/blog/4525713">https://my.oschina.net/u/4579410/blog/4525713</a></p><p>看完这个明白的</p><p>想想aop，</p><p>犯的错：</p><blockquote><p>在一个serviceA的非事务方法中调用 this.func2()   func2是个事务方法，</p><p>func2中调用了 serviceB的func1()  serviceB.func1() 是事务方法</p></blockquote><blockquote><p>结果：    在serviceB.func1()最后抛异常， serviceB回滚了  serviceA.func2()的数据落库了。。</p></blockquote><p>原理 ：</p><p>在serviceA的代理对象的调用过程中，serviceA的方法内部调用了本service的方法，aop只在 最外层的方法（serviceA.func1）进行了增强，也就是 事务开启和回滚都应该加在这里，但是serviceA.func1 没有@Transaction。。。所以 serviceA.func2() 的声明式事务并没有生效。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/%E5%B9%82%E7%AD%89%E6%80%A7%E8%AE%BE%E8%AE%A1/"/>
    <url>/blog/2021/03/22/%E5%B9%82%E7%AD%89%E6%80%A7%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<p>如何保证幂等性</p><ol><li><p>在数据库利用唯一索引。</p><blockquote><p>比如生成订单的时候，不能因为网络延迟而创建两次这个订单，所以可以根据这个订单的唯一id。</p><p>第一个 insert 执行之后已经有了这个订单，下次 insert 的时候会报错，可以直接 try-catch 这个异常，在catch中 select by id 查询这个订单，查询到的结果也就是 insert 的期望结果了。</p></blockquote><blockquote><p>不过要利用这个唯一索引的话，订单的 id 肯定是要相同的生成策略，比如使用相同算法生成，重复生成这个订单的时候，算法入参也是相同的，才能得到相同的订单id。比如根据用户id等等。</p></blockquote><blockquote><p>或者使用 唯一组合索引来创建。</p></blockquote></li><li><p>session-token 来防止表单重复提交</p><blockquote><p>前段生成表单之前先从后端得到一个 form-token ，请求到后端之后，后端先对这个token进行验证，然后修改session中的token。这样重复提交的表单所携带的token就会是无效的token。</p></blockquote></li><li><p>对外提供幂等接口</p><blockquote><p>10、对外提供接口的api如何保证幂等<br>如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号；source+seq在数据库里面做唯一索引，防止多次付款(并发时，只能处理一个请求) 。<br>重点：对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。</p></blockquote></li></ol><p><a href="https://www.cnblogs.com/linjiqin/p/9678022.html">https://www.cnblogs.com/linjiqin/p/9678022.html</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/%E6%AD%BB%E9%94%81/"/>
    <url>/blog/2021/03/22/%E6%AD%BB%E9%94%81/</url>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/hd12370/article/details/82814348">https://blog.csdn.net/hd12370/article/details/82814348</a></p><h3 id="四个必要条件"><a href="#四个必要条件" class="headerlink" title="四个必要条件"></a>四个必要条件</h3><ul><li>互斥</li><li>请求和保持（占有并等待）</li><li>不可剥夺（不能抢）</li><li>环路等待（循环等待）</li></ul><h3 id="预防死锁"><a href="#预防死锁" class="headerlink" title="预防死锁"></a>预防死锁</h3><ol><li>资源一次性分配（破坏请求条件）</li><li>一次性获取所有资源，不能全部获取就释放所有（破坏保持条件）</li><li>资源有序分配（按照一定算法对资源进行排序，按顺序拿资源）</li><li>资源可抢夺（需要设置优先级）</li></ol><h3 id="死锁检测"><a href="#死锁检测" class="headerlink" title="死锁检测"></a>死锁检测</h3><p>Jstack工具</p><p>java自带的jvisualvm</p><p>Jconsule工具</p><p>阿里Arthas  artha-boot.jar</p><h2 id="分布式死锁解决方案"><a href="#分布式死锁解决方案" class="headerlink" title="分布式死锁解决方案"></a>分布式死锁解决方案</h2><p><a href="https://www.cnblogs.com/wadmwz/p/10504201.html">https://www.cnblogs.com/wadmwz/p/10504201.html</a></p><h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><p>支付宝两个人同时向对方转账。</p><h4 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h4><blockquote><p>死锁的四个必要条件：互斥(不可破坏)，不可抢占，占有且等待，循环等待 （3 4一起记）</p></blockquote><p>破坏2/3/4。</p><h5 id="破坏-2-不可抢占："><a href="#破坏-2-不可抢占：" class="headerlink" title="破坏 2 不可抢占："></a>破坏 2 不可抢占：</h5><p>synchronized不能实现。需要JUC的Lock。</p><h5 id="破坏-3-占有且等待："><a href="#破坏-3-占有且等待：" class="headerlink" title="破坏 3 占有且等待："></a>破坏 3 占有且等待：</h5><p>拿到所需全部资源再进行操作，资源利用率低。</p><h5 id="破坏-4-循环等待："><a href="#破坏-4-循环等待：" class="headerlink" title="破坏 4 循环等待："></a>破坏 4 循环等待：</h5><p>规定拿资源的顺序（给资源设定序号）。</p><p>比如用相同的算法（eg：hashcode()）对资源进行标号，按照标号进行排序，拿锁的时候都按顺序拿，每个线程就会都先拿a再拿b。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/03/22/redis/"/>
    <url>/blog/2021/03/22/redis/</url>
    
    <content type="html"><![CDATA[<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><p>配置文件示例</p><p><a href="http://download.redis.io/redis-stable/redis.conf">http://download.redis.io/redis-stable/redis.conf</a></p><p>参考</p><p><a href="https://www.cnblogs.com/kismetv/p/9137897.html">https://www.cnblogs.com/kismetv/p/9137897.html</a></p><hr><h3 id="本地缓存和分布式缓存"><a href="#本地缓存和分布式缓存" class="headerlink" title="本地缓存和分布式缓存"></a>本地缓存和分布式缓存</h3><blockquote><p>本地缓存，比如java中的map，guava实现，轻量、快速，但是如果有多个实例，就需要每个实例都保存一份缓存，不具有一致性。</p></blockquote><blockquote><p> 分布式缓存，比如redis、memcached，缓存具有一致性。但是需要保持服务的高可用。</p></blockquote><hr><h3 id="redis-工作模式"><a href="#redis-工作模式" class="headerlink" title="redis 工作模式"></a>redis 工作模式</h3><p>多个cli连接server</p><blockquote><p>redis需要处理cli的命令(get,set,lpush,rpop…)，对<code>接收客户端链接，处理请求，返回命令结果</code>等任务，redis使用主进程和主线程完成。</p><p>redis后台还有RDB持久化，AOF重写等任务，这些任务会启动子进程来完成。</p></blockquote><h3 id="redis-线程模型"><a href="#redis-线程模型" class="headerlink" title="redis 线程模型"></a>redis 线程模型</h3><p><a href="https://www.jianshu.com/p/8f2fb61097b8">https://www.jianshu.com/p/8f2fb61097b8</a> 这个图更清楚一点</p><blockquote><p>redis内部使用文件事件处理器（file event handler），这个handler是单线程的，所有请求都要经过这个入口才能被处理，自然就有了先后顺序，所以说是单线程模型。</p></blockquote><blockquote><p>在这个模型中，Redis 服务器用主线程执行 I/O 多路复用程序、文件事件分派器以及事件处理器。而且，尽管多个文件事件可能会并发出现，Redis 服务器是顺序处理各个文件事件的。        ——《Redis设计与实现》</p></blockquote><blockquote><p>IO多路复用的 Reactor 模式</p></blockquote><p>master线程监听多个socket，将产生的事件加入任务队列，事件分派器从队列中取出事件并执行，这也就保证按顺序执行。</p><p><img src="redis%E5%A4%84%E7%90%86%E4%B8%80%E6%AC%A1%E5%91%BD%E4%BB%A4%E8%BF%87%E7%A8%8B.png"></p><h3 id="redis6线程模型"><a href="#redis6线程模型" class="headerlink" title="redis6线程模型"></a>redis6线程模型</h3><p>采用多线程处理IO(默认不开启)，事件处理器仍然是单线程。</p><blockquote><pre><code class="hljs coffeescript">io-threads-<span class="hljs-keyword">do</span>-reads <span class="hljs-literal">no</span> <span class="hljs-comment">#yes开启  多线程</span>io-threads <span class="hljs-number">4</span> <span class="hljs-comment">#配置&lt;=cpu核数性能最高，之前单线程就是只能谁用一个cpu，现在如果线程数量过多增加了线程上下文切换的话性能可能不会提升</span><span class="hljs-comment">#官方建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程，线程数一定要小于机器核数。</span><span class="hljs-comment">#官方认为线程数并不是越大越好，超过了8个基本就没什么意义了</span></code></pre></blockquote><p>IO线程只能是同时都在读 或者 同时都在写；</p><p>IO线程时负责读写socket解析命令，命令处理还是通过单线程的文件事件处理器处理；</p><blockquote><ol><li><p>主线程把准备好了的socket放到等待队列，然后阻塞等待IO线程去处理socket（生成对应的事件push到队列）</p><blockquote><p>感觉就相当于 用多线程IO同时对一批socket进行处理，以提高QPS</p></blockquote></li><li><p>主线程顺序处理事件（交由对应的处理器处理），处理结果再交给IO线程写到对应的socket</p></li><li><p>等待IO线程的写操作都完成，解除IO线程和等待队列中的socket的绑定，清空等待队列（socket都处理完了嘛）</p></li><li><p>再走1   这么个循环。</p></li></ol></blockquote><blockquote><p>todo！ 看看redis源码吧   <a href="https://github.com/redis/redis.git">https://github.com/redis/redis.git</a>       <a href="mailto:&#103;&#x69;&#116;&#64;&#x67;&#105;&#116;&#104;&#117;&#98;&#x2e;&#99;&#111;&#109;">&#103;&#x69;&#116;&#64;&#x67;&#105;&#116;&#104;&#117;&#98;&#x2e;&#99;&#111;&#109;</a>:redis/redis.git</p></blockquote><p>可以看看这篇文章：<a href="https://ruby-china.org/topics/38957%EF%BC%89">https://ruby-china.org/topics/38957%EF%BC%89</a></p><h3 id="hash扩容：渐进式扩容"><a href="#hash扩容：渐进式扩容" class="headerlink" title="hash扩容：渐进式扩容"></a>hash扩容：渐进式扩容</h3><p>hash字典的初始容量为4（3.2.8版本是这样）</p><p>redis的hash类型在    <strong>元素数量与数组size相同时（且没有在进行bgsave）</strong> 或  <strong>元素数量是数组size的5倍（不论是否在bgsave）</strong>的时候就会开始扩容，新数组的size为元素数量*2。</p><p>redis hash 维护一个rehashidx来表示重新hash的索引，默认值为 -1，如果 &gt;=0 说明开始 rehash 了，则每次对这个hash进行操作的时候将 rehashidx 处的元素进行rehash，当idx进行到最后的时候再置为-1结束扩容。这样在rehash过程中也能正常提供服务。</p><h3 id="hash缩容"><a href="#hash缩容" class="headerlink" title="hash缩容"></a>hash缩容</h3><p>当hash数组中的元素数量所占比例小于负载因子（0.1），不论是否正在bgsave或者bgwriteaof，都会进行缩容</p><hr><h3 id="redis-VS-memcached"><a href="#redis-VS-memcached" class="headerlink" title="redis VS memcached"></a>redis VS memcached</h3><ol><li>redis数据类型丰富，memcached只支持string；</li><li>redis支持数据持久化，可以在宕机、重启之后进行数据恢复。memcached只能存储在内存；</li><li>redis原生支持集群cluster，memcached没有原生集群模式；</li><li>redis使用单线程的IO多路复用模型，memcached是<strong>多线程</strong>、非阻塞的IO复用的网络模型。redis6也使用了多线程IO</li></ol><hr><h3 id="redis删除过期key：定期删除-惰性删除"><a href="#redis删除过期key：定期删除-惰性删除" class="headerlink" title="redis删除过期key：定期删除+惰性删除"></a>redis删除过期key：定期删除+惰性删除</h3><ul><li><p>定期删除（redis默认100ms）</p><p>redis默认每隔100ms就<strong>随机抽取</strong>一些设置了过期时间的key，检查并删除。</p><blockquote><p>随机抽取的原因：如果key数量巨大，每隔100ms遍历所有设置过期时间的key，可能严重增大CPU的负载。</p></blockquote></li><li><p>惰性删除</p><p>redis的定期删除可能导致一些key没有及时删除。如果一个key已经过期但还留在内存，只有查到了这个key，这个key才会被删除。</p></li></ul><p>如果redis的定期删除漏掉了很多过期的key，并且没有及时查这些key，就会浪费内存。解决这个问题就需要<strong>redis内存淘汰机制</strong>。</p><hr><h2 id="redis内存淘汰机制"><a href="#redis内存淘汰机制" class="headerlink" title="redis内存淘汰机制"></a>redis内存淘汰机制</h2><blockquote><p> 数据库中有2000w数据，redis中只存20w数据，如何保证redis中的数据是热点数据？</p></blockquote><h3 id="8种数据淘汰策略："><a href="#8种数据淘汰策略：" class="headerlink" title="8种数据淘汰策略："></a>8种数据淘汰策略：</h3><p>当内存不足以容纳新写入数据时，</p><ol><li>volatile-lru   <code>从 已设置ex的数据集中 移除 最近最少使用的key</code></li><li>volatile-random   <code>从 已设置ex的数据集中 移除 随机key</code></li><li>volatile-lfu   <code>从 已设置ex的数据集中 移除 最不经常使用的 key </code></li><li>volatile-ttl   <code>从 已设置ex的数据集中 优先移除有更早过期时间的key </code></li><li>allkeys-lru   <code>从 键空间 移除 最近最少使用的key</code></li><li>allkeys-random   <code>从 键空间 移除 随机key</code></li><li>allkeys-lfu   <code>从 键空间 移除 最不经常使用的 key</code></li><li>no-eviction   <code>禁止淘汰，内存不足直接报错。</code></li></ol><blockquote><p> 注 7、8 为 Redis 4.0 新增。</p><p><strong>volatile</strong>为前缀的策略都是从<strong>已过期的数据集</strong>中进行淘汰。</p><p><strong>allkeys</strong>为前缀的策略都是面向<strong>所有key</strong>进行淘汰。</p><p><strong>LRU</strong>（least recently used）最近最少用到的。</p><p><strong>LFU</strong>（Least Frequently Used）最不常用的。</p></blockquote><hr><h2 id="持久化机制-保证重启后数据可恢复"><a href="#持久化机制-保证重启后数据可恢复" class="headerlink" title="持久化机制 保证重启后数据可恢复"></a>持久化机制 保证重启后数据可恢复</h2><p>redis支持持久化，这是redis不同于memcached很重要的一点。</p><h3 id="1-快照-snapshotting-（RDB）（默认）"><a href="#1-快照-snapshotting-（RDB）（默认）" class="headerlink" title="1. 快照 snapshotting （RDB）（默认）"></a>1. 快照 snapshotting （RDB）（默认）</h3><p>在redis.conf中有如下配置</p><pre><code class="hljs properties"><span class="hljs-attr">save</span> <span class="hljs-string">900 1#在900s(15min)之后，至少1个key发生变化，自动触发BGSAVE命令创建快照</span><span class="hljs-attr">save</span> <span class="hljs-string">300 10#在300s(5min)之后，至少10个key发生变化，snapshot</span><span class="hljs-attr">save</span> <span class="hljs-string">60 10000#在60s(1min)之后，至少1w个key发生变化，snapshot</span></code></pre><h3 id="2-追加文件-append-only-（AOF）"><a href="#2-追加文件-append-only-（AOF）" class="headerlink" title="2. 追加文件 append-only （AOF）"></a>2. 追加文件 append-only （AOF）</h3><blockquote><p>特点：实时性，数据全</p></blockquote><h5 id="开启AOF"><a href="#开启AOF" class="headerlink" title="开启AOF"></a>开启AOF</h5><p>在redis.conf中配置<code>appendonly yes</code></p><blockquote><p>开启AOF之后，redis会将每条会更改redis中的数据的命令写入硬盘的aof文件，aof文件位置和rdb文件相同，通过dir参数设置，默认文件名是<code>appendonly.aof</code>。</p></blockquote><h5 id="三种不同的AOF方式："><a href="#三种不同的AOF方式：" class="headerlink" title="三种不同的AOF方式："></a>三种不同的AOF方式：</h5><p>在redis.conf中</p><pre><code class="hljs properties"><span class="hljs-attr">appendfsync</span> <span class="hljs-string">always# 每次发生数据修改都会写入AOF，(严重降低redis的速度)</span><span class="hljs-attr">appendfsync</span> <span class="hljs-string">everysec# 每秒同步一次</span><span class="hljs-attr">appendfsync</span> <span class="hljs-string">no# 由操作系统决定何时同步</span></code></pre><h3 id="3-混合持久化-RDB-AOP"><a href="#3-混合持久化-RDB-AOP" class="headerlink" title="3. 混合持久化 RDB+AOP"></a>3. 混合持久化 RDB+AOP</h3><blockquote><p>4.0开始支持， 默认关闭。 通过配置项  <code>aof-use-rdb-preamble</code>  开启。</p></blockquote><p>混合持久化在AOF重写的时候把RDB的内容写入到aof文件的开头。</p><blockquote><p>优点：重启之后恢复加载更快，避免丢失过多数据</p><p>缺点：aof文件中的rdb部分的压缩格式不再是aof格式，可读性差，aof文件可能过大。</p></blockquote><p>在执行GBREWRITEAOF命令时，redis服务器维护一个aof重写缓冲区，并开启一个子进程<strong>重写AOF</strong>，在子进程工作期间，将所有命令记录到缓冲区，当子进程创建完aof文件之后，将缓冲区的内容追加到新aof文件末尾，使新aof文件和数据库状态一致，最后用新aof文件替换旧aof文件。</p><blockquote><p>命令：<code>BGREWRITEAOF</code>  <code>bgrewriteaof</code></p><p>解决AOF文件体积过大的问题，用户可以使用这个命令让redis重写aof文件（手动rewrite）。</p></blockquote><h5 id="重写AOF-压缩AOF：（目的是减小AOF文件体积）（手动触发、自动触发）"><a href="#重写AOF-压缩AOF：（目的是减小AOF文件体积）（手动触发、自动触发）" class="headerlink" title="重写AOF/压缩AOF：（目的是减小AOF文件体积）（手动触发、自动触发）"></a>重写AOF/压缩AOF：（目的是减小AOF文件体积）（手动触发、自动触发）</h5><blockquote><p>aof文件会越来越大，aof重写是<strong>从redis服务器中的数据</strong>转化为写命令存到新的aof文件中，<strong>不会读旧的aof文件</strong>，所以<strong>过期的数据不再写入aof</strong>，<strong>无效的命令不再写入aof</strong>，<strong>多条命令可能合并成一个（注）</strong>。</p><blockquote><p><strong>注</strong></p><p>不过为了<strong>防止单条命令过大</strong>造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令；而是以某个常量为界将命令拆分为多条。这个常量的配置为</p><p><code>define REDIS_AOF_REWRITE_ITEMS_PER_CMD 64</code></p></blockquote></blockquote><hr><h3 id="AOF配置"><a href="#AOF配置" class="headerlink" title="AOF配置"></a>AOF配置</h3><pre><code class="hljs properties"><span class="hljs-comment">#是否开启AOF</span><span class="hljs-attr">appendonly</span> <span class="hljs-string">no </span><span class="hljs-comment">#AOF文件名</span><span class="hljs-attr">appendfilename</span> <span class="hljs-string">&quot;appendonly.aof&quot;</span><span class="hljs-comment">#RDB文件和AOF文件所在目录</span><span class="hljs-attr">dir</span> <span class="hljs-string">./</span><span class="hljs-comment">#fsync持久化策略</span><span class="hljs-attr">appendfsync</span> <span class="hljs-string">everysec</span><span class="hljs-comment">#AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡</span><span class="hljs-meta">no-appendfsync-on-rewrite</span> <span class="hljs-string">no</span><span class="hljs-comment">#如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件</span><span class="hljs-meta">aof-load-truncated</span> <span class="hljs-string">yes</span><span class="hljs-comment">#执行AOF重写时，文件的最小体积，默认值为64MB。文件重写触发条件之一</span><span class="hljs-meta">auto-aof-rewrite-percentage</span> <span class="hljs-string">100</span><span class="hljs-comment">#执行AOF重写时，当前AOF大小(即aof_current_size)和上一次重写时AOF大小(aof_base_size)的比值。文件重写触发条件之一</span><span class="hljs-meta">auto-aof-rewrite-min-size</span> <span class="hljs-string">64mb</span><span class="hljs-comment">#只有当auto-aof-rewrite-min-size和auto-aof-rewrite-percentage两个参数同时满足时，才会自动触发AOF重写，即bgrewriteaof操作。</span></code></pre><h2 id="缓存穿透、缓存击穿、缓存雪崩"><a href="#缓存穿透、缓存击穿、缓存雪崩" class="headerlink" title="缓存穿透、缓存击穿、缓存雪崩"></a>缓存穿透、缓存击穿、缓存雪崩</h2><p>穿透  <code>同时大量请求一个不存在的key</code></p><p>击穿  <code>同时大量请求一个存在但是失效的key，这个key失效</code></p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><blockquote><p>一个<strong>不存在</strong>的key，缓存不会起作用，请求直接打到DB，如果流量大，DB危险</p></blockquote><p>解决方案：</p><blockquote><ol><li><p>严格参数验证。例如id&lt;0直接拦截。</p></li><li><p>如果DB查询key也不存在，就缓存key=null,expires=较短时间。可以防止用这个id反复请求的暴力攻击。</p></li><li><p>根据业务情况，使用<strong>布隆过滤器</strong>，如果key根本不可能存在，直接拦截。</p><p>3+2更安全，因为布隆过滤器有一定误判率，只能说key可能存在。</p></li></ol></blockquote><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><blockquote><p>一个<strong>存在</strong>的key，在缓存过期的一刻，同时大量请求这个key，这些请求都会打到DB</p></blockquote><p>解决方案：</p><blockquote><ol><li><p>设置热点数据永不过期（因为大量请求说明可能是热点数据）。</p></li><li><p>加锁。</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> V <span class="hljs-title">getData</span><span class="hljs-params">(K key)</span> <span class="hljs-keyword">throws</span> InterruptException </span>&#123;    V v = getDataFromCache(key);    <span class="hljs-keyword">if</span> (v == <span class="hljs-keyword">null</span>)&#123; <span class="hljs-comment">// cache未命中</span>        <span class="hljs-keyword">if</span> (reentrantLock.tryLock())&#123; <span class="hljs-comment">// 获取DB锁，如果能细化到key更好</span>            <span class="hljs-keyword">try</span> &#123;                v = getDataFromDB(key);                <span class="hljs-keyword">if</span> (v != <span class="hljs-keyword">null</span>) &#123; <span class="hljs-comment">// DB中有数据</span>                    setDataToCache(key, v); <span class="hljs-comment">// 同步到cache </span>                &#125; <span class="hljs-keyword">else</span> &#123;                    <span class="hljs-comment">//如果key不存在,并且请求也很多,都走这个同步可能服务超时,不同步可能会缓存穿透,可以在cache设置key=null,expires=30s.</span>                &#125;            &#125; <span class="hljs-keyword">finally</span> &#123; <span class="hljs-comment">// 释放锁</span>                reentrantLock.unlock();            &#125;        &#125; <span class="hljs-keyword">else</span> &#123; <span class="hljs-comment">// 拿不到锁就过一会重新拿</span>            Thread.sleep(<span class="hljs-number">1000</span>);            v = getData(key);        &#125;    &#125;    <span class="hljs-keyword">return</span> v;&#125;</code></pre></li></ol></blockquote><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><blockquote><p>缓存中的数据<strong>同时大面积失效</strong>，就会有大量请求打到数据库</p></blockquote><p>解决方案：</p><blockquote><ol><li>热点数据永不过期</li><li>失效时间设置随机</li></ol></blockquote><p>具体：</p><p>事前：保证redis集群的高可用，发现宕机尽快补。</p><p>事发：本地缓存+hystrix限流&amp;服务降级，保证DB正常运行</p><p>事后：利用持久化机制尽快恢复缓存</p><hr><h2 id="数据类型-命令操作-实际用例"><a href="#数据类型-命令操作-实际用例" class="headerlink" title="数据类型-命令操作-实际用例"></a>数据类型-命令操作-实际用例</h2><h3 id="常用通用命令"><a href="#常用通用命令" class="headerlink" title="常用通用命令"></a>常用通用命令</h3><ul><li><p><strong>del</strong>、<strong>exists</strong>、<strong>type</strong></p></li><li><p>redis <strong>expires</strong></p><p>在redis中添加元素的时候设置过期时间：set key value 存活时间</p></li><li><p><strong>expire</strong>  重新设置key的存活时间</p></li><li><p><strong>persist</strong> 去掉一个key的过期时间，使之成为持久化key</p></li><li><p><strong>ttl</strong>  以秒为单位，返回 key 的剩余生存时间</p></li><li><p><strong>rename</strong> 对一个key改名，之后存活时间继续计时</p></li><li><p><strong>setnx</strong>  不存在就插入</p></li></ul><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><h4 id="string"><a href="#string" class="headerlink" title="string"></a>string</h4><p>​    set、mset、get、mget、getset、strlen</p><p>​    incr、incrby、decr、decrby  （原子增量）</p><p>​    setbit、getbit、bitcount、bitop  （位图）</p><p>位图不是实际的数据类型，而是在字符串类型上定义的一组面向位的操作，最大512M，所以最多存储2^32^位</p><h4 id="list"><a href="#list" class="headerlink" title="list"></a>list</h4><ol><li><p>lpush、rpush、lpop、rpop</p><blockquote><p>用例：BlockingQueue，如果list为空，pop会直接返回null，不会完成其他任何工作。</p></blockquote></li><li><p>llen  查看list中元素的个数</p></li><li><p>lrange –遍历get</p><p>需要两个索引，要返回的范围的第一个和最后一个元素。两个索引都可以为负，-1是列表的最后一个元素，-2是列表的倒数第二个元素，依此类推。</p><pre><code class="hljs tcl">&gt; rpush mylist <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span> <span class="hljs-string">&quot;foo bar&quot;</span>(integer) <span class="hljs-number">9</span>&gt; <span class="hljs-keyword">lrange</span> mylist <span class="hljs-number">0</span> <span class="hljs-number">-1</span><span class="hljs-number">1</span>) <span class="hljs-string">&quot;first&quot;</span><span class="hljs-number">2</span>) <span class="hljs-string">&quot;A&quot;</span><span class="hljs-number">3</span>) <span class="hljs-string">&quot;B&quot;</span><span class="hljs-number">4</span>) <span class="hljs-string">&quot;1&quot;</span><span class="hljs-number">5</span>) <span class="hljs-string">&quot;2&quot;</span><span class="hljs-number">6</span>) <span class="hljs-string">&quot;3&quot;</span><span class="hljs-number">7</span>) <span class="hljs-string">&quot;4&quot;</span><span class="hljs-number">8</span>) <span class="hljs-string">&quot;5&quot;</span><span class="hljs-number">9</span>) <span class="hljs-string">&quot;foo bar&quot;</span></code></pre></li><li><p>ltrim –修剪</p><p>仅从索引0到2列出元素，其他的都丢弃。</p><blockquote><p>用例：lpush并ltrim 0 99，添加新元素并丢弃超出范围的元素。</p></blockquote></li><li><p>brpop、blpop</p><p>按照参数中的list的顺序pop完list1的元素再pop list2中的元素，如果都为空，就阻塞等待n秒，n秒内如果list中有了元素就返回，否则就返回nil</p><pre><code class="hljs apache"><span class="hljs-attribute">blpop</span> list<span class="hljs-number">1</span> list<span class="hljs-number">2</span> list<span class="hljs-number">3</span>... n秒</code></pre><pre><code class="hljs accesslog"><span class="hljs-number">127.0.0.1:7963</span>&gt; brpop list1 list2 <span class="hljs-number">5</span>(nil)(<span class="hljs-number">5</span>.06s)</code></pre></li><li><p>lpoprpush   转移列表的数据</p><pre><code class="hljs apache"><span class="hljs-attribute">rpoplpush</span> list<span class="hljs-number">1</span> list<span class="hljs-number">2</span></code></pre></li><li><p>linsert       插入到指定位置 </p><pre><div class="caption"><span>list1 before/after a v```  在a前边插入一个v，返回新len，如果a不存在返回-1</span></div><code class="hljs linsert">8. 常见用例 及 问题+解决方案   - 用户的最新动态（最近5、10条）   - 队列（不安全）9. **注意**   &gt; 因为不能对集合中每项都设置TTL，但是可以对整个集合设置TTL。**所以，我们可以将每个时间段的数据放在一个集合中。然后对这个集合设置过期时间。**#### hash字典 field-value命令：hset hget hmset hmget hgetall hexists hsetnx </code></pre><blockquote><p>hmset user:1000 username antirez birthyear 1977 verified 1<br>OK<br>hget user:1000 username<br>“antirez”<br>hget user:1000 birthyear<br>“1977”<br>hgetall user:1000</p></blockquote></li></ol><ol><li>“username”</li><li>“antirez”</li><li>“birthyear”</li><li>“1977”</li><li>“verified”</li><li>“1”<blockquote><p>hmget user:1000 username birthyear no-such-field</p></blockquote></li><li>“antirez”</li><li>“1977”</li><li>(nil)<blockquote><p>hincrby user:1000 birthyear 10<br>(integer) 1987<br>hincrby user:1000 birthyear 10<br>(integer) 1997</p></blockquote><pre><code class="hljs haml">#### set-<span class="ruby"> sadd、spop</span><span class="ruby">- sismember  是否存在  返回<span class="hljs-number">1</span>/<span class="hljs-number">0</span></span><span class="ruby">- smembers   所有元素</span><span class="ruby">- srandmember  随机n个元素    <span class="hljs-string">``</span><span class="hljs-string">`srandmember key 2`</span><span class="hljs-string">``</span></span><span class="ruby">- sunion   并集</span></code></pre><blockquote><p>sadd myset 1 2 3<br>(integer) 3<br>smembers myset</p></blockquote></li><li>3</li><li>1</li><li>2<blockquote><p>sismember myset 3<br>(integer) 1<br>sismember myset 30<br>(integer) 0</p></blockquote><pre><code class="hljs tap"><span class="hljs-comment">#### zset  </span>sortedset，增加了权重参数score，使集合中的元素按照score有序排列```shzadd zset<span class="hljs-number"> 1 </span>one  <span class="hljs-comment">#如果one已经存在，就会覆盖原来的分数</span>zadd zset<span class="hljs-number"> 2 </span>two  zadd zset<span class="hljs-number"> 3 </span>threezincrby zset<span class="hljs-number"> 1 </span>one <span class="hljs-comment">#增长分数</span>zscore zset two <span class="hljs-comment">#获取分数</span>zrange zset<span class="hljs-number"> 0 </span>-1 withscores <span class="hljs-comment">#范围遍历</span>zrangebyscore zset<span class="hljs-number"> 10 </span>25 withscores <span class="hljs-comment">#指定范围的值</span>zrangebyscore zset<span class="hljs-number"> 10 </span>25 withscores limit<span class="hljs-number"> 1 </span>2 <span class="hljs-comment">#分页</span>Zrevrangebyscore zset<span class="hljs-number"> 10 </span>25 withscores  <span class="hljs-comment">#指定范围的值</span>zcard zset  <span class="hljs-comment">#元素数量</span>Zcount zset <span class="hljs-comment">#获得指定分数范围内的元素个数</span>Zrem zset one two <span class="hljs-comment">#删除一个或多个元素</span>Zremrangebyrank zset<span class="hljs-number"> 0 </span>1 <span class="hljs-comment">#按照排名范围删除元素</span>Zremrangebyscore zset<span class="hljs-number"> 0 </span>1 <span class="hljs-comment">#按照分数范围删除元素</span>Zrank zset<span class="hljs-number"> 0 </span>-1 <span class="hljs-comment">#分数最小的元素排名为0</span>Zrevrank zset<span class="hljs-number"> 0 </span>-1 <span class="hljs-comment">#分数最大的元素排名为0</span>Zinterstore <span class="hljs-comment">#</span>zunionstore rank:last_week<span class="hljs-number"> 7 </span>rank:20150323 rank:20150324 rank:20150325  weights<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1 1</code></pre></li></ol><h4 id="PFADD"><a href="#PFADD" class="headerlink" title="PFADD"></a>PFADD</h4><h4 id="位图-setbit"><a href="#位图-setbit" class="headerlink" title="位图 setbit"></a>位图 setbit</h4><h4 id="HyperLogLog-hll"><a href="#HyperLogLog-hll" class="headerlink" title="HyperLogLog    hll"></a>HyperLogLog    hll</h4><h2 id="Redis可实现功能"><a href="#Redis可实现功能" class="headerlink" title="Redis可实现功能"></a>Redis可实现功能</h2><h3 id="1-分布式锁"><a href="#1-分布式锁" class="headerlink" title="1.分布式锁"></a>1.分布式锁</h3><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">tryGetDistributedLock</span><span class="hljs-params">(</span></span><span class="hljs-function"><span class="hljs-params">    String lockKey, String requestId, <span class="hljs-keyword">int</span> expireTime)</span> </span>&#123;String result = jedis.set(        <span class="hljs-comment">// key， value为请求id 解锁还需要这个用这个id， setnx 不存在才set， 失效时间</span>        lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime);    <span class="hljs-keyword">if</span> (LOCK_SUCCESS.equals(result)) &#123;        <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;&#125;</code></pre><h3 id="2-附近的人-空间搜索"><a href="#2-附近的人-空间搜索" class="headerlink" title="2.附近的人-空间搜索"></a>2.附近的人-空间搜索</h3><p><a href="https://www.cnblogs.com/ningbj/p/11711875.html">https://www.cnblogs.com/ningbj/p/11711875.html</a></p><blockquote><p>GeoHash是一种地址编码方式。能够把二维空间经纬度数据编码成一个字符串。</p></blockquote><blockquote><pre><code class="hljs sh"><span class="hljs-comment">#geoadd key 经度 纬度 名字 [经度 纬度 名字] ...  返回integer</span>GEOADD key longitude latitude member [longitude latitude member ...]<span class="hljs-comment">#当所需存储的对象数量过多时，可通过设置多key(如一个省一个key)的方式对对象集合变相做sharding，避免单集合数量过多。</span><span class="hljs-comment">#Redis内部使用有序集合(zset)保存位置对象，元素的score值为其经纬度对应的52位的geohash值。</span></code></pre><pre><code class="hljs sh"><span class="hljs-comment">#geopos</span>GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [ASC|DESC] [COUNT count] [STORE key] [STORedisT key]<span class="hljs-comment">#</span></code></pre><pre><code class="hljs sh"><span class="hljs-comment">#geodist</span></code></pre><pre><code class="hljs sh"><span class="hljs-comment">#geohash</span></code></pre><pre><code class="hljs sh"><span class="hljs-comment">#georadius</span></code></pre><pre><code class="hljs sh"><span class="hljs-comment">#georadiusbymember</span></code></pre></blockquote><h3 id="3-位图-签到记录、PV、UV"><a href="#3-位图-签到记录、PV、UV" class="headerlink" title="3.位图-签到记录、PV、UV"></a>3.位图-签到记录、PV、UV</h3><h3 id="4-布隆过滤器-setbit"><a href="#4-布隆过滤器-setbit" class="headerlink" title="4.布隆过滤器 setbit"></a>4.布隆过滤器 setbit</h3><h3 id="5-队列-list-push-pop"><a href="#5-队列-list-push-pop" class="headerlink" title="5.队列 list push pop"></a>5.队列 list push pop</h3><h3 id="6-限流"><a href="#6-限流" class="headerlink" title="6.限流"></a>6.限流</h3><h2 id="集群策略"><a href="#集群策略" class="headerlink" title="集群策略"></a>集群策略</h2><h3 id="1-主从复制"><a href="#1-主从复制" class="headerlink" title="1. 主从复制"></a>1. 主从复制</h3><p>master可以读、写；</p><p>slave只提供读服务，并接受master同步过来的数据。</p><h5 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h5><blockquote><p>slave启动之后发送sync请求到master，master在后台保存快照和保存快照期间的命令，发送给slave。</p></blockquote><h5 id="主从配置"><a href="#主从配置" class="headerlink" title="主从配置"></a>主从配置</h5><p>master无需配置，修改slave节点的配置：</p><pre><code class="hljs properties"><span class="hljs-attr">slaveof</span> <span class="hljs-string">[masterIP] [masterPort]</span><span class="hljs-attr">masterauth</span> <span class="hljs-string">[masterPassword]</span></code></pre><p>连接成功后可以使用<code>info replication</code>查看其他节点的信息</p><h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><p>如果master宕机，不能自动将slave转换成master</p><p><a href="https://www.cnblogs.com/L-Test/p/11626124.html">https://www.cnblogs.com/L-Test/p/11626124.html</a></p><h3 id="2-哨兵模式"><a href="#2-哨兵模式" class="headerlink" title="2. 哨兵模式"></a>2. <span id = "redis-sentinel">哨兵模式</span></h3><p>哨兵模式<strong>sentinel</strong>，比较特殊。哨兵是一个独立的进程，独立运行，他监控多个redis实例。</p><h5 id="工作机制-1"><a href="#工作机制-1" class="headerlink" title="工作机制"></a>工作机制</h5><p>哨兵的功能：</p><ul><li>监控master和slave是否正常运行；</li><li>master出现故障就将slave转化为master；</li><li>多个哨兵互相监控；</li><li>多个哨兵同时监控一个redis</li></ul><h5 id="哨兵和redis之间的通信"><a href="#哨兵和redis之间的通信" class="headerlink" title="哨兵和redis之间的通信"></a>哨兵和redis之间的通信</h5><p><a href="https://blog.csdn.net/q649381130/article/details/79931791">https://blog.csdn.net/q649381130/article/details/79931791</a></p><h5 id="故障切换过程"><a href="#故障切换过程" class="headerlink" title="故障切换过程"></a>故障切换过程</h5><p>如果被ping的节点超时未回复，哨兵认为其<strong>主观下线</strong>，如果是master下线，哨兵会询问其他哨兵是否也认为该master<strong>主观下线</strong>，如果达到（配置文件中的）quorum个投票，哨兵会认为该master<strong>客观下线</strong>，并选举领头哨兵节点发起故障恢复。</p><h6 id="选举领头哨兵-raft算法"><a href="#选举领头哨兵-raft算法" class="headerlink" title="选举领头哨兵 raft算法"></a>选举领头哨兵 raft算法</h6><blockquote><p>发现master下线的A节点像其他哨兵发送消息要求选自己为领头哨兵</p><p>如果目标节点没有选过其他人（没有接收到其他哨兵的相同要求），就选A为领头哨兵</p><p>若超过一半的哨兵同意选A为领头，则A当选</p><p>如果多个哨兵同时参与了领头，可能一轮投票无人当选，A就会等待随机事件后再次发起请求</p></blockquote><p>选出新master之后，会发送消息到其他slave使其接受新master，最后更新数据。已停止的旧master会降为slave，恢复服务之后继续运行。</p><h6 id="领头哨兵挑选新master的规则"><a href="#领头哨兵挑选新master的规则" class="headerlink" title="领头哨兵挑选新master的规则"></a>领头哨兵挑选新master的规则</h6><blockquote><p>优先级最高（slave-priority配置）</p><p>复制偏移量最大</p><p>id最小</p></blockquote><h5 id="哨兵配置-sentinel-conf"><a href="#哨兵配置-sentinel-conf" class="headerlink" title="哨兵配置  sentinel.conf"></a>哨兵配置  sentinel.conf</h5><pre><code class="hljs properties"><span class="hljs-comment"># 设置主机名称 地址 端口 选举所需票数</span><span class="hljs-attr">sentinel</span> <span class="hljs-string">monitor [master-name] [ip] [port] [quorum]</span><span class="hljs-comment"># demo</span><span class="hljs-attr">sentinel</span> <span class="hljs-string">monitor mymaster 192.168.0.107 6379 1</span></code></pre><h5 id="启动哨兵节点"><a href="#启动哨兵节点" class="headerlink" title="启动哨兵节点"></a>启动哨兵节点</h5><pre><code class="hljs sh">bin/redis-server etc/sentinel.conf --sentinel &amp;</code></pre><h5 id="查看指定哨兵节点信息"><a href="#查看指定哨兵节点信息" class="headerlink" title="查看指定哨兵节点信息"></a>查看指定哨兵节点信息</h5><pre><code class="hljs sh"><span class="hljs-comment">#可以在任何一台服务器上查看指定哨兵节点信息：</span>bin/redis-cli -h 192.168.0.110 -p 26379 info Sentinel</code></pre><h3 id="3-集群-cluster"><a href="#3-集群-cluster" class="headerlink" title="3. 集群 cluster"></a>3. 集群 cluster</h3><p>官方推荐集群至少要3台以上master，最好3master 3slave。</p><h5 id="配置-redis-conf"><a href="#配置-redis-conf" class="headerlink" title="配置 redis.conf"></a>配置 redis.conf</h5><pre><code class="hljs properties"><span class="hljs-comment">#开启cluster模式</span><span class="hljs-meta">cluster-enable</span> <span class="hljs-string">yes</span><span class="hljs-comment">#集群模式下的集群配置文件</span><span class="hljs-meta">cluster-config-file</span> <span class="hljs-string">nodes-6379.conf</span><span class="hljs-comment">#集群内节点之间最长响应时间</span><span class="hljs-meta">cluster-node-timeout</span> <span class="hljs-string">15000</span></code></pre><p>启动6个redis-server，可以借助ruby，或者自己写群起脚本</p><h5 id="工作机制-2"><a href="#工作机制-2" class="headerlink" title="工作机制"></a>工作机制</h5><p>对key进行【crc16算法】【%16384】的操作，通过计算结果找到对应插槽所对应的节点，然后直接跳转到这个基点进行存取操作。</p><p>为了保证高可用，使用主从模式。master宕机，启用slave。如果一个节点的主从都宕机，则集群不可用。</p><h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><ul><li>所有redis节点彼此互联（PING-PONG机制），使用二进制协议优化传输速度和带宽</li><li>集群中超过半数的节点检测失效才认为节点fail</li><li>redic-cil与节点直连，不需要中间代理层，任意连接集群中一个可用节点即可。</li></ul><h2 id="整合SpringCache"><a href="#整合SpringCache" class="headerlink" title="整合SpringCache"></a>整合SpringCache</h2><p>配置，在dao代码加注解实现</p><h2 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h2><pre><code class="hljs arduino">localhost:<span class="hljs-number">6379</span>&gt; config get <span class="hljs-keyword">auto</span>-aof-rewrite-min-size<span class="hljs-number">1</span>)<span class="hljs-string">&quot;auto-aof-rewrite-min-size&quot;</span><span class="hljs-number">2</span>)<span class="hljs-string">&quot;67108864&quot;</span></code></pre><pre><code class="hljs apache"><span class="hljs-attribute">localhost</span>:<span class="hljs-number">6379</span>&gt; info persistence<span class="hljs-attribute">1</span>) aof_current_size:<span class="hljs-number">149</span><span class="hljs-attribute">2</span>) aof_base_size:<span class="hljs-number">149</span></code></pre><h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p><a href="https://www.cnblogs.com/demingblog/p/9542124.html">https://www.cnblogs.com/demingblog/p/9542124.html</a></p><p>问题 不能释放别人的锁</p><p>场景：</p><p>A 拿到锁并执行业务逻辑，但是太慢了 锁超时自动释放并由B拿到，然后A执行完毕， 想要释放锁。</p><blockquote><p>如果锁不加区分，A会释放B拿到的锁，  可能会有其他线程 加锁成功， 与B冲突！</p><p>所以需要为锁添加持有人属性。   可以get(lockKey) ， if = 当前执行人(如 threadId),  释放锁， 否则 说明自己执行超时了， 考虑回滚</p></blockquote><h1 id="Lua-脚本-原子执行"><a href="#Lua-脚本-原子执行" class="headerlink" title="Lua 脚本 原子执行"></a>Lua 脚本 原子执行</h1><p>Lua 脚本在 Redis 中是原子执行的，Redis 在执行<code>EVAL</code>命令的时候，一直到执行完毕并返回结果之前，会阻塞所有其他客户端的命令，so Lua脚本中要写逻辑特别复杂的脚本， 必须保证 Lua 脚本的效率。</p><h4 id="SCRIPT-LOAD"><a href="#SCRIPT-LOAD" class="headerlink" title="SCRIPT LOAD"></a>SCRIPT LOAD</h4><p>加载脚本到缓存，以复用</p><pre><code class="hljs jboss-cli"><span class="hljs-string">...</span><span class="hljs-function">:6379</span>&gt; SCRIPT LOAD <span class="hljs-string">&quot;return &#x27;abc&#x27;&quot;</span>“1b936e3fe509bcbc9<span class="hljs-keyword">cd</span>0664897bbe8fd0cac101b”<span class="hljs-string">...</span><span class="hljs-function">:6379</span>&gt; EVALSHA 1b936e3fe509bcbc9<span class="hljs-keyword">cd</span>0664897bbe8fd0cac101b 0<span class="hljs-string">&quot;abc&quot;</span></code></pre><h4 id="SCRIPT-FLUSH"><a href="#SCRIPT-FLUSH" class="headerlink" title="SCRIPT FLUSH"></a>SCRIPT FLUSH</h4><p>清除所有缓存， 不能筛选， 只能全删</p><h4 id="SCRIPT-EXISTS"><a href="#SCRIPT-EXISTS" class="headerlink" title="SCRIPT EXISTS"></a>SCRIPT EXISTS</h4><pre><code class="hljs jboss-cli"><span class="hljs-string">...</span><span class="hljs-function">:6379</span>&gt; SCRIPT EXISTS 1b936e3fe509bcbc9<span class="hljs-keyword">cd</span>0664897bbe8fd0cac101b  1b936e3fe509bcbc9<span class="hljs-keyword">cd</span>0664897bbe8fd0cac10121) <span class="hljs-params">(integer)</span> 12) <span class="hljs-params">(integer)</span> 0</code></pre><h4 id="SCRIPT-KILL"><a href="#SCRIPT-KILL" class="headerlink" title="SCRIPT KILL"></a>SCRIPT KILL</h4><p>终止正在执行的脚本，如果脚本中已经执行了一部分写命令，则 kill 命令无效</p><p>若不对数据进行持久化， 可通过 shutdown nosave 来终止脚本…</p><h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><ul><li>Lua 脚本执行异常也不会回滚， 所以脚本逻辑要有较高的健壮性</li><li>Lua 脚本执行是原子性的，会阻塞其他客户端的命令，所有效率要高</li><li>在集群中使用 Lua 脚本的话要确保脚本中用到的 key 都在相同机器(相同的插槽slot)中，可用 Redis Hash Tags 技术</li><li>不要在脚本中用全局变量， 局部变量效率会高</li></ul><h5 id="Lua脚本-释放锁"><a href="#Lua脚本-释放锁" class="headerlink" title="Lua脚本 释放锁"></a>Lua脚本 释放锁</h5><pre><code class="hljs lua"><span class="hljs-keyword">if</span> redis.call(<span class="hljs-string">&#x27;get&#x27;</span>, KEYS[<span class="hljs-number">1</span>]) == ARGV[<span class="hljs-number">1</span>]     <span class="hljs-keyword">then</span>     <span class="hljs-keyword">return</span> redis.call(<span class="hljs-string">&#x27;del&#x27;</span>, KEYS[<span class="hljs-number">1</span>]) <span class="hljs-keyword">else</span>     <span class="hljs-keyword">return</span> <span class="hljs-number">0</span> <span class="hljs-keyword">end</span></code></pre><h5 id="java实现"><a href="#java实现" class="headerlink" title="java实现"></a>java实现</h5><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> Long lockReleaseOK = <span class="hljs-number">1L</span>;<span class="hljs-comment">// lua脚本，用来释放分布式锁</span><span class="hljs-keyword">static</span> String luaScript = <span class="hljs-string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;,KEYS[1]) else return 0 end&quot;</span>; <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">releaseLock</span><span class="hljs-params">(String key ,String lockValue)</span></span>&#123;<span class="hljs-keyword">if</span>(key == <span class="hljs-keyword">null</span> || lockValue == <span class="hljs-keyword">null</span>) &#123;<span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;&#125;<span class="hljs-keyword">try</span> &#123;Jedis jedis = getJedisPool().getResource();Object res =jedis.eval(luaScript,Collections.singletonList(key),Collections.singletonList(lockValue));jedis.close();<span class="hljs-keyword">return</span> res!=<span class="hljs-keyword">null</span> &amp;&amp; res.equals(lockReleaseOK);&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;&#125;&#125;</code></pre><h1 id="还可能有问题！"><a href="#还可能有问题！" class="headerlink" title="还可能有问题！"></a>还可能有问题！</h1><p>上述做法看似完美实现了分布式锁功能。但只限 Redis 单点的情况！</p><p>如果是在<a href="#redis-sentinel">redis sentinel 集群</a>中, A 拿到锁 <code>set lockKey lockValue</code>命令只在 master 节点执行完成，还没有同步到 slave 的时候， master 挂了，集群将重新选举 master ， 然后 B 再试图拿锁， 也会成功。  这就出错了…   </p><p>这种情况发生概率极小， 但总有不能容忍这个瑕疵的系统。</p><h3 id="解决-redlock"><a href="#解决-redlock" class="headerlink" title="解决 - redlock"></a>解决 - redlock</h3><p>redlock算法 ， 用于多个 redis 实例的场景， </p><p>加锁的时候 向多半的节点发送 <code>setnx lockKey lockValue</code> 命令， 过半节点成功才算加锁成功；</p><p>释放锁的时候 向全部节点发送 <code>del</code> 命令。</p><blockquote><p>这是一种基于【大多数都同意】的一种机制</p></blockquote><p>已有的开源实现：</p><p>python: redlock-py</p><p>java: redission</p><h1 id="Redisson"><a href="#Redisson" class="headerlink" title="Redisson"></a>Redisson</h1><p>实现分布式锁</p><p>开源的 看源码去吧</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
