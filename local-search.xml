<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/04/05/0_todo_Java_JUC/"/>
    <url>/blog/2021/04/05/0_todo_Java_JUC/</url>
    
    <content type="html"><![CDATA[<p>Java线程池</p><p>java.util.concurrent包下</p><p>Executor</p><p>ExecutorService</p><p>AbstractExecutorService</p><p>ThreadPoolExecutor</p><p>静态工具类Executors</p><p>拒绝策略</p><blockquote><p>Abolicy</p></blockquote><p>执行原理 直接看代码</p><p>使用线程池的例子</p><p>netty的EventLoop、EventLoopGroup</p><p>阻塞队列</p><p>java.util.concurrent</p><p><img src="https://i.loli.net/2021/04/02/1sVvczI6hmJY3oN.png"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>一致性hash</title>
    <link href="/blog/2021/01/01/0_todo_Basics_%E4%B8%80%E8%87%B4%E6%80%A7hash/"/>
    <url>/blog/2021/01/01/0_todo_Basics_%E4%B8%80%E8%87%B4%E6%80%A7hash/</url>
    
    <content type="html"><![CDATA[<h1 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h1><p><a href="https://blog.csdn.net/cywosp/article/details/23397179">https://blog.csdn.net/cywosp/article/details/23397179</a></p><p>哈希算法<code>Hash</code>，也叫摘要算法<code>Digest</code></p><blockquote><p>输入一组任意长度的数据，计算得到一个固定长度的摘要数据。</p></blockquote><pre><code class="hljs applescript">java中重写<span class="hljs-keyword">equals</span>()方法,为什么要重写hashCode()?如果只是重写<span class="hljs-keyword">equals</span>(), <span class="hljs-keyword">equals</span>()=<span class="hljs-literal">true</span>，但hashCode()==<span class="hljs-literal">false</span>,这有悖于<span class="hljs-keyword">equals</span>()和hashCode()方法的关系，以及hashCode的规则:两个对象相等，hashcode一定相等两个对象不等，hashcode不一定不等hashcode相等，两个对象不一定相等hashcode不等，两个对象一定不等Object<span class="hljs-comment">#hashCode是用对象的内存地址作为哈希算法的输入，所以重写hashCode()时要用对象的属性值作为入参</span></code></pre><p>哈希碰撞，也就是会产生两个对象不等，hashCode可能相等的情况。这种情况不能避免，毕竟哈希算法是把一个无限的输入集合映射到有限的输出集合。</p><table><thead><tr><th>常用的哈希算法</th><th>输出bit长度</th><th>输出byte长度</th></tr></thead><tbody><tr><td>MD5</td><td>128bits</td><td>16bytes</td></tr><tr><td>RipeMD-160</td><td>160bits</td><td>20</td></tr><tr><td>SHA-1</td><td>160bits</td><td>20</td></tr><tr><td>SHA-256</td><td>256bits</td><td>32</td></tr><tr><td>SHA-512</td><td>512bits</td><td>64</td></tr></tbody></table><p>java中的hash算法：<a href="https://docs.oracle.com/en/java/javase/14/docs/specs/security/standard-names.html#messagedigest-algorithms">https://docs.oracle.com/en/java/javase/14/docs/specs/security/standard-names.html#messagedigest-algorithms</a></p><p>想要破解哈希算法，只能暴力穷举，想要提高穷举效率可以用<strong>彩虹表</strong></p><blockquote><p>彩虹表攻击：提前把一些常见的值生成hashCode存储起来，拿到要破解的hashCode之后先从表里查一遍，这就可能直接拿到该明文。</p></blockquote><p>解决的办法也就是加盐了。计算hashCode时入参添加salt，并且可以进行n次哈希计算。</p><h1 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h1><p>一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：</p><blockquote><ol><li>平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</li><li>单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他(已失效)缓冲区。 </li><li>分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 </li><li>负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</li></ol></blockquote><p>在P2P环境、分布式环境中若使用常见的<code>hash(object)%N</code>算法来分配数据的存储位置，那么在有机器宕机或者删除后，很多原有的数据就无法找到了，这严重的违反了单调性原则。</p><h4 id="环形hash空间"><a href="#环形hash空间" class="headerlink" title="环形hash空间"></a>环形hash空间</h4><p>用常用的hash算法，会得到一个固定长度的数，比如<code>CRC-16</code>产生的hash值是16bit，那么就有 2^16 = 65536 个值，</p><p>将这65536个值连成一个环形，就形成了一个hash环，有65536个hash槽。</p><blockquote><p>比如redis的hash槽数量是16384，没用65536是因为节点之间ping-pong消息需要携带节点配置信息，节点越多消息体内容就越大。而节点应该不会超过1000，所以综合考虑使用了16384。</p></blockquote><p>把所有机器的标识（id/唯一标识）进行hash得到环上的一点。</p><p>在计算数据要分配到哪个节点的时候，对这个数据进行hash，也得到环上的一点，然后只需要确定一个规则（比如把这个数据放在顺时针方向离它最近的一个hash槽）就能将这些数据分配到集群中的节点（机器）。</p><h4 id="节点宕机-删除节点"><a href="#节点宕机-删除节点" class="headerlink" title="节点宕机/删除节点"></a>节点宕机/删除节点</h4><p>只需要把这个节点的数据转移到顺时针方向最近的一个节点上。</p><h4 id="节点恢复-添加节点"><a href="#节点恢复-添加节点" class="headerlink" title="节点恢复/添加节点"></a>节点恢复/添加节点</h4><p>只需要把   新增节点-&gt;逆时针方向临近节点   之间所有的数据放到新增节点上。</p><h4 id="机器分布不均匀怎么办？-这算法的分散性怎样得到高分"><a href="#机器分布不均匀怎么办？-这算法的分散性怎样得到高分" class="headerlink" title="机器分布不均匀怎么办？ 这算法的分散性怎样得到高分"></a>机器分布不均匀怎么办？ 这算法的分散性怎样得到高分</h4><p>使用虚拟节点，让一个机器不止对应一个hash槽，比如一个机器对应的hash槽可能是<code>192.168.1.1#1</code> <code>192.168.1.1#2</code> <code>192.168.1.1#3</code>等三个hash槽</p>]]></content>
    
    
    <categories>
      
      <category>basics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>todo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mysql</title>
    <link href="/blog/2021/01/01/0_todo_DB_MySQL/"/>
    <url>/blog/2021/01/01/0_todo_DB_MySQL/</url>
    
    <content type="html"><![CDATA[<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>InnoDB 唯一主键，B+树（只有叶子节点存数据，普通索引的叶子节点不存数据，存的是主键索引，再通过主键索引(聚簇索引树)找到数据就是‘回表’）</p><p>聚簇索引 （InnoDB）</p><p>辅助索引（普通索引）</p><p>联合索引</p><p>InnoDB不支持哈希索引，只有一个自适应哈希索引</p><h3 id="InnoDB自适应哈希索引（Adaptive-Hash-Index，AHI）"><a href="#InnoDB自适应哈希索引（Adaptive-Hash-Index，AHI）" class="headerlink" title="InnoDB自适应哈希索引（Adaptive Hash Index，AHI）"></a>InnoDB自适应哈希索引（Adaptive Hash Index，AHI）</h3><p>一条查询语句如果使用的是普通索引并需要回表，可能会因为无序导致多次随机IO。</p><p>InnoDB监控对表的索引页的查询，如果<strong>满足要求</strong>就会建立哈希索引。</p><p>这个哈希索引是通过缓存中的索引页构建的，而且也是放在buffer poll中，所以速度很快。</p><blockquote><p>查询：<code>show variables like &#39;%ap%hash_index&#39;;</code>      –innodb_adaptive_hash_index</p><p>打开/关闭自适应哈希索引： <code>set global innodb_adaptive_hash_index=off / on</code></p></blockquote><p>哈希索引嘛，特点都一样：只能用等值查询；不能排序；有可能冲突</p><p>要求：<strong>对这个页的访问模式是一样的</strong>。</p><blockquote><p>例如对（a，b）这个联合索引可能会有两种访问模式：A:<code>where a = ?</code>、B:<code>where a = ? and b = ?</code>，</p><p>如果交替进行A、B两种查询，则不会构造AHI；</p><p>必须以下方两种方式访问才会构造AHI。</p><blockquote><ol><li>以A / B模式访问了100次</li><li>页通过某一种模式被访问了<code>rows / 16</code>次</li></ol></blockquote></blockquote><p>自适应哈希索引不可以人为干预，</p><h3 id="索引注意事项"><a href="#索引注意事项" class="headerlink" title="索引注意事项"></a>索引注意事项</h3><ol><li><p>给千万级以上的数据量过大的表添加索引</p><blockquote><p>先把原表结构复制出<code>t_copy</code>，在<code>t_copy</code>中添加索引，然后将原表中的数据导入新表<code>t_copy</code>，然后重命名这两个表</p></blockquote></li><li><p>联合索引设计</p><blockquote><p>常见的一些区分度不大的字段，比如<code>status</code>、<code>sex</code> 等等，在数据量很大的情况下，也可以添加索引，放再联合索引的左侧，不过为了让联合索引能生效，无论是否筛选<code>status</code>、<code>sex</code>都要在where条件语句中添加<code>status = ？ and  sex = ？</code>，如果不需要筛选就用<code>sex in (1,2)</code>即可。视情况而定</p></blockquote></li><li></li></ol><h2 id="mysql缓存：buffer-pool"><a href="#mysql缓存：buffer-pool" class="headerlink" title="mysql缓存：buffer pool"></a>mysql缓存：buffer pool</h2><p>mysql 会在内存中存放： </p><ul><li><p>数据页(sql 必须完全一致才会命中缓存)；</p></li><li><p>索引页；</p></li><li><p>锁信息   lock info；</p></li><li><p>插入缓冲 insert buffer；(B+树实现)（非唯一 &amp; 辅助索引）</p><blockquote><p>对于非聚集索引的insert/update，先判断插入的非聚集索引页是否在缓冲池(缓存)中，若存在则直接插入；若不存在，则先放到insert buffer中，等待<strong>checkpoint</strong>机制将 insert buffer 和 辅助索引页的子节点进行merge；</p><blockquote><p>这通常可以将多个插入合并到一个操作中（因为在一个索引页中），提高了对非聚集索引的插入性能。</p></blockquote></blockquote></li><li><p>undo log；</p></li><li><p>自适应哈希索引 </p></li></ul><blockquote><p>其实mysql在缓存后边写入磁盘也是交给OS，OS还会有一层OS Cache，OS什么时候把cache刷到硬盘可就不知道了。。</p></blockquote><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p>mysql5.7自动就能搞定，相当于分表，而且比分表方便</p><blockquote><h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1></blockquote><h2 id="mysql-后台线程"><a href="#mysql-后台线程" class="headerlink" title="mysql 后台线程"></a>mysql 后台线程</h2><p><code>Master Thread</code>：处理用户查询线程；<del>将缓冲池中的数据刷新回磁盘，保证数据一致性</del>，<del>以及undo页回收(交由Page Cleaner Thread线程)</del>；</p><p><code>IO Thread</code>：负责io请求的回调；(write x4、read x4、insert buffer thread、log IO thread)</p><p><code>Purge Thread</code>：回收已经使用并分配的undo log页；</p><p><code>Page Cleaner Thread</code>：1.2.x版本引入，专门负责脏页刷新回磁盘，减轻master thread压力</p><h2 id="Checkpoint"><a href="#Checkpoint" class="headerlink" title="Checkpoint"></a>Checkpoint</h2><p>把页从缓冲池刷新回磁盘的机制</p><p>作用： 1 缩短数据库的恢复时间；2 缓冲池不够用了就将脏页刷新到磁盘；3 重做日志不可用的时候，刷新脏页</p><h2 id="脏数据-、-脏页"><a href="#脏数据-、-脏页" class="headerlink" title="脏数据 、 脏页"></a>脏数据 、 脏页</h2><p>脏页 是已提交的事务修改的数据更新到内存中，还未<code>fsync</code>到磁盘中；</p><p>脏数据 是其他事务未提交的数据；</p><p>fsync：同步信号</p><h2 id="MVCC-快照机制"><a href="#MVCC-快照机制" class="headerlink" title="MVCC 快照机制"></a>MVCC 快照机制</h2><blockquote><p>多版本并发控制</p></blockquote><p>可以省去锁的开销。</p><p>mvcc的实现就是在每行添加两列（insertTime，deleteTime）</p><p>每个事务在begin的时候会获取当前的系统版本号curTime，</p><ul><li>select：只查询 <code>insertTime &lt;= curTime</code> &amp; <code>deleteTime &gt; curTime</code> 的记录；</li><li>insert：添加一行记录并 <code>set insertTime = curTime</code>；</li><li>delete：对该行 <code>set deleteTime = curTime</code>；</li><li>udpate：新增一条记录，<code>set insertTime = curTime</code>；对之前的记录 <code>set deleteTime = curTime</code></li></ul><h2 id="InnoDB事务的实现"><a href="#InnoDB事务的实现" class="headerlink" title="InnoDB事务的实现"></a>InnoDB事务的实现</h2><p>事务commit时，必须实现将事务的所有日志（redo + undo）写入到日志文件进行持久化。</p><h3 id="redo-log-–-保证事务持久性D"><a href="#redo-log-–-保证事务持久性D" class="headerlink" title="redo log – 保证事务持久性D"></a>redo log – 保证事务持久性D</h3><p>是<strong>物理日志</strong>，存放在日志文件中；恢复提交事务修改的页操作；记录的是页的物理修改操作。</p><ul><li><p>将事务的执行日志<strong>顺序</strong>(基本上都是顺序写)记录下来，数据库运行的时候是不需要读redo log的。</p></li><li><p>每次将重做日志写入到日志文件之后都要调用<code>fsync</code>以确保日志写入磁盘，<code>fsync</code>的效率取决于磁盘性能，所以这等于放大了 磁盘性能对 数据库执行修改操作时的性能 的影响。</p></li></ul><h3 id="undo-log-–-帮助事务进行回滚及MVCC功能"><a href="#undo-log-–-帮助事务进行回滚及MVCC功能" class="headerlink" title="undo log – 帮助事务进行回滚及MVCC功能"></a>undo log – 帮助事务进行回滚及MVCC功能</h3><p>是<strong>逻辑日志</strong>存放在数据库内部的一个<strong>undo段</strong>（<strong>undo segment</strong>，位于共享表空间），回滚行记录到某个特定版本</p><blockquote><p>可通过 py_innodb_page_info.py 工具查看到 <code>undo Log Page: 1234</code></p></blockquote><ul><li><p>事务的回滚就是通过undo log 实现的</p><blockquote><p>比如 事务中执行了 insert，事务回滚的时候就会执行 delete，逻辑取消事务中执行的的修改操作。</p></blockquote><blockquote><p>通过undo log，数据是恢复了，但是数据结构和页本身可能相差很大。（因为不能影响其他事务在这个空间的操作啊）</p><blockquote><p>比如执行 insert 10000条数据，表空间会增大，rollback之后，表空间并不会恢复到原来的大小。</p></blockquote></blockquote></li><li><p>实现MVCC的非锁定读取</p><blockquote><p>当这个事务中读取一行记录，但该记录已经被其他事务占用，则当前事务可以通过undo读取该行之前版本的信息。</p></blockquote></li><li><p>由于undo log也需要持久性保护，所以生成undo log的时候会伴随生成redo log</p><blockquote><p>毕竟undo log也是在表中存的数据，是逻辑日志</p></blockquote></li></ul><h3 id="purge-–-将缓冲池中的数据刷回磁盘时进行merge"><a href="#purge-–-将缓冲池中的数据刷回磁盘时进行merge" class="headerlink" title="purge – 将缓冲池中的数据刷回磁盘时进行merge"></a>purge – 将缓冲池中的数据刷回磁盘时进行merge</h3><p>delete操作可能并不会直接删除原有数据</p><p>因为InnoDB支持MVCC，所以数据不能再事务提交之后就立即处理（其他事务可能也在引用这行数据）。</p><p>在最后purge的时候才会真正完成 delete、update操作，update也是删除之前版本的那‘行’记录</p><h2 id="InnoDB的锁"><a href="#InnoDB的锁" class="headerlink" title="InnoDB的锁"></a>InnoDB的锁</h2><p><code>Record Lock</code>行锁</p><p><code>Gap Lock</code>间隙锁</p><p><code>Next-Key Lock</code>       InnoDB对于行的查询都是采用这个锁定算法</p><blockquote><p>如果筛选条件为<code>where id = 10</code>，id是主键，则不会加间隙锁，Next-Key Lock会降级为Record Lock，只锁定id=10，此时insert id = 9 是不会阻塞的</p></blockquote><h3 id="InnoDB解决幻读："><a href="#InnoDB解决幻读：" class="headerlink" title="InnoDB解决幻读："></a>InnoDB解决幻读：</h3><p>使用 <code>Next-key Lock</code> (<code>Record Lock</code>+<code>Gap Lock</code>)机制</p><blockquote><p>锁定一个范围和该记录本身</p></blockquote><p>幻读就是： (幻象问题)</p><blockquote><p>事务A 执行 <code>select * from user wehre age &gt; 20 for update</code> … 还未完成；</p><p>与此同时 事务B执行<code>insert into user  (...(age=)25...)</code> 并提交 已完成。</p><p>事务A 再次执行<code>select * from user wehre age &gt; 20 for update</code> 会返回刚才事务B插入的数据。</p></blockquote><p>Next-Key Lock 会把范围 <code>age: (20, +∞)</code> 加锁，以至事务B不能执行该insert。</p><p>如果where的是唯一索引 就会在索引上加锁。</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><p>mysql优化器会让小表驱动大表，因为底层也是两次遍历比较，原理相当于两层for循环，如果使用BTree，查找一条数据的时间复杂度=log(n)，所以两种for嵌套的时间复杂度比较如下：</p><blockquote><p>大表.rows * log(小表.rows)      肯定&gt;    小表.rows * log(大表.rows)</p><blockquote><p>B+Tree 的最大深度 log(n)，n:节点数，而且是B+Tree，每次查询肯定都要找到叶子节点。所以肯定是log(n)</p></blockquote></blockquote><p>但要注意，join on 的条件中，两个表的连接字段必须字符集相同&amp;类型相同。否则索引是不会生效的。</p><p>而且join后的sql只有非驱动表的索引会生效。</p><p>left join 左边的表是驱动表，但是驱动表的索引不会生效，比如</p><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/leftjoin%E5%B7%A6%E8%A1%A8%E9%A9%B1%E5%8A%A8%E6%97%A0%E6%95%88.png" style="zoom:50%;" /><h3 id="自连接的应用"><a href="#自连接的应用" class="headerlink" title="自连接的应用"></a>自连接的应用</h3><p>类似排名这种逻辑，可以用自连接来做。比如   <code>某学生在班级中某科目的分数排名</code>   ，自连接的时候用count()看比自己分高的同学的数量即可得到。要注意   <strong>distinct</strong> 去重。</p><blockquote><p>应用：leetcode <a href="https://leetcode-cn.com/problems/department-top-three-salaries/">185. 部门工资前三高的所有员工</a></p></blockquote><pre><code class="hljs mysql">select d.Name Department, e.Name Employee, e.Salary Salaryfrom Employee e left join Department don e.DepartmentId &#x3D; d.Idwhere e.id in (    select e1.Id from Employee e1 left join Employee e2     on e1.DepartmentId &#x3D; e2.DepartmentId and e1.Salary &lt; e2.Salary    group by e1.id    having count(distinct e2.Salary) &lt; 3)and e.DepartmentId in (select DepartmentId from Department)-- 你测试用例来个Department表是空的可太秀了  淦</code></pre><h3 id="数字相关函数"><a href="#数字相关函数" class="headerlink" title="数字相关函数"></a>数字相关函数</h3><p><code>trancate(表达式，保留n位小数)</code>    不会四舍五入</p><p><code>round(表达式，保留n位小数)</code>    会四舍五入</p><blockquote><p>应用：leetcode <a href="https://leetcode-cn.com/problems/trips-and-users/">262. 行程和用</a></p></blockquote><pre><code class="hljs mysql">select Request_at as Day, round(count(if(Status !&#x3D; &#39;completed&#39;, Status, null)) &#x2F; count(Status) , 2) as &quot;Cancellation Rate&quot;from Trips tinner join Users u on t.Client_id &#x3D; u.Users_id and u.Banned &#x3D; &quot;No&quot;inner join Users u2 on t.Driver_id &#x3D; u2.Users_id and u2.Banned &#x3D; &quot;No&quot;and Request_at &lt; &quot;2013-10-04&quot; and Request_at &gt;&#x3D; &quot;2013-10-01&quot;group by Request_at</code></pre><h3 id="总结MySQL查询的一般性思路："><a href="#总结MySQL查询的一般性思路：" class="headerlink" title="总结MySQL查询的一般性思路："></a>总结MySQL查询的一般性思路：</h3><ul><li><p>能用单表优先用单表，即便是需要用group by、order by、limit等，效率一般也比多表高</p></li><li><p>不能用单表时优先用连接，连接是SQL中非常强大的用法，小表驱动大表+建立合适索引+合理运用连接条件，基本上连接可以解决绝大部分问题。但join级数不宜过多，毕竟是一个接近指数级增长的关联效果</p></li><li><p>能不用子查询、笛卡尔积尽量不用，虽然很多情况下MySQL优化器会将其优化成连接方式的执行过程，但效率仍然难以保证</p></li><li><p>自定义变量在复杂SQL实现中会很有用，例如LeetCode中困难级别的数据库题目很多都需要借助自定义变量实现</p></li><li><p>如果MySQL版本允许，某些带聚合功能的查询需求应用窗口函数是一个最优选择。除了经典的获取3种排名信息，还有聚合函数、向前向后取值、百分位等，具体可参考官方指南。以下是官方给出的几个窗口函数的介绍：</p></li></ul><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/mysql8.0-window%20functions.png" style="zoom:67%;" /><p>最后的最后再补充一点，本题将查询语句封装成一个自定义函数并给出了模板，实际上是降低了对函数语法的书写要求和难度，而且提供的函数写法也较为精简。然而，自定义函数更一般化和常用的写法应该是分三步：</p><p>定义变量接收返回值<br>执行查询条件，并赋值给相应变量<br>返回结果</p><h1 id="大大的-TODO"><a href="#大大的-TODO" class="headerlink" title="大大的 TODO"></a>大大的 TODO</h1><h1 id="TiDB"><a href="#TiDB" class="headerlink" title="TiDB"></a>TiDB</h1><p>直接把mysql dump下来，加载到TiDB，非常简单地进行扩容</p><blockquote><h1 id="todo-1"><a href="#todo-1" class="headerlink" title="todo"></a>todo</h1></blockquote><h1 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h1><p><a href="https://blog.csdn.net/J080624/article/details/86476027">https://blog.csdn.net/J080624/article/details/86476027</a></p><blockquote><h1 id="todo-2"><a href="#todo-2" class="headerlink" title="todo"></a>todo</h1></blockquote><h1 id="数据备份-监听mysql的binlog"><a href="#数据备份-监听mysql的binlog" class="headerlink" title="数据备份 监听mysql的binlog"></a>数据备份 监听mysql的binlog</h1><blockquote><h1 id="todo-3"><a href="#todo-3" class="headerlink" title="todo"></a>todo</h1></blockquote><h1 id="infobright"><a href="#infobright" class="headerlink" title="infobright"></a>infobright</h1><blockquote><h1 id="todo-4"><a href="#todo-4" class="headerlink" title="todo"></a>todo</h1></blockquote>]]></content>
    
    
    <categories>
      
      <category>DB</category>
      
    </categories>
    
    
    <tags>
      
      <tag>todo</tag>
      
      <tag>索引</tag>
      
      <tag>事务</tag>
      
      <tag>mvcc</tag>
      
      <tag>buffer pool</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AQS</title>
    <link href="/blog/2021/01/01/0_todo_Java_AQS%E6%BA%90%E7%A0%81/"/>
    <url>/blog/2021/01/01/0_todo_Java_AQS%E6%BA%90%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<p>todo </p><p><a href="https://www.cnblogs.com/waterystone/p/4920797.html">https://www.cnblogs.com/waterystone/p/4920797.html</a></p><h1 id="AQS源码分析"><a href="#AQS源码分析" class="headerlink" title="AQS源码分析"></a>AQS源码分析</h1><p>维护一个 <code>volatile int</code> 变量 <code>state</code> 代表加锁状态</p><p>维护一个 队列代表请求锁资源的线程，head持有锁，后边的节点（线程）等待锁</p><p>提供一套模板，实现类必须实现以下方法来实现自己加锁解锁的逻辑：</p><ul><li>boolean tryAcquire(int)：独占式 尝试获取资源，成功则返回true，失败则返回false。</li><li>boolean tryRelease(int)：独占式 尝试释放资源，返回值同上。</li><li>int tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。</li><li>int tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。</li><li>isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。</li></ul><p>java同步机制的底层支持(1.6及以上)：LockSupport</p><h1 id="LockSupport"><a href="#LockSupport" class="headerlink" title="LockSupport"></a>LockSupport</h1><p>帮助AQS挂起/恢复当前线程</p><blockquote><p><a href="https://www.cnblogs.com/yonghengzh/p/14280670.html">https://www.cnblogs.com/yonghengzh/p/14280670.html</a></p></blockquote><p>这个接口声明的方法很像Object的 wait() 和 notify()</p><p>void await()  </p><p>void awaitUniterruptibl()</p><p>boolean await(long, TimeUnit)</p><p>long awaitNanos(long)</p><p>boolean awaitUntil(Date)</p><p>void signal()</p><p>void signalAll()</p><p>在java层面只是对<code>Unsafe#park()</code>、<code>Unsafe#unpark()</code>的简单封装，在JVM的C语言实现中，每个线程持有一个Parker对象，该Parker对象有三个变量： <code>_counter</code>、``_cond<code>、</code>_mutex<code>，</code>_counter<code>初始值为</code>0`</p><h2 id="park"><a href="#park" class="headerlink" title="park()"></a>park()</h2><p>HotSpot源码（部分）：</p><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">Parker::park</span><span class="hljs-params">(<span class="hljs-keyword">bool</span> isAbsolute, jlong time)</span> </span>&#123;<span class="hljs-keyword">if</span> (Atomic::xchg(<span class="hljs-number">0</span>, &amp;_counter) &gt; <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span>;<span class="hljs-comment">// 获取_counter的值并将其置为0，如果原值为1，则什么也不做</span>    Thread* thread = Thread::current();    assert(thread-&gt;is Java_thread(), <span class="hljs-string">&quot;Must be JavaThread&quot;</span>);    JavaThread *jt = (JavaThread *)thread;        assert(_cur_index == <span class="hljs-number">-1</span>, <span class="hljs-string">&quot;invariant&quot;</span>);    <span class="hljs-keyword">if</span> (time == <span class="hljs-number">0</span>) &#123;        _cur_index = REL_INDEX;                <span class="hljs-comment">// 使当前线程加入操作系统的条件等待队列，同时释放mutex锁，并挂起当前线程（也就是 阻塞在这里！！！！！）</span>        statue = pthread_cond_wait (&amp;_cond[_cur_index], _mutex);<span class="hljs-comment">// pthread_cond_wait 是Linux标准线程库的一个系统调用</span>        <span class="hljs-comment">// Java中的wait()、await()如果是在Linux中调用，也是通过native调用的这个函数</span>    &#125; <span class="hljs-keyword">else</span> &#123;        _cur_index = isAbsolute ? ABS_INDEX : REL_INDEX;        status = os::Linux::safe_cond_timedwait (&amp;_cond[_cur_index], _mutex, &amp;absTime);<span class="hljs-comment">//??????</span>        <span class="hljs-keyword">if</span> (status != <span class="hljs-number">0</span> &amp;&amp; WorkAroundNPTLTimedWaitHang) &#123;            pthread_cond_destroy (&amp;_cond[_cur_index]);            pthread_cond_init    (&amp;_cond[_cur_index], isAbsolute ? <span class="hljs-literal">NULL</span> : os::Linux::condAttr());        &#125;    &#125;    _cur_index = <span class="hljs-number">-1</span>;    assert_status(status == <span class="hljs-number">0</span> || status == EINTR || ...)        ...    _counter = <span class="hljs-number">0</span>; <span class="hljs-comment">// 计数器再次被置为0</span>    status = pthread_mutex_unlock(_mutex);<span class="hljs-comment">// 线程释放锁   结束一个park()操作</span>        assert_status(status == <span class="hljs-number">0</span>, status, <span class="hljs-string">&quot;invariant&quot;</span>);    OrderAccess::fence();    <span class="hljs-keyword">if</span> (jt -&gt; handle_special_suspend_equivalent_condition()) &#123;        jt-&gt;java_suspend_self();    &#125;&#125;</code></pre><ol><li>获取当前线程关联的 Parker 对象。</li><li>将计数器置为 0，同时检查计数器的原值是否为 1，如果是则放弃后续操作。</li><li>在互斥量上加锁。</li><li><strong>在条件变量上阻塞</strong>，同时<strong>释放锁</strong>并等待被其他线程唤醒，当被唤醒后，将重新获取锁。</li><li>当线程恢复至运行状态后，将计数器的值再次置为 0。</li><li>释放锁。<code>最后都要释放锁</code></li></ol><p>简单说：</p><blockquote><ul><li>如果<code>_counter==0</code>，则线程t暂停（wait）,直到被唤醒（ unpark(t) ）；</li><li>如果<code>_counter==1</code>，则将<code>_counter</code>置为<code>0</code>，线程继续运行；</li></ul></blockquote><h2 id="unpark-Thread"><a href="#unpark-Thread" class="headerlink" title="unpark(Thread)"></a>unpark(Thread)</h2><p>HotSpot源码：</p><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">Parker::unpark</span><span class="hljs-params">()</span> </span>&#123;    <span class="hljs-keyword">int</span> s, status ;    status = pthread_mutex_lock(_mutex);<span class="hljs-comment">// 给当前线程加锁           这里加锁了</span>    assert (status == <span class="hljs-number">0</span>, <span class="hljs-string">&quot;invariant&quot;</span>);    s = _counter;    _counter = <span class="hljs-number">1</span>;<span class="hljs-comment">// 然后将_counter置为1</span>    <span class="hljs-keyword">if</span> (s &lt; <span class="hljs-number">1</span>) &#123;<span class="hljs-comment">// 然后判断Parker对象关联的线程是否被park(),</span>        <span class="hljs-comment">// thread might be parked 线程可能已经停止了</span>        <span class="hljs-keyword">if</span> (_cur_index != <span class="hljs-number">1</span>) &#123;            <span class="hljs-keyword">if</span> (WorkAroundNPTLTimedWaitHang) &#123;                status = pthread_cond_signal (&amp;_cond[_cur_index]);<span class="hljs-comment">// 如果被park():通过 pthread_mutex_signal 函数唤醒该线程</span>                assert (status == <span class="hljs-number">0</span>, <span class="hljs-string">&quot;invariant&quot;</span>);                status = pthread_mutex_unlock(_mutex);<span class="hljs-comment">// 最后释放锁</span>                assert (status == <span class="hljs-number">0</span>, <span class="hljs-string">&quot;invariant&quot;</span>);            &#125; <span class="hljs-keyword">else</span> &#123;                status = pthread_mutex_unlock(_mutext);                assert (status == <span class="hljs-number">0</span>, <span class="hljs-string">&quot;invariant&quot;</span>);                status = pthread_cond_signal (&amp;_cond[_cur_index]);                assert (status == <span class="hljs-number">0</span>, <span class="hljs-string">&quot;invariant&quot;</span>);            &#125;        &#125; <span class="hljs-keyword">else</span> &#123;            pthread_mutex_unlock(_mutex);            assert (status == <span class="hljs-number">0</span>, <span class="hljs-string">&quot;invariant&quot;</span>);        &#125;    &#125; <span class="hljs-keyword">else</span> &#123;        pthread_mutex_unlock(_mutex);        assert (status == <span class="hljs-number">0</span>, <span class="hljs-string">&quot;invariant&quot;</span>);    &#125;    &#125;<span class="hljs-comment">//   --该线程恢复至运行状态(先拿到mutex锁)然后从pthread_cond_wait方法返回--------关联park()源码的pthread_cond_wait函数调用！！！！！</span></code></pre><ol><li>获取目标线程关联的 Parker 对象（注意目标线程不是当前线程，是Java中unpark(jt)的参数对应的线程）。——jt：JavaThread</li><li>在互斥量上加锁。——jt在park()函数中阻塞的时候是释放了锁的</li><li>将计数器置为 1。——jt在park()函数开始时将<code>_counter</code>置为了 0，这里置为 1，jt被唤醒之后还会把<code>_counter</code>置为 0</li><li>唤醒在条件变量上等待着的线程。——jt调用park()函数并阻塞在了系统函数<code>pthread_cond_wait</code>调用的地方</li><li>释放锁。-—–jt继续运行需要拿到对象的mutex锁</li></ol><p>简单说：</p><blockquote><ul><li>如果线程已暂停，则唤醒它</li><li>如果线程正在运行，<code>_counter==0</code>，将<code>_counter</code>置为<code>1</code></li><li>如果线程正在运行，<code>_counter==1</code>，do nothing</li></ul><blockquote><p>可以在改线程调用park()之前调用unpark()，效果就是 该线程调用park()的时候不会暂停</p></blockquote><blockquote><p>相比Object的<code>wait()-notify()/notifyAll()</code>来说更准确，可以控制到指定的线程（只要持有该线程Thread的引用）</p></blockquote></blockquote><h1 id="Exclusive独占模式"><a href="#Exclusive独占模式" class="headerlink" title="Exclusive独占模式"></a>Exclusive独占模式</h1><h2 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h2><h3 id="acquire-int-arg"><a href="#acquire-int-arg" class="headerlink" title="acquire(int arg)"></a>acquire(int arg)</h3><p>独占式获取锁</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">acquire</span><span class="hljs-params">(<span class="hljs-keyword">int</span> arg)</span> </span>&#123;    <span class="hljs-keyword">if</span> (!tryAcquire(arg) &amp;&amp; <span class="hljs-comment">// 如果尝试拿锁成功 直接return  没拿到就入队然后阻塞直到获取到锁</span>        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))<span class="hljs-comment">// 如果尝试拿锁失败，就以独占模式入队</span>        selfInterrupt();<span class="hljs-comment">// currentThread.interrupt(); </span>    <span class="hljs-comment">// 调用interrupt()是因为acquireQueued(...)方法可能判断过线程是否被中断，用的是isInterrupted()方法，会清除中断标识，acquireQueued(...)的返回值就代表了线程是否被中断过，所以这里根据这个返回值决定是否需要补充currentThread的中断标识</span>&#125;</code></pre><h4 id="acquireQueued-…-独占模式入队并阻塞获取锁"><a href="#acquireQueued-…-独占模式入队并阻塞获取锁" class="headerlink" title="acquireQueued(…) 独占模式入队并阻塞获取锁"></a>acquireQueued(…) 独占模式入队并阻塞获取锁</h4><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">final</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">acquireQueued</span><span class="hljs-params">(<span class="hljs-keyword">final</span> Node node, <span class="hljs-keyword">int</span> arg)</span> </span>&#123;    <span class="hljs-comment">//标记是否成功拿到资源，默认false</span>    <span class="hljs-keyword">boolean</span> failed = <span class="hljs-keyword">true</span>;    <span class="hljs-keyword">try</span> &#123;        <span class="hljs-keyword">boolean</span> interrupted = <span class="hljs-keyword">false</span>;<span class="hljs-comment">//标记等待过程中是否被中断过</span>        <span class="hljs-keyword">for</span> (;;) &#123;            <span class="hljs-keyword">final</span> Node p = node.predecessor();<span class="hljs-comment">// 相当于 p = node.prev  判断了prev是不是null</span>            <span class="hljs-comment">// 如果当前节点是头节点 且 尝试获取锁成功 就return</span>            <span class="hljs-keyword">if</span> (p == head &amp;&amp; tryAcquire(arg)) &#123;<span class="hljs-comment">// node.prev == head 并且 try=true</span>                setHead(node);<span class="hljs-comment">// 清理引用： head = node; node.thread = null; node.prev = null;</span>                p.next = <span class="hljs-keyword">null</span>; <span class="hljs-comment">// help GC</span>                failed = <span class="hljs-keyword">false</span>;                <span class="hljs-keyword">return</span> interrupted;<span class="hljs-comment">// return false 表示没有中断, acquire()会直接return</span>            &#125;            <span class="hljs-comment">// 如果上边try失败了就检查当前线程是否应该park(),如果需要 就检查当前线程是否被中断了（会清空中断标识，然后继续自旋，所以说是不可被中断的，说的就是acquireQueued(...)这个方法！ 只能是最后将原本的中断标识返回出去，由acquire()方法在设置上当前线程的中断标识）</span>            <span class="hljs-keyword">if</span> (shouldParkAfterFailedAcquire(p, node) &amp;&amp; <span class="hljs-comment">// 检查当前线程是否需要park()</span>                parkAndCheckInterrupt())                interrupted = <span class="hljs-keyword">true</span>;        &#125;    &#125; <span class="hljs-keyword">finally</span> &#123;        <span class="hljs-keyword">if</span> (failed)            cancelAcquire(node);    &#125;&#125;</code></pre><p>值得一提的是：<code>Condition#await()</code>的调用链中的一环——<code>doAcquireSharedInterruptibly()</code>的大致逻辑也是这样！</p><h5 id="addWaiter-node-将当前线程包装成node入队-将curNode通过自旋置为tail"><a href="#addWaiter-node-将当前线程包装成node入队-将curNode通过自旋置为tail" class="headerlink" title="addWaiter(node)将当前线程包装成node入队  将curNode通过自旋置为tail"></a>addWaiter(node)将当前线程包装成node入队  将curNode通过自旋置为tail</h5><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> Node <span class="hljs-title">addWaiter</span><span class="hljs-params">(Node mode)</span> </span>&#123;    Node node = <span class="hljs-keyword">new</span> Node(Thread.currentThread(), mode);    <span class="hljs-comment">// Try the fast path of enq; backup to full enq on failure</span>    Node pred = tail;    <span class="hljs-keyword">if</span> (pred != <span class="hljs-keyword">null</span>) &#123;        node.prev = pred;        <span class="hljs-keyword">if</span> (compareAndSetTail(pred, node)) &#123;            pred.next = node;            <span class="hljs-keyword">return</span> node;        &#125;    &#125;    <span class="hljs-comment">// 如果pred==null说明队列需要初始化</span>    enq(node);<span class="hljs-comment">// 在这里自旋，CAS设置tail为自己</span>    <span class="hljs-keyword">return</span> node;&#125;<span class="hljs-comment">// enq(node) 将node置为tail</span><span class="hljs-function"><span class="hljs-keyword">private</span> Node <span class="hljs-title">enq</span><span class="hljs-params">(<span class="hljs-keyword">final</span> Node node)</span> </span>&#123;    <span class="hljs-keyword">for</span> (;;) &#123;<span class="hljs-comment">// 自旋                1</span>        Node t = tail;        <span class="hljs-keyword">if</span> (t == <span class="hljs-keyword">null</span>) &#123; <span class="hljs-comment">// Must initialize  必须初始化，因为发现队列没有初始化才调用的enq()，这里再验证一下</span>            <span class="hljs-keyword">if</span> (compareAndSetHead(<span class="hljs-keyword">new</span> Node()))                tail = head;        &#125; <span class="hljs-keyword">else</span> &#123;            node.prev = t;                       <span class="hljs-comment">// 2</span>            <span class="hljs-keyword">if</span> (compareAndSetTail(t, node)) &#123;    <span class="hljs-comment">// 3  其实就是自选执行这三步 所以就算多个线程在同时跑这三行代码 总会排着队入队的</span>                t.next = node;<span class="hljs-comment">// 必须把自己设置为tail才行</span>                <span class="hljs-keyword">return</span> t; <span class="hljs-comment">// 唯一出口</span>            &#125;        &#125;    &#125;&#125;</code></pre><h5 id="shouldParkAfterFailedAcquire-prev-curNode-检查当前线程是否应该park"><a href="#shouldParkAfterFailedAcquire-prev-curNode-检查当前线程是否应该park" class="headerlink" title="shouldParkAfterFailedAcquire(prev, curNode) 检查当前线程是否应该park()"></a>shouldParkAfterFailedAcquire(prev, curNode) 检查当前线程是否应该park()</h5><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">shouldParkAfterFailedAcquire</span><span class="hljs-params">(Node pred, Node node)</span> </span>&#123;    <span class="hljs-keyword">int</span> ws = pred.waitStatus;    <span class="hljs-keyword">if</span> (ws == Node.SIGNAL)<span class="hljs-comment">//Signal： -1，指示后续线程需要unpark()</span>        <span class="hljs-comment">//prev的状态是signal，要求释放以发出信号，所以可以安全地park()</span>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;    <span class="hljs-keyword">if</span> (ws &gt; <span class="hljs-number">0</span>) &#123;        <span class="hljs-comment">// prev对应的线程被cancelled(取消)</span>        <span class="hljs-keyword">do</span> &#123;            <span class="hljs-comment">// 跳过prev并重试 直到找到waitStatus&lt;=0的node</span>            node.prev = pred = pred.prev;        &#125; <span class="hljs-keyword">while</span> (pred.waitStatus &gt; <span class="hljs-number">0</span>);        <span class="hljs-comment">// 让(最靠后的、waitStatus&lt;=0的)node作为当前节点的prev</span>        pred.next = node;    &#125; <span class="hljs-keyword">else</span> &#123;        <span class="hljs-comment">/*</span><span class="hljs-comment">         * waitStatus must be 0 or PROPAGATE.  Indicate that we</span><span class="hljs-comment">         * need a signal, but don&#x27;t park yet.  Caller will need to</span><span class="hljs-comment">         * retry to make sure it cannot acquire before parking.</span><span class="hljs-comment">         */</span>        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;&#125;</code></pre><h5 id="parkAndCheckInterrupt-park当前线程并中断"><a href="#parkAndCheckInterrupt-park当前线程并中断" class="headerlink" title="parkAndCheckInterrupt() park当前线程并中断"></a>parkAndCheckInterrupt() park当前线程并中断</h5><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">parkAndCheckInterrupt</span><span class="hljs-params">()</span> </span>&#123;    LockSupport.park(<span class="hljs-keyword">this</span>);<span class="hljs-comment">// 挂起当前线程</span>    <span class="hljs-keyword">return</span> Thread.interrupted();<span class="hljs-comment">//最后在查询线程是否被中断，并返回该中断标识（清除掉了，不处理，return出去交给调用方处理）</span>&#125;</code></pre><h2 id="解锁"><a href="#解锁" class="headerlink" title="解锁"></a>解锁</h2><h1 id="Shared共享模式"><a href="#Shared共享模式" class="headerlink" title="Shared共享模式"></a>Shared共享模式</h1><h2 id="加锁-1"><a href="#加锁-1" class="headerlink" title="加锁"></a>加锁</h2><h2 id="解锁-1"><a href="#解锁-1" class="headerlink" title="解锁"></a>解锁</h2>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>todo</tag>
      
      <tag>JUC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java中的IO</title>
    <link href="/blog/2021/01/01/0_todo_Java_IO/"/>
    <url>/blog/2021/01/01/0_todo_Java_IO/</url>
    
    <content type="html"><![CDATA[<h2 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h2><p>Java 1.4 之前， 传统io，阻塞 所以又叫BIO（Blocking IO）</p><p>数据的读取写入必须阻塞在一个线程内等待其完成。</p><p>比如用socket，想要多个client同时访问就要开同样多个线程来处理client的链接，线程资源太宝贵了，这不OK。</p><h2 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h2><p>New IO / Non blocking IO</p><h3 id="核心组件："><a href="#核心组件：" class="headerlink" title="核心组件："></a>核心组件：</h3><ul><li><h5 id="channels"><a href="#channels" class="headerlink" title="channels"></a>channels</h5><p>通道是双向的，流的读写是单向的</p></li><li><h5 id="buffers"><a href="#buffers" class="headerlink" title="buffers"></a>buffers</h5><p>比如ByteBuffer，其他每种java基本类型(除了boolean)都对应一种缓冲区</p></li><li><h5 id="selectors"><a href="#selectors" class="headerlink" title="selectors"></a>selectors</h5><p>用于单个线程处理多个通道。</p></li></ul><h3 id="NIO的特点也就是和IO的不同之处："><a href="#NIO的特点也就是和IO的不同之处：" class="headerlink" title="NIO的特点也就是和IO的不同之处："></a>NIO的特点也就是和IO的不同之处：</h3><ul><li><p>NIO面向缓冲区，IO面向流</p></li><li><p>NIO有选择器，IO没有</p></li><li><p>NIO非阻塞，IO阻塞</p></li></ul><h3 id="NIO读写数据的方式："><a href="#NIO读写数据的方式：" class="headerlink" title="NIO读写数据的方式："></a>NIO读写数据的方式：</h3><ul><li>从通道（channels）读取：创建一个缓冲区，请求通道读取数据。</li><li>从通道（channels）写入：创建一个环城区，填充数据，并要求通道写入数据。</li></ul><p>todo！！！  这好像是JVM的范围了。</p><p>java中使用的堆外内存，也是用户空间的，因为他是JVM进程使用<code>malloc</code>申请的内存，只不过在JVM管理的内存范围内。</p><p><a href="https://sulangsss.github.io/2018/12/08/Java/Advance/ByteBuffer/">https://sulangsss.github.io/2018/12/08/Java/Advance/ByteBuffer/</a></p><p>不过GC也会帮助清理堆外内存，GC清理了DirectByteBuffer对象，下次GC会调用Cleaner对象的clean()</p><p><a href="https://kaiwu.lagou.com/course/courseInfo.htm?sid=&amp;courseId=516#/detail/pc?id=4923">https://kaiwu.lagou.com/course/courseInfo.htm?sid=&amp;courseId=516#/detail/pc?id=4923</a></p><p><a href="https://tech.meituan.com/2016/11/04/nio.html">https://tech.meituan.com/2016/11/04/nio.html</a></p><h2 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h2><p><strong>Asynchronous</strong> IO</p><p><strong>异步IO</strong>是基于<strong>事件</strong>和<strong>回调机制</strong>实现的，应用操作之后会直接返回。当后台处理完成，操作系统通知相应线程进行后续的操作。</p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>todo</tag>
      
      <tag>IO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>synchronized</title>
    <link href="/blog/2021/01/01/0_todo_Java_synchronized/"/>
    <url>/blog/2021/01/01/0_todo_Java_synchronized/</url>
    
    <content type="html"><![CDATA[<h1 id="todo-todo-大写的todo！！！！"><a href="#todo-todo-大写的todo！！！！" class="headerlink" title="todo todo  大写的todo！！！！"></a>todo todo  大写的todo！！！！</h1><p><a href="https://blog.csdn.net/lengxiao1993/article/details/81568130">https://blog.csdn.net/lengxiao1993/article/details/81568130</a></p><p>无锁</p><p>偏向锁</p><p>轻量级锁</p><p>重量级锁</p><h3 id="无锁-gt-偏向锁"><a href="#无锁-gt-偏向锁" class="headerlink" title="无锁-&gt;偏向锁"></a>无锁-&gt;偏向锁</h3><blockquote><p>也就是无锁加锁过程</p></blockquote><ul><li>如果为可偏向状态（可以用jvm参数设置为不启用偏向锁    -XX:-UseBiasedLocking）<ul><li>如果 CAS 操作成功， 则认为已经获取到该对象的偏向锁， 执行同步块代码 </li><li>如果 CAS 操作失败， 则说明有另外一个线程B 抢先获取了偏向锁。 这种状态说明该对象的竞争比较激烈， 此时需要<strong>撤销</strong> B 获得的偏向锁，将 Thread B 持有的锁升级为轻量级锁</li></ul></li><li>如果为已偏向状态<ul><li>MarkWord.threadID == threadID，当前线程获取到偏向锁，继续执行同步代码块；</li><li>MarkWord.threadID != threadID，该对象偏向其他线程，需要撤销偏向锁。</li></ul></li></ul><h3 id="偏向锁-gt-轻量级锁"><a href="#偏向锁-gt-轻量级锁" class="headerlink" title="偏向锁-&gt;轻量级锁"></a>偏向锁-&gt;轻量级锁</h3><p>当超过一个线程竞争某一个对象时，会发生偏向锁的撤销操作。撤销之后对象可能处于两种情况：</p><ol><li><p>不可偏向的无锁状态</p><blockquote><p>原来获取了偏向锁的线程已经执行完同步代码块，对象处于闲置状态</p></blockquote></li><li><p>不可偏向的轻量级锁(已锁)状态</p><blockquote><p>原来获取了偏向锁的线程还未执行完同步代码块，偏向锁依旧有效，有竞争，转为轻量级锁加锁状态。</p></blockquote></li></ol><h3 id="轻量级锁-gt-重量级锁"><a href="#轻量级锁-gt-重量级锁" class="headerlink" title="轻量级锁-&gt;重量级锁"></a>轻量级锁-&gt;重量级锁</h3><p>轻量级锁加锁过程：</p><ul><li>根据标志位（tag bits）判断对象处于不可偏向的无锁状态</li><li>在当前线程栈针中创建锁记录空间</li><li>CAS操作将对象头中的MarkWord替换为所记录的指针<ul><li>成功：当前线程获得锁</li><li>失败：该对象已经被加锁了，先自旋CAS，再失败，就升级重量级锁</li></ul></li></ul><h3 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h3><p>重量级锁依赖于操作系统的互斥量（<strong>mutex</strong>） 实现。 </p><p>该操作会导致进程从<strong>用户态与内核态之间的切换</strong>， 是一个开销较大的操作。</p><h2 id="java-对象头"><a href="#java-对象头" class="headerlink" title="java 对象头"></a>java 对象头</h2><p><img src="images%5Cjava-%E5%AF%B9%E8%B1%A1%E5%A4%B4.png" alt="java-对象头"></p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>todo</tag>
      
      <tag>synchronized</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RabbitMQ</title>
    <link href="/blog/2021/01/01/0_todo_MQ_RabbitMQ/"/>
    <url>/blog/2021/01/01/0_todo_MQ_RabbitMQ/</url>
    
    <content type="html"><![CDATA[<p>查看所有的队列：<code>rabbitmqctl list_queues</code></p><p>清除所有的队列：<code>rabbitmqctl reset</code></p><hr><p>停止：<code>service rabbitmq-server stop</code></p><p>启动：<code>service rabbitmq-server start</code></p><p>重启:   <code>service rabbitmq-server restart</code></p><p>查看状态：<code>service rabbitmq-server status</code></p><p>关闭应用：<code>rabbitmqctl stop_app</code></p><p>启动应用：<code>rabbitmqctl start_app</code></p><p>查看插件打开情况：<code>rabbitmq-plugins list</code></p><p>启动监控管理器：<code>rabbitmq-plugins enable rabbitmq_management</code></p><p>关闭监控管理器：<code>rabbitmq-plugins disable rabbitmq_management</code></p><p>查看状态：<code>rabbitmqctl status</code></p><p>集群同步：</p><blockquote><p>所有节点的值相同：<code>/var/lib/rabbitmq/.erlang.cookie</code></p><p>加入集群：</p><p>host1 和 host2，在 host2 上操作</p><p>先停止：<code>rabbitmqctl -n rabbit stop_app</code></p><p>加入：<code>rabbitmqctl -n rabbit join_cluster rabbit@$rabbit_hostname1</code></p><p>再启动：<code>rabbitmqctl -n rabbit start_app</code></p></blockquote><p>查看集群状态：<code>rabbitmqctl cluster_status</code></p><p>多应用使用  <code>rabbitmqctl -n rabbit_ceilometer</code></p><h4 id="user相关命令"><a href="#user相关命令" class="headerlink" title="user相关命令"></a>user相关命令</h4><ul><li><p>创建用户</p><p><code>rabbitmqctl add_user &#123;用户名&#125; &#123;密码&#125;</code></p></li><li><p>设置权限</p><p><code>rabbitmqctl set_user_tags &#123;用户名&#125; &#123;权限&#125;</code></p></li><li><p>查看用户列表</p><p><code>rabbitmqctl list_users</code></p></li><li><p>给用户授权</p><p><code>rabbitmqctl  set_permissions -p vhost1 user1 &#39;.*&#39; &#39;.*&#39; &#39;.*&#39; </code></p><blockquote><p>demo: <code>rabbitmqctl  set_permissions -p / admin &#39;.*&#39; &#39;.*&#39; &#39;.*&#39; </code></p></blockquote></li><li><p>查看权限</p><p><code>rabbitmqctl list_user_permissions user1</code></p><p><code>rabbitmqctl list_permissions -p vhost1</code></p></li><li><p>清除权限</p><p><code>rabbitmqctl clear_permissions [-p VHostPath] User</code></p></li><li><p>删除用户</p><p><code>rabbitmqctl delete_user Username</code></p></li><li><p>修改密码</p><p><code>rabbitmqctl change_password Username Newpassword</code></p></li><li><p>清除用户权限</p><p><code>rabbitmqctl  clear_permissions  [-p VHostPath]  admin</code></p></li></ul><h4 id="用户角色分类-权限列表"><a href="#用户角色分类-权限列表" class="headerlink" title="用户角色分类  (权限列表)"></a>用户角色分类  (权限列表)</h4><ul><li><p><strong>none</strong>：无法登录控制台</p><p>不能访问 management plugin，通常就是普通的生产者和消费者。</p></li><li><p><strong>management</strong>：普通管理者</p><p>仅可登陆管理控制台(启用management plugin的情况下)，无法看到节点信息，也无法对policies进行管理。</p><p>用户可以通过AMQP做的任何事外加： </p><ol><li>列出自己可以通过AMQP登入的virtual hosts</li><li>查看自己的virtual hosts中的queues, exchanges 和 bindings</li><li>查看和关闭自己的channels 和 connections</li><li>查看有关自己的virtual hosts的“全局”的统计信息，包含其他用户在这些virtual hosts中的活动。</li></ol></li><li><p><strong>policymaker</strong>：策略制定者</p><p>management可以做的任何事外加：</p><ol><li>查看、创建和删除自己的virtual hosts所属的policies和parameters</li></ol></li><li><p><strong>monitoring</strong>：监控者</p><p>management可以做的任何事外加：</p><ol><li>列出所有virtual hosts，包括他们不能登录的virtual hosts</li><li>查看其他用户的connections和channels</li><li>查看节点级别的数据如clustering和memory使用情况</li><li>查看真正的关于所有virtual hosts的全局的统计信息</li><li>同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等)</li></ol></li><li><p><strong>administrator</strong>：超级管理员</p><p>policymaker和monitoring可以做的任何事外加:</p><ol><li>创建和删除virtual host</li><li>查看、创建和删除users</li><li>查看创建和删除permissions</li><li>关闭其他用户的connections</li></ol></li></ul>]]></content>
    
    
    <categories>
      
      <category>MQ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>todo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RocketMQ</title>
    <link href="/blog/2021/01/01/0_todo_MQ_RocketMQ/"/>
    <url>/blog/2021/01/01/0_todo_MQ_RocketMQ/</url>
    
    <content type="html"><![CDATA[<h1 id="部署架构"><a href="#部署架构" class="headerlink" title="部署架构"></a>部署架构</h1><h1 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h1>]]></content>
    
    
    <categories>
      
      <category>MQ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>todo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ElasticSearch</title>
    <link href="/blog/2021/01/01/0_todo_%E5%88%86%E5%B8%83%E5%BC%8F_Elasticsearch/"/>
    <url>/blog/2021/01/01/0_todo_%E5%88%86%E5%B8%83%E5%BC%8F_Elasticsearch/</url>
    
    <content type="html"><![CDATA[<p>ELK</p><p>elasticsearch + Logstash + Kibana</p><p>在加上kafka更好</p><p>Elasticsearch基于Lucene</p><p>下载elasticsearch并安装 port9200</p><p>下载head (Node.js) port9100</p><p>config中配置跨域</p><pre><code class="hljs yaml"><span class="hljs-attr">http.cors.enable:</span> <span class="hljs-literal">true</span><span class="hljs-attr">http.cors.allow-origin:</span> <span class="hljs-string">&quot;*&quot;</span></code></pre><p>Kibana下载 要和Elasticsearch的版本一致  可以汉化</p><p>使用了Lucene倒排索引</p><p>分片就是倒排索引</p><p>下载ik分词器</p><p>在kibana中使用rest请求</p><pre><code class="hljs json">GET _analyze&#123;  <span class="hljs-attr">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;ik_smart&quot;</span>,  <span class="hljs-attr">&quot;text&quot;</span>: <span class="hljs-string">&quot;java大数据行业&quot;</span>&#125;GET _analyze&#123;  <span class="hljs-attr">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;ik_max_word&quot;</span>,  <span class="hljs-attr">&quot;text&quot;</span>: <span class="hljs-string">&quot;java大数据行业&quot;</span>&#125;GET _analyze&#123;  <span class="hljs-attr">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;standard&quot;</span>,  <span class="hljs-attr">&quot;text&quot;</span>: <span class="hljs-string">&quot;↑这个是标准的分词器&quot;</span>&#125;GET _analyze&#123;  <span class="hljs-attr">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;keyword&quot;</span>,  <span class="hljs-attr">&quot;text&quot;</span>: <span class="hljs-string">&quot;这个不会拆分text&quot;</span>&#125;</code></pre><p>字典中没有的词需要自己加入到字典中， 在ik中增加自己的配置，新增.dic文件</p><p>字段如果是keyword类型，就不会被分词器拆分，如果是text才可以</p><p>version 0-6 一个索引下有可以有多个type</p><p>version 7     一个索引下只有一个type</p><p>version 8      索引下直接使用documentId，没有type</p><ul><li>查看所有索引 GET /_cat/indices</li><li>查看集群是否健康 GET /_cat/health</li><li>查看集群节点 GET /_cat/nodes</li></ul><h3 id="CRUD"><a href="#CRUD" class="headerlink" title="CRUD"></a>CRUD</h3><ol><li><p>创建一个库  创建规则</p><pre><code class="hljs json">PUT /索引名&#123;  <span class="hljs-attr">&quot;mappings&quot;</span>: &#123;    <span class="hljs-attr">&quot;properties&quot;</span>: &#123;      <span class="hljs-attr">&quot;name&quot;</span>: &#123;        <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>      &#125;,      <span class="hljs-attr">&quot;height&quot;</span>: &#123;        <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-string">&quot;double&quot;</span>      &#125;,      <span class="hljs-attr">&quot;birthday&quot;</span>: &#123;        <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-string">&quot;date&quot;</span>      &#125;    &#125;  &#125;&#125;</code></pre></li><li><p>查看索引下所有数据</p><pre><code class="hljs json">GET /team/_search?pretty<span class="hljs-comment">// _doc</span><span class="hljs-comment">// _search</span><span class="hljs-comment">// _mapping...</span>结果&#123;  <span class="hljs-attr">&quot;took&quot;</span> : <span class="hljs-number">0</span>,  <span class="hljs-attr">&quot;timed_out&quot;</span> : <span class="hljs-literal">false</span>,<span class="hljs-comment">// 超时</span>  <span class="hljs-attr">&quot;_shards&quot;</span> : &#123;<span class="hljs-comment">//分区信息</span>    <span class="hljs-attr">&quot;total&quot;</span> : <span class="hljs-number">1</span>,    <span class="hljs-attr">&quot;successful&quot;</span> : <span class="hljs-number">1</span>,    <span class="hljs-attr">&quot;skipped&quot;</span> : <span class="hljs-number">0</span>,    <span class="hljs-attr">&quot;failed&quot;</span> : <span class="hljs-number">0</span>  &#125;,  <span class="hljs-attr">&quot;hits&quot;</span> : &#123;    <span class="hljs-attr">&quot;total&quot;</span> : &#123;      <span class="hljs-attr">&quot;value&quot;</span> : <span class="hljs-number">3</span>,      <span class="hljs-attr">&quot;relation&quot;</span> : <span class="hljs-string">&quot;eq&quot;</span>    &#125;,    <span class="hljs-attr">&quot;max_score&quot;</span> : <span class="hljs-number">1.0</span>,    <span class="hljs-attr">&quot;hits&quot;</span> : [ <span class="hljs-comment">// 全部数据</span>      &#123;        <span class="hljs-attr">&quot;_index&quot;</span> : <span class="hljs-string">&quot;team&quot;</span>,<span class="hljs-comment">//索引</span>        <span class="hljs-attr">&quot;_type&quot;</span> : <span class="hljs-string">&quot;_doc&quot;</span>,        <span class="hljs-attr">&quot;_id&quot;</span> : <span class="hljs-string">&quot;1&quot;</span>,        <span class="hljs-attr">&quot;_score&quot;</span> : <span class="hljs-number">1.0</span>,<span class="hljs-comment">//分值</span>        <span class="hljs-attr">&quot;_source&quot;</span> : &#123;<span class="hljs-comment">//source数据</span>          <span class="hljs-attr">&quot;name&quot;</span> : <span class="hljs-string">&quot;Thunders&quot;</span>,          <span class="hljs-attr">&quot;area&quot;</span> : <span class="hljs-string">&quot;north-west&quot;</span>,          <span class="hljs-attr">&quot;address&quot;</span> : <span class="hljs-string">&quot;Oklahoma City&quot;</span>,          <span class="hljs-attr">&quot;Coach&quot;</span> : <span class="hljs-string">&quot;Mitchell Donovan&quot;</span>        &#125;      &#125;,      &#123;        <span class="hljs-attr">&quot;_index&quot;</span> : <span class="hljs-string">&quot;team&quot;</span>,        <span class="hljs-attr">&quot;_type&quot;</span> : <span class="hljs-string">&quot;_doc&quot;</span>,        <span class="hljs-attr">&quot;_id&quot;</span> : <span class="hljs-string">&quot;2&quot;</span>,        <span class="hljs-attr">&quot;_score&quot;</span> : <span class="hljs-number">1.0</span>,        <span class="hljs-attr">&quot;_source&quot;</span> : &#123;          <span class="hljs-attr">&quot;name&quot;</span> : <span class="hljs-string">&quot;Warriors&quot;</span>,          <span class="hljs-attr">&quot;area&quot;</span> : <span class="hljs-string">&quot;north-west&quot;</span>,          <span class="hljs-attr">&quot;address&quot;</span> : <span class="hljs-string">&quot;Golden State&quot;</span>,          <span class="hljs-attr">&quot;Coach&quot;</span> : <span class="hljs-string">&quot;Steve Kerr&quot;</span>        &#125;      &#125;,      &#123;        <span class="hljs-attr">&quot;_index&quot;</span> : <span class="hljs-string">&quot;team&quot;</span>,        <span class="hljs-attr">&quot;_type&quot;</span> : <span class="hljs-string">&quot;_doc&quot;</span>,        <span class="hljs-attr">&quot;_id&quot;</span> : <span class="hljs-string">&quot;3&quot;</span>,        <span class="hljs-attr">&quot;_score&quot;</span> : <span class="hljs-number">1.0</span>,        <span class="hljs-attr">&quot;_source&quot;</span> : &#123;          <span class="hljs-attr">&quot;name&quot;</span> : <span class="hljs-string">&quot;Clippers&quot;</span>,          <span class="hljs-attr">&quot;area&quot;</span> : <span class="hljs-string">&quot;north-west&quot;</span>,          <span class="hljs-attr">&quot;address&quot;</span> : <span class="hljs-string">&quot;Los Angeles&quot;</span>,          <span class="hljs-attr">&quot;Coach&quot;</span> : <span class="hljs-string">&quot;Doc Rivers&quot;</span>        &#125;      &#125;    ]  &#125;&#125;</code></pre></li><li><p>增加一条索引</p><pre><code class="hljs json">PUT /索引名/type名/id&#123;  <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;melopoz&quot;</span>,  <span class="hljs-attr">&quot;height&quot;</span>: <span class="hljs-string">&quot;190&quot;</span>&#125;</code></pre></li><li><p>修改一条索引  每次version会+1</p><pre><code class="hljs json"><span class="hljs-comment">//如果缺少字段，更新之后就会丢失</span>PUT /索引/type/id&#123;  <span class="hljs-attr">&quot;doc&quot;</span>: &#123;    <span class="hljs-attr">&quot;feildName&quot;</span>: <span class="hljs-string">&quot;newValue&quot;</span>     &#125;&#125;<span class="hljs-comment">//不会丢失字段 在id后加update。</span>POST /索引/type/id/_update&#123;  <span class="hljs-attr">&quot;doc&quot;</span>: &#123;    <span class="hljs-attr">&quot;feildName&quot;</span>: <span class="hljs-string">&quot;newValue&quot;</span>  &#125;&#125;</code></pre></li><li><p>删除  DELETE</p></li></ol><h3 id="复杂查询"><a href="#复杂查询" class="headerlink" title="复杂查询"></a>复杂查询</h3><ul><li>match 使用分词器解析</li></ul><pre><code class="hljs json">GET /../../..&#123;  <span class="hljs-attr">&quot;query&quot;</span>: &#123;    <span class="hljs-attr">&quot;match&quot;</span>: &#123;      <span class="hljs-attr">&quot;字段名&quot;</span>: <span class="hljs-string">&quot;值&quot;</span>,      ...    &#125;  &#125;,  <span class="hljs-comment">//字段过滤</span>  &quot;_source&quot;: [&quot;name&quot;, &quot;height&quot;],   <span class="hljs-comment">//排序 多种写法</span>  &quot;sort&quot;: [    &#123;      <span class="hljs-attr">&quot;height&quot;</span>: <span class="hljs-string">&quot;asc&quot;</span>    &#125;,&#123;&#125;  ]  <span class="hljs-comment">//分页</span>  &quot;from&quot;: 0,  &quot;size&quot;: 20&#125;</code></pre><ul><li>boolean查询</li></ul><pre><code class="hljs json">GET /../../..&#123;  <span class="hljs-attr">&quot;query&quot;</span>: &#123;    <span class="hljs-attr">&quot;bool&quot;</span>: &#123;      <span class="hljs-attr">&quot;must&quot;</span>: [<span class="hljs-comment">//should(or) must(and) must_not(!=)</span>        &#123;          <span class="hljs-attr">&quot;match&quot;</span>: &#123;            <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;melopoz&quot;</span>          &#125;        &#125;,&#123;          <span class="hljs-attr">&quot;match&quot;</span>: &#123;            <span class="hljs-attr">&quot;height&quot;</span>: <span class="hljs-number">190</span>          &#125;        &#125;      ],      <span class="hljs-attr">&quot;filter&quot;</span>: &#123;        <span class="hljs-attr">&quot;range&quot;</span>: &#123;          <span class="hljs-attr">&quot;height&quot;</span>: &#123;            <span class="hljs-attr">&quot;gt&quot;</span>: <span class="hljs-number">185</span> <span class="hljs-comment">//gt gte lt lte</span>          &#125;        &#125;      &#125;    &#125;  &#125;&#125;</code></pre><ul><li>term 直接精确查询 若果存储的value首字母大写了，查询时的参数首字母也要小写。因为分词器分析出的都是小写。 standard</li></ul><pre><code class="hljs json">GET /../../..&#123;  <span class="hljs-attr">&quot;query&quot;</span>: &#123;    <span class="hljs-attr">&quot;term&quot;</span>: &#123;      <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;melopoz&quot;</span> <span class="hljs-comment">//如果name字段的type为keyword，有name=melopoz2的数据，也不会被查询到</span>    &#125;  &#125;&#125;</code></pre><ul><li>高亮查询</li></ul><pre><code class="hljs awk">GET <span class="hljs-regexp">/../</span>../..&#123;  <span class="hljs-string">&quot;query&quot;</span>: &#123;    <span class="hljs-string">&quot;match&quot;</span>: &#123;      <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;melopoz&quot;</span>    &#125;  &#125;,  <span class="hljs-string">&quot;highlight&quot;</span>: &#123;    <span class="hljs-string">&quot;pre_tags&quot;</span>: <span class="hljs-string">&quot;&lt;hl class=&quot;</span>highlight_word<span class="hljs-string">&quot;&gt;&quot;</span>    <span class="hljs-string">&quot;post_tags&quot;</span>: <span class="hljs-string">&quot;&lt;/h1&gt;&quot;</span>    <span class="hljs-string">&quot;name&quot;</span>:&#123;&#125;  &#125;&#125;</code></pre><h3 id="聚合索引"><a href="#聚合索引" class="headerlink" title="聚合索引"></a>聚合索引</h3><pre><code class="hljs awk"><span class="hljs-regexp">//</span>查询<span class="hljs-number">20</span>-<span class="hljs-number">30</span>,<span class="hljs-number">0</span>-<span class="hljs-number">40</span>,<span class="hljs-number">40</span>-<span class="hljs-number">50</span>这三个年龄段分别有多少人GET /..&#123;  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-regexp">//</span> size=<span class="hljs-number">0</span>则不显示数据只显示聚合结果，每个阶段的人数  <span class="hljs-string">&quot;user&quot;</span>: &#123;    <span class="hljs-string">&quot;age&quot;</span>: &#123;      <span class="hljs-string">&quot;range&quot;</span>: &#123;        <span class="hljs-string">&quot;field&quot;</span>: <span class="hljs-string">&quot;age&quot;</span>,        <span class="hljs-string">&quot;ranges&quot;</span>: [          &#123;            <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-number">20</span>,            <span class="hljs-string">&quot;to&quot;</span>: <span class="hljs-number">30</span>          &#125;,&#123;            <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-number">30</span>,            <span class="hljs-string">&quot;to&quot;</span>: <span class="hljs-number">40</span>          &#125;,&#123;            <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-number">40</span>,            <span class="hljs-string">&quot;to&quot;</span>: <span class="hljs-number">50</span>          &#125;        ]      &#125;    &#125;  &#125;&#125;</code></pre><h3 id="tokenizer分词器"><a href="#tokenizer分词器" class="headerlink" title="tokenizer分词器"></a>tokenizer分词器</h3><ul><li>keyword分词器</li></ul><pre><code class="hljs json">GET /kibana_sample_data_ecommerce/_analyze&#123;  <span class="hljs-attr">&quot;text&quot;</span>: [<span class="hljs-string">&quot;Happy Birthday&quot;</span>],  <span class="hljs-attr">&quot;tokenizer&quot;</span>: <span class="hljs-string">&quot;keyword&quot;</span>&#125;结果：&#123;  <span class="hljs-attr">&quot;tokens&quot;</span> : [    &#123;      <span class="hljs-attr">&quot;token&quot;</span> : <span class="hljs-string">&quot;Happy Birthday&quot;</span>,      <span class="hljs-attr">&quot;start_offset&quot;</span> : <span class="hljs-number">0</span>,      <span class="hljs-attr">&quot;end_offset&quot;</span> : <span class="hljs-number">14</span>,      <span class="hljs-attr">&quot;type&quot;</span> : <span class="hljs-string">&quot;word&quot;</span>,      <span class="hljs-attr">&quot;position&quot;</span> : <span class="hljs-number">0</span>    &#125;  ]&#125;</code></pre><ul><li>standard标准分词器</li></ul><pre><code class="hljs awk">GET <span class="hljs-regexp">/kibana_sample_data_ecommerce/</span>_analyze&#123;  <span class="hljs-string">&quot;text&quot;</span>: [<span class="hljs-string">&quot;Happy Birthday&quot;</span>],  <span class="hljs-string">&quot;tokenizer&quot;</span>: <span class="hljs-string">&quot;standard&quot;</span>, <span class="hljs-regexp">//</span>使用standard  标准分词器  <span class="hljs-string">&quot;filter&quot;</span>: [<span class="hljs-string">&quot;lowercase&quot;</span>] <span class="hljs-regexp">//</span>转换为小写&#125;结果：&#123;  <span class="hljs-string">&quot;tokens&quot;</span> : [    &#123;      <span class="hljs-string">&quot;token&quot;</span> : <span class="hljs-string">&quot;happy&quot;</span>,      <span class="hljs-string">&quot;start_offset&quot;</span> : <span class="hljs-number">0</span>,      <span class="hljs-string">&quot;end_offset&quot;</span> : <span class="hljs-number">5</span>,      <span class="hljs-string">&quot;type&quot;</span> : <span class="hljs-string">&quot;&lt;ALPHANUM&gt;&quot;</span>,      <span class="hljs-string">&quot;position&quot;</span> : <span class="hljs-number">0</span>    &#125;,    &#123;      <span class="hljs-string">&quot;token&quot;</span> : <span class="hljs-string">&quot;birthday&quot;</span>,      <span class="hljs-string">&quot;start_offset&quot;</span> : <span class="hljs-number">6</span>,      <span class="hljs-string">&quot;end_offset&quot;</span> : <span class="hljs-number">14</span>,      <span class="hljs-string">&quot;type&quot;</span> : <span class="hljs-string">&quot;&lt;ALPHANUM&gt;&quot;</span>,      <span class="hljs-string">&quot;position&quot;</span> : <span class="hljs-number">1</span>    &#125;  ]&#125;</code></pre><h3 id="Spring-Data-Elasticsearch"><a href="#Spring-Data-Elasticsearch" class="headerlink" title="Spring Data Elasticsearch"></a>Spring Data Elasticsearch</h3><p>​    可以使用RestClient(RestHighLevelClient)、Jest、SpringDataElasticsearch</p><h4 id="RestHighLevelClient"><a href="#RestHighLevelClient" class="headerlink" title="RestHighLevelClient"></a>RestHighLevelClient</h4><p>_My Project.spring-elasticsearch</p><h4 id="Jest"><a href="#Jest" class="headerlink" title="Jest"></a>Jest</h4><p>引入依赖 （就不需要再引入elasticsearch的依赖了）</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/io.searchbox/jest --&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>io.searchbox<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jest<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>6.3.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><p>直接注入bean，不需要自己配置bean</p><pre><code class="hljs java"><span class="hljs-meta">@Autowired</span>JestClient jestClient;</code></pre><p>添加索引</p><pre><code class="hljs java"><span class="hljs-keyword">import</span> io.searchbox.core.Index;</code></pre><pre><code class="hljs java">Player player = <span class="hljs-keyword">new</span> Player(...);Index index = <span class="hljs-keyword">new</span> Index.Builder(player).index(<span class="hljs-string">&quot;索引&quot;</span>).type(<span class="hljs-string">&quot;类型&quot;</span>).build();<span class="hljs-keyword">try</span>&#123;jestClient.execute(index);&#125;<span class="hljs-keyword">catch</span> (IOException e)&#123;e.printStackTrace();&#125;</code></pre><p>…</p><h4 id="SpringDataElasticsearch"><a href="#SpringDataElasticsearch" class="headerlink" title="SpringDataElasticsearch"></a>SpringDataElasticsearch</h4><p>依赖</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-data-elasticsearch<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><span class="hljs-comment">&lt;!--需要使用json--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.google.code.gson<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>gson<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.8.5<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><p>实体类</p><pre><code class="hljs java"><span class="hljs-meta">@Document(indexName=&quot;nba&quot;, type=&quot;player&quot;)</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Player</span></span>&#123;...&#125;</code></pre><p>repository接口</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">PlayerRepo</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ElasticsearchRepository</span>&lt;<span class="hljs-title">Player</span>, <span class="hljs-title">Integer</span>&gt;</span>&#123;&#125;</code></pre><p>注入bean即可使用</p><pre><code class="hljs java"><span class="hljs-meta">@Autowired</span>PlayerRepo playerRepo;</code></pre><p>添加索引</p><pre><code class="hljs java">playerRepo.index(<span class="hljs-keyword">new</span> Player(...));</code></pre><p>使用接口的方法即可</p>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>todo</tag>
      
      <tag>分布式</tag>
      
      <tag>搜索引擎</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RPC:Remote Procedure Call</title>
    <link href="/blog/2021/01/01/0_todo_%E5%88%86%E5%B8%83%E5%BC%8F_RPC/"/>
    <url>/blog/2021/01/01/0_todo_%E5%88%86%E5%B8%83%E5%BC%8F_RPC/</url>
    
    <content type="html"><![CDATA[<h2 id="RPC和HTTP区别"><a href="#RPC和HTTP区别" class="headerlink" title="RPC和HTTP区别"></a>RPC和HTTP区别</h2><p>在OSI中所处的层就不同，HTTP是在TCP的基础上，RPC是自己实现的传输层协议。</p><p>OSI分层</p><blockquote><p>应用层（应用层+表示层+会话层）</p><p>传输层</p><p>网络层</p><p>链路层</p><p>物理层</p></blockquote><p>HTTP是应用层的协议，自己是此案</p><p>性能对两者来说并不是重点,因为RPC也有使用HTTP协议的,比如JSON-RPC,使用场景是两者的最大区别:RPC场景是公司内部互相调用.最大的好处是包装合理的RPC你会觉得他就是本地的一个库或者内置函数.对于开发人员来说,无需处理请求返回的问题.编写代码的时候几乎无感,开发效率高(你可以想象一下一个模块中需要进行几十次的发送请求处理返回状态和返回体是多么的令人崩溃),HTTP reset的场景是对外服务,(这个对外值的是可控团体之外,一般理解为公司外部即可),需要进行请求和响应的处理.一般用于事务型接口(一个接口对应一个事务).</p><p>todo todo todo</p><p>todo  写个RPC框架</p>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>todo</tag>
      
      <tag>OSI</tag>
      
      <tag>RPC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>EA-对象逃逸</title>
    <link href="/blog/2021/01/01/1_redo_Java_%E5%AF%B9%E8%B1%A1%E9%80%83%E9%80%B8EA&amp;%E9%94%81%E4%BC%98%E5%8C%96/"/>
    <url>/blog/2021/01/01/1_redo_Java_%E5%AF%B9%E8%B1%A1%E9%80%83%E9%80%B8EA&amp;%E9%94%81%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="逃逸分析-Escape-Analysis-简称-EA"><a href="#逃逸分析-Escape-Analysis-简称-EA" class="headerlink" title="逃逸分析 Escape Analysis  简称 EA"></a>逃逸分析 Escape Analysis  简称 EA</h1><p>EA允许java编译器在多种情况下优化我们的代码。</p><p><a href="https://blog.csdn.net/wolfcode_cn/article/details/83058235">https://blog.csdn.net/wolfcode_cn/article/details/83058235</a></p><h2 id="对象逃逸-的-三种状态"><a href="#对象逃逸-的-三种状态" class="headerlink" title="对象逃逸 的 三种状态"></a>对象逃逸 的 三种状态</h2><ul><li><p>全局级别逃逸 全局逃逸状态</p><blockquote><p>一个对象可能从一个方法或当前线程中逃逸。</p><ol><li><p>如果一个对象被作为方法的返回值，</p></li><li><p>作为类静态字段 static field</p><blockquote><p>所以肯定存在堆内存。</p></blockquote></li><li><p>作为类字段 field</p></li><li><p>重写了finalize()方法</p><blockquote><p>这要求这个对象对JVM的finalizer必须是可见的，所以必须分配在堆内存。</p></blockquote><blockquote><p>finalize()方法没啥意义，为了方便c/c++程序员适应java的。这里用来举例。</p></blockquote></li></ol><p>就会被标记为全集逃逸状态。</p></blockquote><p><strong>全局逃逸状态的对象一定会放入堆内存中。</strong></p></li><li><p>参数级别逃逸</p><blockquote><p>一个对象被作为参数传递给了一个方法，这个方法之外的还是无法访问该对象的(对其他线程不可见)，这个对象就会被标记为参数级别逃逸。</p></blockquote></li><li><p>无逃逸状态</p><blockquote><p>不产生逃逸。</p></blockquote></li></ul><h2 id="推论"><a href="#推论" class="headerlink" title="推论"></a>推论</h2><ul><li><p>理论上，无逃逸状态的对象不必须存储在堆空间中，那就是可以直接在栈上分配内存，甚至直接在CPU寄存器中分配空间，效率极高。</p></li><li><p>参数级别逃逸是可能在内存中去掉对象同步锁的，因为该对象不能被其他线程访问到。</p><blockquote><p>同步的代价很大，去掉同步锁可以提高并发性能。</p></blockquote></li><li><p>无逃逸状态</p><blockquote><p>标量替换：java虚拟机中的原始数据类型(int,long等)都不能在进一步分解，他们就可以成为标量。相对的，如果一个数据可以继续分解，那么他成为聚合量，java中最典型的聚合量就是对象。如果逃逸分析证明一个对象不会被外部访问，并且这个这个对象是可以分解的，那么程序真正执行的时候可能不创建这个对象，而改为直接创建它的若干个被这个方法能够使用到的成员变量来代替。拆散后的变量便可以被单独的分析与优化，可以分别分配在栈帧或者寄存器上，原来的对象就不需要整体被分配在堆中。</p></blockquote></li></ul><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>一个方法中new一个对象并作为返回值return出去的时候，该返回的对象就是全局逃逸状态。</p><p>如果在方法的参数中就传入承载计算结果的容器，在把这个方法计算的结果存入该参数，不用设置该大对象为返回值。</p><blockquote><p>例如</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> Object <span class="hljs-title">doSomething</span><span class="hljs-params">(Object arg1, Object arg2)</span></span>&#123;<span class="hljs-comment">//do something...</span>Object result = <span class="hljs-keyword">new</span> Object();<span class="hljs-keyword">return</span> result;&#125;;</code></pre><p>改为</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">doSomething</span><span class="hljs-params">(Object arg1, Object arg2, Object result)</span></span>&#123;&#125;;</code></pre></blockquote><p>就不会有全局对象逃逸，参数级别逃逸就可能去掉同步锁，可以提高并发性能。</p><p>在一个线程中的一串任务中如果都使用这种方式，就可能节省堆空间，降低gc的压力。提高程序的性能。</p><p>1.6的一个锁优化：锁消除</p><p>如果锁定的变量根本不会被其他线程访问到，这个加锁就是没必要的。</p><blockquote><p>写代码的人应该是很清楚这个同步有没有必要，但是代码编译之后可能就会被加上一些同步操作，或者一些框架内部可能用到了synchronized。</p></blockquote><p>所以JVM会根据对象是否逃逸来判断是否可以进行锁消除。</p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>zookeeper</title>
    <link href="/blog/2021/01/01/1_redo_%E5%88%86%E5%B8%83%E5%BC%8F_Zookeeper/"/>
    <url>/blog/2021/01/01/1_redo_%E5%88%86%E5%B8%83%E5%BC%8F_Zookeeper/</url>
    
    <content type="html"><![CDATA[<h1 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h1><p>分布式协调服务，为其他分布式应用程序提供基本的同步和组服务</p><p>为了可靠性，不能一个宕机就完蛋，也要搭建集群，搭建集群就分布式，分布式就要保证一致性，一致性的解决方案。。又是Paxos</p><p>选举一个leader，发送提案，多半同意则发送提交，</p><blockquote><p>这里会有个问题 <a href="https://www.zhihu.com/question/324291664">https://www.zhihu.com/question/324291664</a></p><p><a href="https://www.zhihu.com/question/324291664/answer/909822937">https://www.zhihu.com/question/324291664/answer/909822937</a> 这个答案很清楚。 （就是依靠 最少半数节点+读时检测 保证的一致性）</p></blockquote><p>因为要保证一致性，所以节点越多性能就越低，一般3、5个节点即可</p><blockquote><p>奇数就是因为 保证节点一致性需要超过半数同意提案嘛， 5个节点和6个节点都需要3个节点同意才行，所以六个节点多出来那个没必要，还会增加节点通信的开销。</p></blockquote><h2 id="ZAB-zookeeper原子广播协议"><a href="#ZAB-zookeeper原子广播协议" class="headerlink" title="ZAB zookeeper原子广播协议"></a>ZAB zookeeper原子广播协议</h2><p>Paxos的简单实现吧</p><h2 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h2><p>镜像下载链接：</p><p><a href="https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.14/">https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.14/</a></p><p>zookeeper读取/conf/zoo.cfg文件作为配置文件，可复制zoo_simple.cfg在修改</p><pre><code class="hljs mipsasm"><span class="hljs-keyword">bin/zkServer.sh </span>start <span class="hljs-comment">#启动zk服务</span><span class="hljs-keyword">bin/zkServer.sh </span>status <span class="hljs-comment">#查看zk服务的状态</span><span class="hljs-keyword">bin/zkServer.sh </span>restart <span class="hljs-comment">#重启</span><span class="hljs-keyword">bin/zkServer.sh </span>stop <span class="hljs-comment">#停止</span><span class="hljs-keyword">bin/zkCli.sh </span><span class="hljs-comment">#连接zk服务  -server host:port</span></code></pre><pre><code class="hljs jboss-cli"><span class="hljs-keyword">ls</span> / <span class="hljs-comment">#查看根目录下的内容</span><span class="hljs-keyword">ls</span>2 / <span class="hljs-comment">#查看根目录下的内容和更新次数等具体信息</span>create <span class="hljs-string">/test</span> <span class="hljs-string">&quot;info1&quot;</span> <span class="hljs-comment">#创建一个新的znode节点，和关联的字符串</span>get <span class="hljs-string">/test</span><span class="hljs-keyword">set</span> <span class="hljs-string">/test</span> <span class="hljs-string">&quot;info-update&quot;</span>delete <span class="hljs-string">/test</span> <span class="hljs-comment">#删除节点</span><span class="hljs-keyword">quit</span> <span class="hljs-comment">#退出客户端</span></code></pre><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-built_in">stat</span> | nc 127.0.0.1 2181 <span class="hljs-comment">#来查看哪个节点被选择作为follower或者leader</span><span class="hljs-built_in">echo</span> ruok | nc 127.0.0.1 2181 <span class="hljs-comment">#测试是否启动了该Server，若回复imok表示已经启动。</span><span class="hljs-built_in">echo</span> dump | nc 127.0.0.1 2181 <span class="hljs-comment">#列出未经处理的会话和临时节点。</span><span class="hljs-built_in">echo</span> <span class="hljs-built_in">kill</span> | nc 127.0.0.1 2181 <span class="hljs-comment">#关掉server</span><span class="hljs-built_in">echo</span> conf | nc 127.0.0.1 2181 <span class="hljs-comment">#输出相关服务配置的详细信息。</span><span class="hljs-built_in">echo</span> cons | nc 127.0.0.1 2181 <span class="hljs-comment">#列出所有连接到服务器的客户端的完全的连接 / 会话的详细信息。</span><span class="hljs-built_in">echo</span> envi | nc 127.0.0.1 2181 <span class="hljs-comment">#输出关于服务环境的详细信息（区别于 conf 命令）。</span><span class="hljs-built_in">echo</span> reqs | nc 127.0.0.1 2181 <span class="hljs-comment">#列出未经处理的请求。</span><span class="hljs-built_in">echo</span> wchs | nc 127.0.0.1 2181 <span class="hljs-comment">#列出服务器 watch 的详细信息。</span><span class="hljs-built_in">echo</span> wchc | nc 127.0.0.1 2181 <span class="hljs-comment">#通过 session 列出服务器 watch 的详细信息，它的输出是一个与 watch 相关的会话的列表。</span><span class="hljs-built_in">echo</span> wchp | nc 127.0.0.1 2181 <span class="hljs-comment">#通过路径列出服务器 watch 的详细信息。它输出一个与 session 相关的路径。</span></code></pre>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redo</tag>
      
      <tag>分布式协调服务</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>幂等性设计</title>
    <link href="/blog/2021/01/01/1_redo_%E6%9E%B6%E6%9E%84_%E5%B9%82%E7%AD%89%E6%80%A7%E8%AE%BE%E8%AE%A1/"/>
    <url>/blog/2021/01/01/1_redo_%E6%9E%B6%E6%9E%84_%E5%B9%82%E7%AD%89%E6%80%A7%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<p>如何保证幂等性</p><ol><li><p>在数据库利用唯一索引。</p><blockquote><p>比如生成订单的时候，不能因为网络延迟而创建两次这个订单，所以可以根据这个订单的唯一id。</p><p>第一个 insert 执行之后已经有了这个订单，下次 insert 的时候会报错，可以直接 try-catch 这个异常，在catch中 select by id 查询这个订单，查询到的结果也就是 insert 的期望结果了。</p></blockquote><blockquote><p>不过要利用这个唯一索引的话，订单的 id 肯定是要相同的生成策略，比如使用相同算法生成，重复生成这个订单的时候，算法入参也是相同的，才能得到相同的订单id。比如根据用户id等等。</p></blockquote><blockquote><p>或者使用 唯一组合索引来创建。</p></blockquote></li><li><p>session-token 来防止表单重复提交</p><blockquote><p>前端生成表单之前先从后端得到一个 form-token ，请求到后端之后，后端先对这个token进行验证，然后修改session中的token。这样重复提交的表单所携带的token就会是无效的token。</p></blockquote></li><li><p>对外提供幂等接口</p><blockquote><p>对外提供接口的api如何保证幂等<br>如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号；source+seq在数据库里面做唯一索引，防止多次付款(并发时，只能处理一个请求) 。<br>重点：对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。</p></blockquote></li></ol><p>啥啊 todo todo todo </p><p>参考：</p><p><a href="https://www.cnblogs.com/linjiqin/p/9678022.html">https://www.cnblogs.com/linjiqin/p/9678022.html</a></p>]]></content>
    
    
    <categories>
      
      <category>架构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git</title>
    <link href="/blog/2021/01/01/Basics_Git/"/>
    <url>/blog/2021/01/01/Basics_Git/</url>
    
    <content type="html"><![CDATA[<h5 id="初始化成git仓库"><a href="#初始化成git仓库" class="headerlink" title="初始化成git仓库"></a>初始化成git仓库</h5><p><code>git init</code></p><h5 id="绑定到远程仓库"><a href="#绑定到远程仓库" class="headerlink" title="绑定到远程仓库"></a>绑定到远程仓库</h5><p><code>git remote add origin https://xxx.git</code></p><h5 id="第一次push-的时候携带的参数"><a href="#第一次push-的时候携带的参数" class="headerlink" title="第一次push 的时候携带的参数"></a>第一次push 的时候携带的参数</h5><p><code>git push -u origin master</code></p><h2 id="revert"><a href="#revert" class="headerlink" title="revert"></a>revert</h2><p><code>git revert HEAD^</code>  <code>git revert HEAD^^</code>  <code>git revert HEAD~3</code>   一个^就是前1次commit </p><p><code>git revert &lt;commitId&gt;</code>  revert 到指定的commit版本</p><p>会再生成一次commit，并且当前代码和指定的那次commit的代码一致。</p><h2 id="reset"><a href="#reset" class="headerlink" title="reset"></a>reset</h2><p>用<code>reset</code>回滚，参数：</p><blockquote><ul><li>git reset –soft                          保留工作目录，并把新的全部差异放进暂存区</li></ul><blockquote><p>原节点和Reset节点之间的所有差异都会放到暂存区中</p></blockquote><ul><li><p>git reset (git reset –mixed)    保留工作目录，清空暂存区</p></li><li><p>git reset –hard                         清空工作目录，清空暂存区，全部和git log 中的上n次commit内容相同</p><blockquote><p>然后push的话会报错，‘必须先pull’ 才能push， 但是pull，会把刚才回退的commit又带出来，所以得 push -f   （强制）</p></blockquote></li></ul></blockquote><blockquote><p> soft 和 mixed 区别应该就是 mixed 不需要再手动 add 而 soft 需要自己再手动 add 然后 commit。</p></blockquote><h2 id="修改commit的msg"><a href="#修改commit的msg" class="headerlink" title="修改commit的msg"></a>修改commit的msg</h2><p><code>git commit --amend</code><br>会进入vim，修改保存就行了</p><h3 id="如果commit已经被覆盖"><a href="#如果commit已经被覆盖" class="headerlink" title="如果commit已经被覆盖"></a>如果commit已经被覆盖</h3><p><code>git rebase -i HEAD^</code> </p><p><code>git rebase -i HEAD~n</code> n是逆推几次</p><pre><code class="hljs awk">pick <span class="hljs-number">07</span>bca843 添加 广告线索来源构成分析、概览 接口 <span class="hljs-regexp">/source-ad/</span>constitute、<span class="hljs-regexp">/source-ad/</span>listpick <span class="hljs-number">67</span>d1e638 移除<span class="hljs-regexp">/income/</span>top</code></pre><p>将开头的pick修改为edit就可以编辑了<br>然后git会提示</p><pre><code class="hljs sql">You can amend the <span class="hljs-keyword">commit</span> now, <span class="hljs-keyword">with</span>  git <span class="hljs-keyword">commit</span> <span class="hljs-comment">--amend</span>Once you <span class="hljs-keyword">are</span> satisfied <span class="hljs-keyword">with</span> your changes, run  git rebase <span class="hljs-comment">--continue</span></code></pre><p><code>git commit --amend</code> 进入修改<br>完事continue rebase 即可<br><code>git rebase --continue</code></p><p>​             </p><h2 id="git-diff"><a href="#git-diff" class="headerlink" title="git diff"></a>git diff</h2><p><code>git diff --cached</code> 查看本地分支和当前代码的区别</p><h2 id="统计git-log"><a href="#统计git-log" class="headerlink" title="统计git log"></a>统计git log</h2><pre><code class="hljs apache"><span class="hljs-attribute">git</span> log --author=<span class="hljs-string">&quot;$(git config --get user.name)&quot;</span> --since=<span class="hljs-number">2021</span>-<span class="hljs-number">01</span>-<span class="hljs-number">01</span> --until=<span class="hljs-number">2021</span>-<span class="hljs-number">03</span>-<span class="hljs-number">30</span> --pretty=tformat: --numstat | gawk &#x27;&#123; add += $<span class="hljs-number">1</span> ; subs += $<span class="hljs-number">2</span> ; loc += $<span class="hljs-number">1</span> - $<span class="hljs-number">2</span> &#125; END &#123; printf <span class="hljs-string">&quot;增加的行数:%s 删除的行数:%s 总行数: %s\n&quot;</span>,add,subs,loc &#125;&#x27;</code></pre>]]></content>
    
    
    <categories>
      
      <category>basics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>note</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>WSL</title>
    <link href="/blog/2021/01/01/Basics_WSL/"/>
    <url>/blog/2021/01/01/Basics_WSL/</url>
    
    <content type="html"><![CDATA[<pre><code class="hljs dos"><span class="hljs-built_in">net</span> stop LxssManager 停止子系统服务<span class="hljs-built_in">net</span> <span class="hljs-built_in">start</span> LxssManager 开启子系统服务</code></pre><hr><h3 id="linux-查看进程相关参数的命令"><a href="#linux-查看进程相关参数的命令" class="headerlink" title="linux 查看进程相关参数的命令"></a>linux 查看进程相关参数的命令</h3><p><code>lsof -i:3306</code> 查看3306端口</p><p><code>netstat -tap |grep mysql</code> 查看mysql进程占用的端口</p><hr><h3 id="zsh"><a href="#zsh" class="headerlink" title="zsh"></a>zsh</h3><ol><li>安装 <code>sudo apt-get install zsh</code></li><li>设置默认shell <code>chsh -s /bin/zsh</code>，重启(WSL)生效<blockquote><p>查看当前默认shell <code>echo $SHELL</code><br>查看已安装shell <code>cat /etc/shells</code></p></blockquote></li></ol><hr><h3 id="oh-my-zsh"><a href="#oh-my-zsh" class="headerlink" title="oh-my-zsh"></a>oh-my-zsh</h3><blockquote><p>先安装git <code>apt</code></p><ol><li>安装，去官网下载install.sh <del>已经copy了官网脚本：[oh-my-zsh   install.sh</del>](<a href="http://47.94.212.95:20000/upload/2020/10/oh-my-zsh-install-486bace8f443481b98be1f9d4700f222.sh">http://47.94.212.95:20000/upload/2020/10/oh-my-zsh-install-486bace8f443481b98be1f9d4700f222.sh</a>)<br><code> sh -c &quot;$(curl -fsSL http://47.94.212.95:20000/upload/2020/10/oh-my-zsh-install-486bace8f443481b98be1f9d4700f222.sh)&quot; </code></li><li>主题列表<br><code>https://github.com/ohmyzsh/ohmyzsh/wiki/Themes-%28legacy%29</code></li><li>oh-my-zsh的配置文件: <code>~/.zshrc</code>, 下方有模板</li></ol></blockquote><blockquote><p><code>ZSH_THEME=&quot;agnoster&quot;</code><br>4. 插件<br>语法高亮,官方md<br><code>https://github.com/zsh-users/zsh-syntax-highlighting/blob/master/INSTALL.md</code></p><ol><li><p>(找个路径)下载插件<br><code>git clone https://github.com/zsh-users/zsh-syntax-highlighting.git</code></p></li><li><p>编辑 ~/.zshrc<br><code>echo &quot;source $&#123;(q-)PWD&#125;/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh&quot; &gt;&gt; $&#123;ZDOTDIR:-$HOME&#125;/.zshrc</code></p></li><li><p>source生效<br><code>source ./zsh-syntax-highlighting/zsh-syntax-highlighting.zsh</code></p></li></ol></blockquote><blockquote><p>命令补全plugin</p><ol><li>zsh-autosuggestions<blockquote><ol><li><code>git clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions</code></li><li>在~/.zshrc添加插件：<code>plugins=(git zsh-autosuggestions)</code></li><li>重启终端</li></ol></blockquote></li><li>incr<blockquote><p><img src="http://47.94.212.95:20000/upload/2020/10/image-664ef5bfb6a7471ea0eafbac580441b7.png" alt="incr"></p><ol><li><code>wget http://mimosa-pudica.net/src/incr-0.2.zsh    ~/.oh-my-zsh/plugins/incr/incr*.zsh</code></li><li>在~/.zshrc添加：<code>source ~/.oh-my-zsh/plugins/incr/incr*.zsh</code></li><li>重启终端</li></ol></blockquote></li></ol></blockquote><hr><h3 id="更换apt国内镜像"><a href="#更换apt国内镜像" class="headerlink" title="更换apt国内镜像"></a>更换apt国内镜像</h3><ol><li><p>备份原配置文件</p><p><code>sudo cp /etc/apt/sources.list /etc/apt/sources.list.def</code></p></li><li><p>编辑配置文件</p><p><code>sudo vim /etc/apt/sources.list</code></p><blockquote><p>deb <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial main restricted universe multiverse<br>deb <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial-security main restricted universe multiverse<br>deb <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial-updates main restricted universe multiverse<br>deb <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial-proposed main restricted universe multiverse<br>deb <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial-backports main restricted universe multiverse<br>deb-src <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial main restricted universe multiverse<br>deb-src <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial-security main restricted universe multiverse<br>deb-src <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial-updates main restricted universe multiverse<br>deb-src <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial-proposed main restricted universe multiverse<br>deb-src <a href="http://mirrors.ustc.edu.cn/ubuntu/">http://mirrors.ustc.edu.cn/ubuntu/</a> xenial-backports main restricted universe multiverse</p></blockquote><blockquote><p>deb-src <a href="http://archive.ubuntu.com/ubuntu">http://archive.ubuntu.com/ubuntu</a> xenial main restricted #Added by software-properties<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial main restricted<br>deb-src <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial main restricted multiverse universe #Added by software-properties<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-updates main restricted<br>deb-src <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-updates main restricted multiverse universe #Added by software-properties<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial universe<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-updates universe<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial multiverse<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-updates multiverse<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-backports main restricted universe multiverse<br>deb-src <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-backports main restricted universe multiverse #Added by software-properties<br>deb <a href="http://archive.canonical.com/ubuntu">http://archive.canonical.com/ubuntu</a> xenial partner<br>deb-src <a href="http://archive.canonical.com/ubuntu">http://archive.canonical.com/ubuntu</a> xenial partner<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-security main restricted<br>deb-src <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-security main restricted multiverse universe #Added by software-properties<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-security universe<br>deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> xenial-security multiverse</p></blockquote><blockquote><p>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial main restricted<br>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial-updates main restricted<br>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial universe<br>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial-updates universe<br>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial multiverse<br>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial-updates multiverse<br>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial-backports main restricted universe multiverse<br>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial-security main restricted<br>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial-security universe<br>deb <a href="http://mirrors.tuna.tsinghua.edu.cn/ubuntu/">http://mirrors.tuna.tsinghua.edu.cn/ubuntu/</a> xenial-security multiverse</p></blockquote><blockquote><p>deb <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic main restricted universe multiverse<br>deb <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic-security main restricted universe multiverse<br>deb <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic-updates main restricted universe multiverse<br>deb <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic-proposed main restricted universe multiverse<br>deb <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic-backports main restricted universe multiverse<br>deb-src <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic main restricted universe multiverse<br>deb-src <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic-security main restricted universe multiverse<br>deb-src <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic-updates main restricted universe multiverse<br>deb-src <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic-proposed main restricted universe multiverse<br>deb-src <a href="http://mirrors.163.com/ubuntu/">http://mirrors.163.com/ubuntu/</a> bionic-backports main restricted universe multiverse</p></blockquote></li><li><p>更新软件包</p><p><code>sudo apt-get update</code></p></li><li><p>修复损坏的软件包，尝试卸载出错的软件包，重装正确版本</p><p><code>sudo apt-get -f install</code></p></li><li><p>升级系统中所有软件包</p><p><code>sudo apt-get -y upgrade</code></p></li></ol><hr><h3 id="zshrc模板"><a href="#zshrc模板" class="headerlink" title="~/.zshrc模板"></a>~/.zshrc模板</h3><pre><code class="hljs vala"><span class="hljs-meta"># If you come from bash you might have to change your $PATH.</span><span class="hljs-meta"># export PATH=$HOME/bin:/usr/local/bin:$PATH</span><span class="hljs-meta"># Path to your oh-my-zsh installation.</span>  export ZSH=<span class="hljs-string">&quot;/home/yeyuntian/.oh-my-zsh&quot;</span><span class="hljs-meta"># Set name of the theme to load --- if set to &quot;random&quot;, it will</span><span class="hljs-meta"># load a random theme each time oh-my-zsh is loaded, in which case,</span><span class="hljs-meta"># to know which specific one was loaded, run: echo $RANDOM_THEME</span><span class="hljs-meta"># See https://github.com/robbyrussell/oh-my-zsh/wiki/Themes</span>ZSH_THEME=<span class="hljs-string">&quot;robbyrussell&quot;</span><span class="hljs-meta"># Set list of themes to pick from when loading at random</span><span class="hljs-meta"># Setting this variable when ZSH_THEME=random will cause zsh to load</span><span class="hljs-meta"># a theme from this variable instead of looking in ~/.oh-my-zsh/themes/</span><span class="hljs-meta"># If set to an empty array, this variable will have no effect.</span><span class="hljs-meta"># ZSH_THEME_RANDOM_CANDIDATES=( &quot;robbyrussell&quot; &quot;agnoster&quot; )</span><span class="hljs-meta"># Uncomment the following line to use case-sensitive completion.</span><span class="hljs-meta"># CASE_SENSITIVE=&quot;true&quot;</span><span class="hljs-meta"># Uncomment the following line to use hyphen-insensitive completion.</span><span class="hljs-meta"># Case-sensitive completion must be off. _ and - will be interchangeable.</span><span class="hljs-meta"># HYPHEN_INSENSITIVE=&quot;true&quot;</span><span class="hljs-meta"># Uncomment the following line to disable bi-weekly auto-update checks.</span><span class="hljs-meta"># DISABLE_AUTO_UPDATE=&quot;true&quot;</span><span class="hljs-meta"># Uncomment the following line to change how often to auto-update (in days).</span><span class="hljs-meta"># export UPDATE_ZSH_DAYS=13</span><span class="hljs-meta"># Uncomment the following line to disable colors in ls.</span><span class="hljs-meta"># DISABLE_LS_COLORS=&quot;true&quot;</span><span class="hljs-meta"># Uncomment the following line to disable auto-setting terminal title.</span><span class="hljs-meta"># DISABLE_AUTO_TITLE=&quot;true&quot;</span><span class="hljs-meta"># Uncomment the following line to enable command auto-correction.</span><span class="hljs-meta"># ENABLE_CORRECTION=&quot;true&quot;</span><span class="hljs-meta"># Uncomment the following line to display red dots whilst waiting for completion.</span><span class="hljs-meta"># COMPLETION_WAITING_DOTS=&quot;true&quot;</span><span class="hljs-meta"># Uncomment the following line if you want to disable marking untracked files</span><span class="hljs-meta"># under VCS as dirty. This makes repository status check for large repositories</span><span class="hljs-meta"># much, much faster.</span><span class="hljs-meta"># DISABLE_UNTRACKED_FILES_DIRTY=&quot;true&quot;</span><span class="hljs-meta"># Uncomment the following line if you want to change the command execution time</span><span class="hljs-meta"># stamp shown in the history command output.</span><span class="hljs-meta"># You can set one of the optional three formats:</span><span class="hljs-meta"># &quot;mm/dd/yyyy&quot;|&quot;dd.mm.yyyy&quot;|&quot;yyyy-mm-dd&quot;</span><span class="hljs-meta"># or set a custom format using the strftime function format specifications,</span><span class="hljs-meta"># see &#x27;man strftime&#x27; for details.</span><span class="hljs-meta"># HIST_STAMPS=&quot;mm/dd/yyyy&quot;</span><span class="hljs-meta"># Would you like to use another custom folder than $ZSH/custom?</span><span class="hljs-meta"># ZSH_CUSTOM=/path/to/new-custom-folder</span><span class="hljs-meta"># Which plugins would you like to load?</span><span class="hljs-meta"># Standard plugins can be found in ~/.oh-my-zsh/plugins/*</span><span class="hljs-meta"># Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/</span><span class="hljs-meta"># Example format: plugins=(rails git textmate ruby lighthouse)</span><span class="hljs-meta"># Add wisely, as too many plugins slow down shell startup.</span>plugins=(  git)source $ZSH/oh-my-zsh.sh<span class="hljs-meta"># User configuration</span><span class="hljs-meta"># export MANPATH=&quot;/usr/local/man:$MANPATH&quot;</span><span class="hljs-meta"># You may need to manually set your language environment</span><span class="hljs-meta"># export LANG=en_US.UTF-8</span><span class="hljs-meta"># Preferred editor for local and remote sessions</span><span class="hljs-meta"># if [[ -n $SSH_CONNECTION ]]; then</span><span class="hljs-meta">#   export EDITOR=&#x27;vim&#x27;</span><span class="hljs-meta"># else</span><span class="hljs-meta">#   export EDITOR=&#x27;mvim&#x27;</span><span class="hljs-meta"># fi</span><span class="hljs-meta"># Compilation flags</span><span class="hljs-meta"># export ARCHFLAGS=&quot;-arch x86_64&quot;</span><span class="hljs-meta"># ssh</span><span class="hljs-meta"># export SSH_KEY_PATH=&quot;~/.ssh/rsa_id&quot;</span><span class="hljs-meta"># Set personal aliases, overriding those provided by oh-my-zsh libs,</span><span class="hljs-meta"># plugins, and themes. Aliases can be placed here, though oh-my-zsh</span><span class="hljs-meta"># users are encouraged to define aliases within the ZSH_CUSTOM folder.</span><span class="hljs-meta"># For a full list of active aliases, run `alias`.</span><span class="hljs-meta">#</span><span class="hljs-meta"># Example aliases</span><span class="hljs-meta"># alias zshconfig=&quot;mate ~/.zshrc&quot;</span><span class="hljs-meta"># alias ohmyzsh=&quot;mate ~/.oh-my-zsh&quot;</span></code></pre><h2 id="install-mysql"><a href="#install-mysql" class="headerlink" title="install mysql"></a>install mysql</h2><p>安装<code>sudo apt install mysql-server-5.7</code></p><p>连接<code>mysql -p</code></p><p>密码<code>123456</code></p><p>添加数据库<code>create database melopozDB</code></p><p>查看db<code>show databases</code></p><p>配置文件在</p><p>mysqld 在 <code>/etc/mysql/mysql.conf.d/mysqld.cnf</code></p><p>mysql   在 <code>/etc/mysql/conf.d/mysql.cnf</code></p><p>client    在 <code>/etc/mysql/debian.cnf</code></p><p>设置默认字符集<code>utf8mb4</code></p><blockquote><p>在 【client】下追加：</p><p>default-character-set=utf8</p><p>在 【mysqld】下追加：</p><p>character-set-server=utf8</p><p>在 【mysql】 下追加：</p><p>default-character-set=utf8</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>basics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>note</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tail关键词高亮</title>
    <link href="/blog/2021/01/01/Basics_tail%E5%85%B3%E9%94%AE%E5%AD%97%E9%AB%98%E4%BA%AE/"/>
    <url>/blog/2021/01/01/Basics_tail%E5%85%B3%E9%94%AE%E5%AD%97%E9%AB%98%E4%BA%AE/</url>
    
    <content type="html"><![CDATA[<pre><code class="hljs apache"><span class="hljs-attribute">tail</span> -f system.log |grep <span class="hljs-string">&quot;/write-down&quot;</span> |grep <span class="hljs-string">&quot;payload=&quot;</span> | perl -pe &#x27;s/(visitType)|(visitTerminal)|(operateType)/\e[<span class="hljs-number">1</span>;<span class="hljs-number">33</span>m$<span class="hljs-number">1</span>\e[<span class="hljs-number">0</span>m\e[<span class="hljs-number">1</span>;<span class="hljs-number">33</span>m$<span class="hljs-number">2</span>\e[<span class="hljs-number">0</span>m\e[<span class="hljs-number">1</span>;<span class="hljs-number">33</span>m$<span class="hljs-number">3</span>\e[<span class="hljs-number">0</span>m/g&#x27;</code></pre><p><code>perl</code>命令 进行动态替换，格式：</p><pre><code class="hljs apache"><span class="hljs-attribute">perl</span> -pe &#x27;s/([关键词<span class="hljs-number">1</span>])|([关键词<span class="hljs-number">2</span>])/\e</code></pre><p>关键词部分：<code>s/([关键词1])|([关键词2])/</code><br>颜色部分：<code>\e[1;颜色1$1\e[背景颜色</code> <code>\e[1;颜色2$2\e[背景颜色</code></p><pre><code class="hljs subunit">字体颜色：30m：黑31m：红32m：绿33m：黄34m：蓝35m：紫36m：青37m：白背景颜色设置40<span class="hljs-string">-47</span> 黑、红、绿、黄、蓝、紫、青、白40：黑41：红42：绿43：黄44：蓝45：紫46：青47：白</code></pre>]]></content>
    
    
    <categories>
      
      <category>basics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>note</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/blog/2021/01/01/Basics_%E4%BD%8D%E8%BF%90%E7%AE%97&amp;%E8%A1%A5%E7%A0%81/"/>
    <url>/blog/2021/01/01/Basics_%E4%BD%8D%E8%BF%90%E7%AE%97&amp;%E8%A1%A5%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h2 id="Java中的位运算"><a href="#Java中的位运算" class="headerlink" title="Java中的位运算"></a>Java中的位运算</h2><p><code>&lt;&lt; / &gt;&gt;</code>：算数位移，符号位不变</p><p><code>&gt;&gt;&gt;</code>：逻辑位移，忽略符号位的含义，直接将所有bit右移</p><p>比如：<code>-2</code>用8位二进制表示：<code>1111 1110</code></p><p><strong>算数右移</strong>一位得到<code>-1</code>(八位二进制：<code>1111 1111</code>)</p><blockquote><p><code>1111 1110</code>, &gt;&gt;1: <code>0111 1111</code>, 保留符号位：<code>1111 1111</code>，二进制负数求值1)反码:<code>1000 0000</code>2）加1:<code>1000 0001</code></p></blockquote><p><strong>逻辑右移</strong>一位得到127(八位二进制：<code>0111 1111</code>)</p><blockquote><p><code>1111 1110</code>, &gt;&gt;1: <code>0111 1111</code> ，忽略第一位本应该表示的符号含义，结果变成了正数，直接计算值 2^7-1。</p><blockquote><p>如果用int类型，<code> -2&gt;&gt;1 = -1</code>，<code>-2&gt;&gt;&gt;1 = 2147483647</code></p></blockquote></blockquote><h2 id="补码"><a href="#补码" class="headerlink" title="补码"></a>补码</h2><blockquote><p>反码：正数时，跟原码一样；负数时，原码符号位除外，其他位按位取反</p></blockquote><blockquote><p>补码：正数时，跟原码一样；负数时，反码加一</p></blockquote><p>cpu只能处理加法，那减法怎么办 ？  补码相加</p><blockquote><p>比如  3 - 8：（ 3 + -8）</p><p>3:0000 0011</p><p>8:0000 1000</p><p>-8:1000 1000（第一位 符号位）</p><blockquote><p>3补:0000 0011（正整数的补码还是他本身）</p><p>-8补:1111 1000（除符号位之外取反，然后+1）</p><p>​    0000 0011</p><p>+ 1111 1000</p><p>=  1111 1011（不是最终结果）</p><p>=  1000 0101 （取反+1）</p><p>十进制表示 ： -5</p></blockquote></blockquote><p>如果是 8-3</p><blockquote><p>  0000 1000（8补）</p><p>  1000 0011（-3）</p><p>  1111 1101（-3补）</p><p>= 0000 0101（8补 + -3补）（非最终结果）</p><p>最终结果：取补码，还是 0000 0101</p><p>十进制表示：5</p></blockquote><p>乘法基于加法，除法基于乘法</p><h2 id="掩码-mask"><a href="#掩码-mask" class="headerlink" title="掩码 mask"></a>掩码 mask</h2><p>掩码（Mask），通过与目标数字（flag）的按位进行与运算，达到屏蔽指定位的效果。</p><p>比如我们可以定义常量<code>MASK=2</code>，即二进制<code>0000 0010</code>，待操作数<code>flag=11</code>，即<code>0000 1011</code>，那么： flag &amp; MASK =&gt;</p><pre><code class="hljs shell">    00000010 #mask&amp;   00001011 #flag    00000010 #result  相当与 用mask规定哪些是有效位（mask为1的bit是有效位）。</code></pre><p>可以看到，flag除了位1外，其他都被置0了，可以看出掩码的一个作用就是保留掩码为1 的位所对应操作数的位为1，其他位清零。</p>]]></content>
    
    
    <categories>
      
      <category>basics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>位运算</tag>
      
      <tag>二进制</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>死锁</title>
    <link href="/blog/2021/01/01/Basics_%E6%AD%BB%E9%94%81/"/>
    <url>/blog/2021/01/01/Basics_%E6%AD%BB%E9%94%81/</url>
    
    <content type="html"><![CDATA[<h1 id="四个必要条件"><a href="#四个必要条件" class="headerlink" title="四个必要条件"></a>四个必要条件</h1><ul><li>互斥</li><li>请求和保持（占有并等待）</li><li>不可剥夺（不能抢）</li><li>环路等待（循环等待）</li></ul><h1 id="预防死锁"><a href="#预防死锁" class="headerlink" title="预防死锁"></a>预防死锁</h1><ol><li>资源一次性分配（破坏请求条件）</li><li>一次性获取所有资源，不能全部获取就释放所有（破坏保持条件）</li><li>资源有序分配（按照一定算法对资源进行排序，按顺序拿资源）</li><li>资源可抢夺（需要设置优先级）</li></ol><blockquote><p>场景：两个人同时向对方转账。</p><p>解决方案：破坏 2 / 3 / 4</p><h5 id="破坏-2-不可抢占："><a href="#破坏-2-不可抢占：" class="headerlink" title="破坏 2 不可抢占："></a>破坏 2 不可抢占：</h5><p>synchronized不能实现。需要JUC的Lock。</p><h5 id="破坏-3-占有且等待："><a href="#破坏-3-占有且等待：" class="headerlink" title="破坏 3 占有且等待："></a>破坏 3 占有且等待：</h5><p>拿到所需全部资源再进行操作，不能全拿到就全放弃，<code>资源利用率低</code>。</p><h5 id="破坏-4-循环等待："><a href="#破坏-4-循环等待：" class="headerlink" title="破坏 4 循环等待："></a>破坏 4 循环等待：</h5><p>规定拿资源的顺序（给资源设定序号）（都按相同顺序加锁）。</p><blockquote><p>比如用相同的算法（eg：hashcode()）对资源进行标号，按照标号进行排序，拿锁的时候都按顺序拿，每个线程就会都先拿a的锁再拿b的锁。</p></blockquote></blockquote><h1 id="死锁检测"><a href="#死锁检测" class="headerlink" title="死锁检测"></a>死锁检测</h1><p>Jstack工具</p><p>java自带的jvisualvm</p><p>Jconsule工具</p><p>阿里Arthas  artha-boot.jar</p>]]></content>
    
    
    <categories>
      
      <category>basics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>并发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker</title>
    <link href="/blog/2021/01/01/CICD_Docker/"/>
    <url>/blog/2021/01/01/CICD_Docker/</url>
    
    <content type="html"><![CDATA[<h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><p>Docker本身是一个容器运行载体（或称为 管理引擎）。我们把应用程序和配置依赖打包成一个可交付的运行环境，这个环境就是image镜像文件。只有通过这个image才能生成Docker容器。</p><pre><code>image文件生成的容器实例，本身也是一个文件。一个容器运行一种服务，需要的时候就通过docker客户端创建一个对应的运行实例仓库就是存放一堆镜像的地方，可以吧镜像发布到仓库中，需要的时候pull。就像Git</code></pre><h2 id="三要素"><a href="#三要素" class="headerlink" title="三要素"></a>三要素</h2><blockquote><p>仓库 镜像image 容器</p></blockquote><table><thead><tr><th>docker</th><th>java</th></tr></thead><tbody><tr><td>仓库</td><td>包(存放多个镜像)</td></tr><tr><td>镜像</td><td>类</td></tr><tr><td>容器</td><td>对象</td></tr></tbody></table><h2 id="Dockerfile-镜像描述文件"><a href="#Dockerfile-镜像描述文件" class="headerlink" title="Dockerfile 镜像描述文件"></a>Dockerfile 镜像描述文件</h2><p>Dockerfile可以解放手工操作，保证环境统一</p><p>docker build 命令会根据Dockerfile文件自动构建镜像</p><blockquote><p>Hello.java    –&gt;  Hello.class<br>DockerFile   –&gt;  Docker images</p></blockquote><h2 id="Dockerfile-基础命令"><a href="#Dockerfile-基础命令" class="headerlink" title="Dockerfile 基础命令"></a>Dockerfile 基础命令</h2><ol><li><p>FROM</p><pre><code class="hljs dockerfile"><span class="hljs-comment"># 制作基准镜像</span><span class="hljs-keyword">FROM</span> 镜像<span class="hljs-comment"># 比如我们要发布一个应用到tomcat里，那么的第一步就是FROM tomcat</span><span class="hljs-keyword">FROM</span> tomcat&lt;:tags&gt;</code></pre></li><li><p>LABEL &amp; MAINTAINER</p><pre><code class="hljs dockerfile"><span class="hljs-comment"># MAINTAINER：维护员，一般写个人id或组织id</span><span class="hljs-comment"># LABEL 就是注释，纯注释。方便阅读的，纯注释说明。不会对Dockerfile造成任何影响</span><span class="hljs-keyword">MAINTAINER</span> melopoz.com<span class="hljs-keyword">LABEL</span><span class="bash"> version = <span class="hljs-string">&quot;1.0.0&quot;</span></span><span class="hljs-keyword">LABEL</span><span class="bash"> description = <span class="hljs-string">&quot;my project&quot;</span></span></code></pre></li><li><p>WORKDIR</p><pre><code class="hljs dockerfile"><span class="hljs-comment"># 类似Linux的cd。不同点是如果没有这个目录，WORKDIR就创建</span><span class="hljs-keyword">WORKDIR</span><span class="bash"> /usr/<span class="hljs-built_in">local</span>/mpdir</span></code></pre></li><li><p>ADD &amp; COPY</p><pre><code class="hljs dockerfile"><span class="hljs-comment"># COPY 拷贝文件到镜像的某个路径下</span><span class="hljs-keyword">COPY</span><span class="bash"> test1.txt /usr/<span class="hljs-built_in">local</span>/mpdir/<span class="hljs-built_in">test</span></span><span class="hljs-comment"># 拷贝所有 abc 开头的文件到testdir目录下</span><span class="hljs-keyword">COPY</span><span class="bash"> abc* /testdir/</span><span class="hljs-comment"># ? 是单个字符的占位符，比如匹配文件 abc1.log</span><span class="hljs-keyword">COPY</span><span class="bash"> abc?.<span class="hljs-built_in">log</span> /testdir/</span></code></pre><pre><code class="hljs dockerfile"><span class="hljs-comment"># 拷贝文件到镜像的某个路径下，如果路径不存在则创建</span><span class="hljs-keyword">ADD</span><span class="bash"> test1.txt /usr/<span class="hljs-built_in">local</span>/mpdir/test1</span><span class="hljs-comment"># 如果ADD的是tar.gz则将解压缩的内容拷贝到镜像的某个路径下</span><span class="hljs-keyword">ADD</span><span class="bash"> test1.tar.gz /usr/<span class="hljs-built_in">local</span>/mpdir/test1</span></code></pre><p>如果是从远程复制文件，尽量使用curl、wget代替ADD。因为ADD会创建更多镜像层。</p></li><li><p>ENV</p><pre><code class="hljs dockerfile"><span class="hljs-comment"># ENV 设置环境变量，便于下文使用  其他地方都可用$&#123;JAVA_HOME&#125;引用</span><span class="hljs-keyword">ENV</span> JAVA_HOME=/usr/local/jdk1.<span class="hljs-number">8</span></code></pre></li><li><p>RUN &amp; CMD &amp; ENTRYPOINT</p><pre><code class="hljs dockerfile"><span class="hljs-comment"># RUN 在构建镜像时运行，可以修改镜像内部的文件, 有两种命令格式</span><span class="hljs-keyword">RUN</span><span class="bash"> [<span class="hljs-string">&quot;echo&quot;</span>, <span class="hljs-string">&quot;image is building...&quot;</span>]</span></code></pre><blockquote><ul><li>SHELL 命令格式 生成一个子shell进程去执行脚本，执行完退出子进程，回到父进程</li></ul><pre><code class="hljs dockerfile"><span class="hljs-keyword">RUN</span><span class="bash"> yum -y install vim</span></code></pre><ul><li>EXEC 命令格式 用exec进程替换当前进程，保持PID不变，执行完退出，且不会退回原来的进程</li></ul><pre><code class="hljs dockerfile"><span class="hljs-keyword">RUN</span><span class="bash"> [<span class="hljs-string">&quot;yum&quot;</span>, <span class="hljs-string">&quot;-y&quot;</span>, <span class="hljs-string">&quot;install&quot;</span>, <span class="hljs-string">&quot;vim&quot;</span>]</span></code></pre><p>shell会创建子进程执行，EXEC不会创建子进程。<strong>推荐使用EXEC进程</strong>。</p></blockquote><pre><code class="hljs dockerfile"><span class="hljs-comment"># CMD 在容器启动时执行,如果启动时有其他额外命令，则CMD命令不生效。</span><span class="hljs-keyword">CMD</span><span class="bash"> [<span class="hljs-string">&quot;echo&quot;</span>, <span class="hljs-string">&quot;container starting...&quot;</span>]</span></code></pre><pre><code class="hljs dockerfile"><span class="hljs-comment"># ENTRYPOINT 在容器创建时执行，且Dockerfile中只有最后一个ENTRYPOINT会被执行</span><span class="hljs-keyword">ENTRYPOINT</span><span class="bash"> [<span class="hljs-string">&quot;ps&quot;</span>, <span class="hljs-string">&quot;-ef&quot;</span>]</span></code></pre></li></ol><h2 id="docker-服务相关命令"><a href="#docker-服务相关命令" class="headerlink" title="docker 服务相关命令"></a>docker 服务相关命令</h2><pre><code>sudo systemctl status docker//查看docker状态sudo systemctl restart docker// 重启dockersudo vim /etc/docker/daemon.json// 修改配置文件 需要reloadsudo systemctl daemon-reload// 重新加载配置文件</code></pre><h2 id="docker-操作命令"><a href="#docker-操作命令" class="headerlink" title="docker 操作命令"></a>docker 操作命令</h2><h5 id="镜像操作"><a href="#镜像操作" class="headerlink" title="镜像操作"></a>镜像操作</h5><pre><code class="hljs awk">docker images <span class="hljs-regexp">//</span>列出本地主机上的镜像docker search 镜像名 <span class="hljs-regexp">//</span> 从hub.docker.com查找镜像    -s <span class="hljs-number">20</span> 镜像名 <span class="hljs-regexp">//</span>筛选点赞数超过<span class="hljs-number">20</span>的镜像    -no-trunc 镜像名 <span class="hljs-regexp">//</span>显示完整描述信息    -automated 镜像名 <span class="hljs-regexp">//</span>只列出automated build的镜像docker pull 镜像名:<span class="hljs-number">9.0</span> <span class="hljs-regexp">//</span>从镜像加速器(如果有配置，没配就是从hub.docker)拉取镜像到本地;版本号不写默认lasterdocker rmi 唯一镜像名(或id) <span class="hljs-regexp">//</span>删除本地镜像 可直接空格连接多个id全部删除    -f <span class="hljs-regexp">//</span> 强制删除  --force <span class="hljs-regexp">//</span>如果在使用也删除docker run 镜像名 <span class="hljs-regexp">//</span>启动一个容器docker commit <span class="hljs-regexp">//</span>提交容器副本使之成为一个新的镜像    -m=<span class="hljs-string">&quot;描述信息&quot;</span> -a=<span class="hljs-string">&quot;作者&quot;</span> 容器id 要创建的目标镜像名:[标签名]</code></pre><h6 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h6><pre><code class="hljs jboss-cli">docker build * <span class="hljs-string">//</span>使用Dockerfile创建镜像；Dockerfile可以是本地、在线、自定义的。    docker build [options] PATH | URL | - <span class="hljs-string">//</span>语法        <span class="hljs-params">--build-arg=</span>[] :设置镜像创建时的变量；        <span class="hljs-params">--cpu-shares</span> :设置 cpu 使用权重；        <span class="hljs-params">--cpu-period</span> :限制 CPU CFS周期；        <span class="hljs-params">--cpu-quota</span> :限制 CPU CFS配额；        <span class="hljs-params">--cpuset-cpus</span> :指定使用的CPU id；        <span class="hljs-params">--cpuset-mems</span> :指定使用的内存 id；        <span class="hljs-params">--disable-content-trust</span> :忽略校验，默认开启；        -f :指定要使用的Dockerfile路径        <span class="hljs-params">--force-rm</span> :设置镜像过程中删除中间容器；        <span class="hljs-params">--isolation</span> :使用容器隔离技术；        <span class="hljs-params">--label=</span>[] :设置镜像使用的元数据        -m :设置内存最大值；        <span class="hljs-params">--memory-swap</span> :设置Swap的最大值为内存+swap，<span class="hljs-string">&quot;-1&quot;</span>表示不限swap；        <span class="hljs-params">--no-cache</span> :创建镜像的过程不使用缓存；        <span class="hljs-params">--pull</span> :尝试去更新镜像的新版本；        -q, <span class="hljs-params">--quiet</span> :安静模式，成功后只输出镜像 ID；        <span class="hljs-params">--rm</span> :设置镜像成功后删除中间容器；        <span class="hljs-params">--shm-size</span> :设置<span class="hljs-string">/dev/shm</span>的大小，默认值是64M；        <span class="hljs-params">--ulimit</span> <span class="hljs-function">:Ulimit</span>配置。        <span class="hljs-params">--t</span>, <span class="hljs-params">--tag</span>: 镜像的名字及标签，通常 name<span class="hljs-function">:tag</span> 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。        <span class="hljs-params">--network</span>: 默认 default。在构建期间设置RUN指令的网络模式</code></pre><p>例如</p><pre><code class="hljs applescript">当前目录下有Dockerfile和hims<span class="hljs-number">-0.1</span>.jar创建镜像：    docker build -t hims:<span class="hljs-number">0.1</span> .查看镜像：    docker images    结果：    hims   <span class="hljs-number">0.1</span>   ...<span class="hljs-built_in">id</span>...     <span class="hljs-number">5</span> seconds ago    <span class="hljs-number">713</span>MB运行镜像：    docker <span class="hljs-built_in">run</span> -d <span class="hljs-number">0</span></code></pre><h5 id="启动容器-start"><a href="#启动容器-start" class="headerlink" title="启动容器 start"></a>启动容器 start</h5><pre><code class="hljs isbl"><span class="hljs-variable">docker</span> <span class="hljs-variable">start</span> 镜像<span class="hljs-function"><span class="hljs-title">id</span>(或容器名)</span></code></pre><h5 id="新建并启动容器-run"><a href="#新建并启动容器-run" class="headerlink" title="新建并启动容器 run"></a>新建并启动容器 run</h5><pre><code class="hljs awk">docker run [options] IMAGE [command][arg]    --name=<span class="hljs-string">&quot;容器新名字&quot;</span><span class="hljs-regexp">//</span> 为容器指定一个名称    -d <span class="hljs-regexp">//</span>后台运行容器，返回容器id，即启动守护式容器    -i <span class="hljs-regexp">//</span>以交互模式运行容器，通常与-t同时使用    -t <span class="hljs-regexp">//</span>为容器重新分配一个伪输入终端    -P <span class="hljs-regexp">//</span>随机端口映射    -p <span class="hljs-regexp">//</span>指定端口映射有四种格式 一般使用 主机端口:docker容器端口        ip:hostPort:containerPort        ip::containerPort        hostPort:containerPort        containerPort</code></pre><h5 id="运行时命令"><a href="#运行时命令" class="headerlink" title="运行时命令"></a>运行时命令</h5><pre><code class="hljs awk">docker ps<span class="hljs-regexp">//</span> 查看正在运行的容器   --no-trunc 不截断输出,显示完整containerID    -a <span class="hljs-regexp">//</span>列出当前所有正在运行的容器 + 历史上运行过的    -l <span class="hljs-regexp">//</span>显示最近创建的容器    -n <span class="hljs-number">3</span> <span class="hljs-regexp">//</span>显示最近创建的<span class="hljs-number">3</span>个容器    -q <span class="hljs-regexp">//</span>静默模式，只显示容器编号(可用于批量关闭容器)    --no-trunc <span class="hljs-regexp">//</span> 不截断输出</code></pre><h5 id="停止容器"><a href="#停止容器" class="headerlink" title="停止容器"></a>停止容器</h5><pre><code class="hljs isbl"><span class="hljs-variable">docker</span> <span class="hljs-variable">stop</span> 容器<span class="hljs-function"><span class="hljs-title">id</span>(或容器名)</span></code></pre><h5 id="强制停止容器"><a href="#强制停止容器" class="headerlink" title="强制停止容器"></a>强制停止容器</h5><pre><code class="hljs isbl"><span class="hljs-variable">docker</span> <span class="hljs-variable">kill</span> 容器<span class="hljs-function"><span class="hljs-title">id</span>(或容器名)</span></code></pre><h5 id="删除已停止容器"><a href="#删除已停止容器" class="headerlink" title="删除已停止容器"></a>删除已停止容器</h5><pre><code class="hljs powershell">docker <span class="hljs-built_in">rm</span> <span class="hljs-operator">-f</span> 容器iddocker <span class="hljs-built_in">rm</span> 容器id(或容器名)    <span class="hljs-operator">-f</span> // 关闭并删除</code></pre><h5 id="删除多个容器"><a href="#删除多个容器" class="headerlink" title="删除多个容器"></a>删除多个容器</h5><pre><code class="hljs powershell">docker <span class="hljs-built_in">rm</span> <span class="hljs-operator">-f</span> <span class="hljs-variable">$</span>(docker <span class="hljs-built_in">ps</span> <span class="hljs-literal">-a</span> <span class="hljs-literal">-q</span>) 或者 docker <span class="hljs-built_in">ps</span> <span class="hljs-literal">-a</span> <span class="hljs-literal">-q</span> | xargs docker <span class="hljs-built_in">rm</span></code></pre><h5 id="退出容器"><a href="#退出容器" class="headerlink" title="退出容器"></a>退出容器</h5><pre><code class="hljs awk"><span class="hljs-keyword">exit</span> <span class="hljs-regexp">//</span> 容器停止退出ctrl+P+Q <span class="hljs-regexp">//</span> 不停止容器退出</code></pre><h5 id="重新进入正在运行的容器"><a href="#重新进入正在运行的容器" class="headerlink" title="重新进入正在运行的容器"></a>重新进入正在运行的容器</h5><pre><code class="hljs arduino">docker attach 容器id  <span class="hljs-comment">// 直接进入容器启动命令的终端，不会启动新进程</span></code></pre><h5 id="在容器内执行命令"><a href="#在容器内执行命令" class="headerlink" title="在容器内执行命令"></a>在容器内执行命令</h5><pre><code class="hljs mel">docker <span class="hljs-keyword">exec</span> -t 容器id 命令 <span class="hljs-comment">// 在容器中打开新终端，并且可以启动新进程</span>    比如sentos容器：docker <span class="hljs-keyword">exec</span> -t centosiID <span class="hljs-keyword">ls</span> -l /tmp  <span class="hljs-comment">//就会返回该容器的tmp目录</span></code></pre><h5 id="查看日志"><a href="#查看日志" class="headerlink" title="查看日志"></a>查看日志</h5><pre><code>docker logs 容器id    -t // 显示日志打印的时间    -f // =tail -f     -tail 3 // 看三行  可以和-f 一起用</code></pre><h5 id="查看容器信息-json格式"><a href="#查看容器信息-json格式" class="headerlink" title="查看容器信息 json格式"></a>查看容器信息 json格式</h5><pre><code>docker inspect 容器id</code></pre><h5 id="复制容器内文件"><a href="#复制容器内文件" class="headerlink" title="复制容器内文件"></a>复制容器内文件</h5><pre><code>(比如centos容器)docker cp centosID:/容器内文件路径 /目的路径</code></pre><h2 id="Docker数据卷"><a href="#Docker数据卷" class="headerlink" title="Docker数据卷"></a>Docker数据卷</h2><h3 id="容器内添加"><a href="#容器内添加" class="headerlink" title="容器内添加"></a>容器内添加</h3><h5 id="1-直接命令添加-v"><a href="#1-直接命令添加-v" class="headerlink" title="1. 直接命令添加  -v"></a>1. 直接命令添加  -v</h5><pre><code class="hljs awk">docker run -it -v <span class="hljs-regexp">/宿主机绝对路径:/</span>容器内路径 镜像名 <span class="hljs-regexp">//</span>双方都可读写并同步<span class="hljs-regexp">//</span> 可以通过【docker inspect 容器id】查看到VolumesRW.containerDir为true</code></pre><pre><code class="hljs awk">docker run -it -v <span class="hljs-regexp">/hostDir:/</span>containerDir:ro 镜像名 <span class="hljs-regexp">//</span> 只有host可执行写操作，容器只能读<span class="hljs-regexp">//</span> 可以通过【docker inspect 容器id】查看到VolumesRW.containerDir为false</code></pre><h5 id="2-DockerFile添加"><a href="#2-DockerFile添加" class="headerlink" title="2. DockerFile添加"></a>2. DockerFile添加</h5><pre><code class="hljs plain">docker的dockerfile就像linux的脚本文件。dockerfile不能创建host的本地目录来实现数据卷，只能创建一个&#x2F;多个容器内数据卷。</code></pre><p>创建dockerfile（touch /mydocker/Dockerfile）</p><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> centos<span class="hljs-keyword">VOLUME</span><span class="bash"> [<span class="hljs-string">&quot;/dataVolumeContainer1&quot;</span>,<span class="hljs-string">&quot;/dataVolumeContainer2&quot;</span>]</span><span class="hljs-keyword">CMD</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;finished,--------success1&quot;</span></span><span class="hljs-keyword">CMD</span><span class="bash"> /bin/bash</span></code></pre><p>创建dockerfile   单独例2</p><pre><code class="hljs jboss-cli">FORM java<span class="hljs-function">:8</span> <span class="hljs-string">//</span>依赖java8EXPOSE 8080 <span class="hljs-string">//</span>暴露8080端口VOLUME <span class="hljs-string">/tmp</span> <span class="hljs-string">//</span>ENV TZ=Asia/ShanghaiRUN ln -sf <span class="hljs-string">/usr/share/zoneinfo/</span>&#123;TZ&#125; <span class="hljs-string">/etc/localtime</span> &amp;&amp; <span class="hljs-keyword">echo</span> <span class="hljs-string">&quot;&#123;TZ&#125;&quot;</span> &gt; <span class="hljs-string">/etc/timezone</span>ADD hims-0.0.1-SNAPSHOT.jar <span class="hljs-string">/app.jar</span> <span class="hljs-string">//</span>将项目jar包添加到容器并设置别名为app.jarRUN bash -c &#x27;touch <span class="hljs-string">/app.jar</span>&#x27;ENTRYPOINT [<span class="hljs-string">&quot;java&quot;</span>,<span class="hljs-string">&quot;-jar&quot;</span>,<span class="hljs-string">&quot;/app.jar&quot;</span>] <span class="hljs-string">//</span> 启动命令为 java -jar app.jar</code></pre><p>构建镜像</p><pre><code class="hljs awk">docker build -f <span class="hljs-regexp">/mydocker/</span>Dockerfile -t melopoz/centos</code></pre><p>创建容器并运行</p><pre><code class="hljs awk">docker run -it melopoz<span class="hljs-regexp">/centos /</span>bin<span class="hljs-regexp">/bash （/</span>bin/bash可以不写）</code></pre><p>虽然没有指定宿主机(运行docker的服务器)上与数据卷绑定的路径，但是可以通过<code>docker inspect 容器id</code>查看默认生成的宿主机数据卷路径</p><p>Volumes：{dataVolumeContainer1:/var/lib/docker/…, dataVolumeContainer2:/var/…}</p><h5 id="3-备注"><a href="#3-备注" class="headerlink" title="3. 备注"></a>3. 备注</h5><p>如果Docker挂载主机目录Dokcer访问出现cannot open directory.:Permission denied</p><p>就在挂载目录后加参数<code>--privileged=true</code></p><p>即<code>docker run -it -v /myDir:/containerDir --privileged=true 镜像名</code></p><h2 id="镜像分层-概念"><a href="#镜像分层-概念" class="headerlink" title="镜像分层 概念"></a>镜像分层 概念</h2><p>以tomcat镜像为例</p><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> tomcat:latest<span class="hljs-keyword">MAINTAINER</span> melopoz.com<span class="hljs-keyword">WORKDIR</span><span class="bash"> /usr/<span class="hljs-built_in">local</span>/tomcat/webapps</span><span class="hljs-keyword">ADD</span><span class="bash"> helloworld ./helloworld</span></code></pre><p>Dockerfile内容4行，执行过程也是4行：</p><pre><code class="hljs gradle">Sending build context to Docker daemon <span class="hljs-number">3.584</span>kB<span class="hljs-keyword">Step</span> <span class="hljs-number">1</span>/<span class="hljs-number">4</span> : <span class="hljs-keyword">FROM</span> tomcat:latest ---&gt; aaaaaaa<span class="hljs-keyword">Step</span> <span class="hljs-number">2</span>/<span class="hljs-number">4</span> : MAINTAINER melopoz.com ---&gt; Running in bbbbbbbRemoving intermediate container bbbbbbb<span class="hljs-keyword">Step</span> <span class="hljs-number">3</span><span class="hljs-regexp">/4 : WORKDIR /u</span>sr<span class="hljs-regexp">/local/</span>tomcat/webapps ---&gt; Running in ccccccc<span class="hljs-keyword">Step</span> <span class="hljs-number">4</span><span class="hljs-regexp">/4 : ADD helloworld ./</span>helloworld ---&gt; dddddddSuccessfully build dddddddSuccessfully tagged melopoz.com/test-helloworld:<span class="hljs-number">1.0</span>.<span class="hljs-number">0</span></code></pre><p>将Dockerfile中的内容改为</p><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> tomcat:latest<span class="hljs-keyword">MAINTAINER</span> melopoz.com<span class="hljs-keyword">WORKDIR</span><span class="bash"> /usr/<span class="hljs-built_in">local</span>/tomcat/webapps</span><span class="hljs-keyword">ADD</span><span class="bash"> helloworld ./helloworld</span><span class="hljs-keyword">ADD</span><span class="bash"> helloworld ./helloworld2 <span class="hljs-comment">#多部署一份helloworld到容器的helloworld2目录</span></span></code></pre><p>再次build之后输出为：</p><pre><code class="hljs ada">Step <span class="hljs-number">1</span>/<span class="hljs-number">4</span> : <span class="hljs-type">FROM</span> tomcat:latest <span class="hljs-comment">---&gt; aaaaaaa</span>Step <span class="hljs-number">2</span>/<span class="hljs-number">4</span> : <span class="hljs-type">MAINTAINER</span> melopoz.com <span class="hljs-comment">---&gt; Using cache</span> <span class="hljs-comment">---&gt; Running in bbbbbbb</span>Step <span class="hljs-number">3</span>/<span class="hljs-number">4</span> : <span class="hljs-type">WORKDIR</span> /usr/local/tomcat/webapps <span class="hljs-comment">---&gt; Using cache</span> <span class="hljs-comment">---&gt; Running in ccccccc</span>Step <span class="hljs-number">4</span>/<span class="hljs-number">4</span> : <span class="hljs-type">ADD</span> helloworld ./helloworld <span class="hljs-comment">---&gt; Using cache</span> <span class="hljs-comment">---&gt; ddddddd</span>Step <span class="hljs-number">4</span>/<span class="hljs-number">4</span> : <span class="hljs-type">ADD</span> helloworld ./helloworld <span class="hljs-comment">---&gt; eeeeeee</span>Successfully build eeeeeeeSuccessfully <span class="hljs-keyword">tagged</span> melopoz.com/test-helloworld:<span class="hljs-number">1.0</span>.<span class="hljs-number">0</span></code></pre><p>前四步没有重复创建容器而是使用了Cache，step1没有UsingCache是由于从本地仓库直接拉取了tomcat:latest镜像作为基础镜像。</p><h1 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h1><h2 id="Docker-mysql"><a href="#Docker-mysql" class="headerlink" title="Docker   mysql"></a>Docker   mysql</h2><h3 id="查找-拉取镜像"><a href="#查找-拉取镜像" class="headerlink" title="查找 拉取镜像"></a>查找 拉取镜像</h3><p><code>docker pull mysql:5.7（版本自定义或者不写默认laster)</code></p><h3 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h3><pre><code class="hljs awk">docker run -p <span class="hljs-number">3306</span>:<span class="hljs-number">3306</span> --name:mysql_docker-v ...<span class="hljs-regexp">/container_cfgfiles/my</span>sql<span class="hljs-regexp">/conf:/</span>etc<span class="hljs-regexp">/mysql/</span>conf.d-v ...<span class="hljs-regexp">/container_cfgfiles/my</span>sql<span class="hljs-regexp">/logs:/</span>logs-v ...<span class="hljs-regexp">/container_cfgfiles/my</span>sql<span class="hljs-regexp">/conf:/</span>var<span class="hljs-regexp">/lib/my</span>sql-e MYSQL_ROOT_PASSWORD=<span class="hljs-number">123456</span>-d mysql:<span class="hljs-number">5.7</span><span class="hljs-regexp">//</span> 指定配置文件 容器名 后台运行 。。</code></pre><h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><pre><code class="hljs python">docker <span class="hljs-built_in">exec</span> -it 容器<span class="hljs-built_in">id</span> /<span class="hljs-built_in">bin</span>/bashmysql -uroot -p输入密码</code></pre><h3 id="数据备份"><a href="#数据备份" class="headerlink" title="数据备份"></a>数据备份</h3><p>在docker宿主机终端</p><pre><code class="hljs haskell"><span class="hljs-title">docker</span> exec mysql容器id sh -<span class="hljs-type">C</span> &#x27;<span class="hljs-title">exec</span> mysqldump <span class="hljs-comment">--all-databases -uroot -p&quot;123456&quot;</span>&#x27; &gt; /<span class="hljs-class"><span class="hljs-keyword">data</span>/docker_mysql_data/all-databases.sql</span></code></pre><h2 id="Docker-redis"><a href="#Docker-redis" class="headerlink" title="Docker   redis"></a>Docker   redis</h2><h3 id="启动-这是是在创建容器的时候就启动了redis-server，也可以之后使用exec启动"><a href="#启动-这是是在创建容器的时候就启动了redis-server，也可以之后使用exec启动" class="headerlink" title="启动 这是是在创建容器的时候就启动了redis-server，也可以之后使用exec启动"></a>启动 这是是在创建容器的时候就启动了redis-server，也可以之后使用exec启动</h3><pre><code class="hljs awk">docker run -p <span class="hljs-number">6379</span>:<span class="hljs-number">6379</span>-v ...<span class="hljs-regexp">/container_cfgfiles/</span>redis<span class="hljs-regexp">/data:/</span>data-v ...<span class="hljs-regexp">/container_cfgfiles/</span>redis<span class="hljs-regexp">/redis.conf:/u</span>sr<span class="hljs-regexp">/local/</span>etc<span class="hljs-regexp">/redis/</span>redis.conf-d redis:版本号 redis-server <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/etc/</span>redis/redis.conf--appendonly yes</code></pre><p>开启了redis AOF</p><h6 id="连接redis-cli"><a href="#连接redis-cli" class="headerlink" title="连接redis-cli"></a>连接redis-cli</h6><pre><code class="hljs applescript">docker exec -<span class="hljs-keyword">it</span> redis容器<span class="hljs-built_in">id</span> redis-cli</code></pre><h1 id="Docker-image-提交到阿里云仓库"><a href="#Docker-image-提交到阿里云仓库" class="headerlink" title="Docker image 提交到阿里云仓库"></a>Docker image 提交到阿里云仓库</h1><h5 id="用实例容器生成最新镜像"><a href="#用实例容器生成最新镜像" class="headerlink" title="用实例容器生成最新镜像"></a>用实例容器生成最新镜像</h5><pre><code class="hljs awk"><span class="hljs-regexp">//</span> docker commit -a 作者 -m <span class="hljs-string">&quot;提交信息&quot;</span> 正在运行的容器id 镜像名:版本号docker commit -a melopoz -m <span class="hljs-string">&quot;centos1.3 to 1.4 with vim,ifconfig&quot;</span> xxxx mycentos:<span class="hljs-number">1.4</span></code></pre><h5 id="查看生成的镜像"><a href="#查看生成的镜像" class="headerlink" title="查看生成的镜像"></a>查看生成的镜像</h5><p><code>docker images mycentos</code></p><h5 id="推送到云仓库"><a href="#推送到云仓库" class="headerlink" title="推送到云仓库"></a>推送到云仓库</h5><h6 id="阿里云-容器镜像服务"><a href="#阿里云-容器镜像服务" class="headerlink" title="阿里云-容器镜像服务"></a>阿里云-容器镜像服务</h6><ol><li>创建镜像仓库(需要命名空间)</li><li>阿里云给了推送命令 复制即可<pre><code class="hljs stylus"><span class="hljs-comment">//将镜像推送到Registry</span>sudo docker login --username=xxx registry<span class="hljs-selector-class">.cn-beijing</span><span class="hljs-selector-class">.aliyuncs</span>.com<span class="hljs-comment">// 输入密码</span>sudo docker tag <span class="hljs-selector-attr">[ImageId]</span> registry<span class="hljs-selector-class">.cn-beijing</span><span class="hljs-selector-class">.aliyuncs</span>.com/命名空间/仓库名:<span class="hljs-selector-attr">[镜像版本号]</span>sudo docker push registry<span class="hljs-selector-class">.cn-beijing</span><span class="hljs-selector-class">.aliyuncs</span>.com/xx/xx:<span class="hljs-selector-attr">[镜像版本号]</span><span class="hljs-comment">//根据实际镜像信息替换示例中的[ImageId]和[镜像版本号]参数。</span></code></pre></li><li>从阿里云拉取镜像<pre><code class="hljs stylus">sudo docker pull registry<span class="hljs-selector-class">.cn-beijing</span><span class="hljs-selector-class">.aliyuncs</span>.com/命名空间/仓库名:<span class="hljs-selector-attr">[镜像版本号]</span></code></pre></li></ol><h1 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h1><h2 id="多个仓库引用一个镜像时-要删除镜像"><a href="#多个仓库引用一个镜像时-要删除镜像" class="headerlink" title="多个仓库引用一个镜像时 要删除镜像"></a>多个仓库引用一个镜像时 要删除镜像</h2><p>先使用镜像名删除</p><h2 id="记第一次启动tomcat，启动成功，访问404"><a href="#记第一次启动tomcat，启动成功，访问404" class="headerlink" title="记第一次启动tomcat，启动成功，访问404"></a>记第一次启动tomcat，启动成功，访问404</h2><p>启动成功没有页面可能是tomcat下没有页面，需要进入tomcat下的webapps</p><pre><code class="hljs elixir">docker exec -it 容器id /bin/bashroot<span class="hljs-variable">@f37547416a87</span><span class="hljs-symbol">:/usr/local/tomcat</span><span class="hljs-comment"># ls -l // 查看目录 </span>root<span class="hljs-variable">@f37547416a87</span><span class="hljs-symbol">:/usr/local/tomcat</span><span class="hljs-comment"># cd webapps // 为空。。而webapps.dist不为空</span>    把dist复制到webapps，再访问即可webapps.dist下的内容：ROOT  docs  examples  host-manager  manager</code></pre>]]></content>
    
    
    <categories>
      
      <category>CI/CD</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>JVM的一些参数</title>
    <link href="/blog/2021/01/01/JVM_%E5%8F%82%E6%95%B0/"/>
    <url>/blog/2021/01/01/JVM_%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>查看jvm参数(参数默认值): <code>java -XX:+PrintFlagsFinal -version</code></p><p>查看java进程的参数的配置: <code>jinfo -flags [pid]</code> `</p><p>查看java进程的指定参数的配置: <code>jinfo -flags [option] [pid]</code></p><blockquote><p>jinfo -flags NewRatio 15222</p></blockquote><h1 id="SoftRefLRUPolicyMSPerMB"><a href="#SoftRefLRUPolicyMSPerMB" class="headerlink" title="SoftRefLRUPolicyMSPerMB"></a>SoftRefLRUPolicyMSPerMB</h1><blockquote><p>关系到 软引用 再GC发生时,是否被GC回收</p><p>-XX:SoftRefLRUPolicyMSPerMB</p></blockquote><blockquote><p>LRU:  Least Recently Used, 最近最少使用.</p></blockquote><p><a href="https://blog.csdn.net/u010833547/article/details/90289325">https://blog.csdn.net/u010833547/article/details/90289325</a></p><p>软引用是在内存空间不足的时候才会被回收, 这只是比较简单的形容. </p><p>首先看一下SoftReference类和描述</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SoftReference</span>&lt;<span class="hljs-title">T</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">Reference</span>&lt;<span class="hljs-title">T</span>&gt; </span>&#123;    <span class="hljs-comment">/**</span><span class="hljs-comment">     * Timestamp clock, updated by the garbage collector</span><span class="hljs-comment">     */</span>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> clock;<span class="hljs-comment">// ------------每次GC会更新这个时间戳</span>    <span class="hljs-comment">/**</span><span class="hljs-comment">     * Timestamp updated by each invocation of the get method.  The VM may use</span><span class="hljs-comment">     * this field when selecting soft references to be cleared, but it is not</span><span class="hljs-comment">     * required to do so.</span><span class="hljs-comment">     */</span>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> timestamp;<span class="hljs-comment">// ------------每次使用(构造、get)会更新这个时间戳</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">SoftReference</span><span class="hljs-params">(T referent)</span> </span>&#123;        <span class="hljs-keyword">super</span>(referent);        <span class="hljs-keyword">this</span>.timestamp = clock;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">SoftReference</span><span class="hljs-params">(T referent, ReferenceQueue&lt;? <span class="hljs-keyword">super</span> T&gt; q)</span> </span>&#123;        <span class="hljs-keyword">super</span>(referent, q);        <span class="hljs-keyword">this</span>.timestamp = clock;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> T <span class="hljs-title">get</span><span class="hljs-params">()</span> </span>&#123;        T o = <span class="hljs-keyword">super</span>.get();        <span class="hljs-keyword">if</span> (o != <span class="hljs-keyword">null</span> &amp;&amp; <span class="hljs-keyword">this</span>.timestamp != clock)            <span class="hljs-keyword">this</span>.timestamp = clock;        <span class="hljs-keyword">return</span> o;    &#125;&#125;</code></pre><p>GC时,回收软引用对象要走LRU算法</p><blockquote><p>if (       <code>clock - timestamp &lt;= freespace * SoftRefLRUPolicyMSPerMB</code>       ) {</p><p>​        不回收这个对象</p><p>}</p></blockquote><p>clock 记录的是上一次GC的时间戳, timestamp 记录最近使用这个引用对象的时间, freespace是 剩余可用空间, </p><p><code>clock - timestamp</code> 表示这个引用已经闲置了多久, </p><p><code>freespace * SoftRefLRUPolicyMSPerMB</code> 表示JVM.GC对软引用的忍耐程度. SoftRefLRUPolicyMSPerMB越小, 就会越早回收soft-ref对象. </p><p>如果<code>clock - timestamp</code>为负数, 是 本次GC之前,上次GC之后被使用过, 那么本次GC不回收这个soft-ref. </p><p>所以软引用肯定不会被它所经历的第一次GC(本次GC)回收. </p><blockquote><p>只有发生gc时才会计算这个 <code>clock - timestamp</code> 的啊.. </p><p>个人认为必须要 先确定是否回收这个soft-ref, 如果不必回收这个soft-ref, 再更新clock. </p><p>这样这个clock才能表示 上次GC的时间, 否则这个clock就是当前GC的时间(因为要STW, 所以clock就是当前时间)</p></blockquote><p>SoftRefLRUPolicyMSPerMB的默认值为1000, 也就是1s</p><h3 id="xx-SoftRefLRUPolicyMSPerMB-的坑"><a href="#xx-SoftRefLRUPolicyMSPerMB-的坑" class="headerlink" title="-xx:SoftRefLRUPolicyMSPerMB 的坑"></a>-xx:SoftRefLRUPolicyMSPerMB 的坑</h3><p>这个值越小, jvm对软引用的忍耐程度就越小, 但是不能设置为0</p><h6 id="如果为0"><a href="#如果为0" class="headerlink" title="如果为0:"></a>如果为0:</h6><p>每次GC的时候很多软引用</p><p>参考: <a href="https://blog.csdn.net/qiang_zi_/article/details/100700784">https://blog.csdn.net/qiang_zi_/article/details/100700784</a></p><p>就是jvm利用反射生成的很多软引用对象, 每次GC的时候因为对软引用的忍耐程序为0, 就都给清除了,  清除之后还要用到这些soft-ref, 就又生成, 这样不但没有真正节省出内存空间, 还降低了性能. </p><p>还如上方链接中举例, 可能会造成metaspace不稳定, 导致FULL GC频率飙升</p><p>所以不便在一开始就设置SoftRefLRUPolicyMSPerMB, 可以在后期根据情况进行调整.</p><p>有可能需要调高SOftRefLRUPolicyMSPerMB, 让一些经常用到的soft-ref对象不会总被回收再创建, 使metaspace空间的使用率更平稳一些.</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>JVM安全退出</title>
    <link href="/blog/2021/01/01/JVM_%E5%AE%89%E5%85%A8%E9%80%80%E5%87%BA/"/>
    <url>/blog/2021/01/01/JVM_%E5%AE%89%E5%85%A8%E9%80%80%E5%87%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="Shutdown-Hook"><a href="#Shutdown-Hook" class="headerlink" title="Shutdown Hook"></a>Shutdown Hook</h2><p>System.getRuntime().addShutdownHook(Thread thread);</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JVMShutdownHook</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> InterruptedException </span>&#123;        <span class="hljs-comment">//hook</span>        Runtime.getRuntime().addShutdownHook(<span class="hljs-keyword">new</span> Thread(()-&gt;&#123;            System.out.println(<span class="hljs-string">&quot;jvm要关闭了&quot;</span>);            <span class="hljs-keyword">try</span> &#123;                TimeUnit.SECONDS.sleep(<span class="hljs-number">3</span>);            &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(<span class="hljs-string">&quot;拜拜&quot;</span>);        &#125;));        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5</span>; i++) &#123;            System.out.println(i);            <span class="hljs-keyword">if</span> (i == <span class="hljs-number">3</span>)&#123;                System.exit(<span class="hljs-number">0</span>);            &#125;        &#125;    &#125;&#125;</code></pre><p>控制台打印：</p><pre><code class="hljs awk">D:\Java\jdk1.<span class="hljs-number">8.0</span>_231\bin\java.exe ...<span class="hljs-number">0</span><span class="hljs-number">1</span><span class="hljs-number">2</span><span class="hljs-number">3</span>jvm要关闭了<span class="hljs-regexp">//</span>等<span class="hljs-number">3</span>s拜拜Process finished with <span class="hljs-keyword">exit</span> code <span class="hljs-number">0</span></code></pre><h2 id="java结束程序的方法："><a href="#java结束程序的方法：" class="headerlink" title="java结束程序的方法："></a>java结束程序的方法：</h2><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/jvm%E5%85%B3%E9%97%AD.png" style="zoom:50%;" /><ul><li><p>System.exit(int status);</p><blockquote><p>status表示程序退出的状态码，如果其他程序调用这个程序，这个状态吗就会返回给调用者。</p><p>0表示正常退出，非0表示异常终止。</p></blockquote></li></ul>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Kafka</title>
    <link href="/blog/2021/01/01/MQ_Kafka/"/>
    <url>/blog/2021/01/01/MQ_Kafka/</url>
    
    <content type="html"><![CDATA[<h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><img alt="Kafka架构图" src="https://raw.githubusercontent.com/melopoz/pics/master/img/kafka%E6%9E%B6%E6%9E%84%E5%9B%BE.png" style="zoom:80%;" /><p>通过 zookeeper 保存元数据，管理集群配置、选举Leader、Consumer Group发生变化时进行rebalance。</p><img alt="Kafka元数据在zookeeper中的数据结构" src="https://raw.githubusercontent.com/melopoz/pics/master/img/kafka%E5%85%83%E6%95%B0%E6%8D%AE%E5%9C%A8zookeeper%E4%B8%AD%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png" style="zoom:60%;" /><h2 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h2><p>Kafka是发布/订阅模式的消息队列，生产、消费消息，都是面向Topic的。</p><blockquote><p>另一种是<strong>点对点</strong>消息队列，即一条消息被一个消费者消费一次就没了</p></blockquote><h2 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h2><p>一条消息可以发送到不同的Consumer Group，但一个Consumer Group中只能有一个Consumer能消费这条消息。</p><blockquote><p>即 Topic下的一个<a href="#Partition">Partition</a>只能被同一个Consumer Group下的一个Consumer线程来消费。</p></blockquote><p>Topic有几个分区，消费这个Topic的Consumer Group就有几个Consumer即可，效率也最高，Consumer多了就会有Consumer拿不到消息。</p><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/Kafka-%E5%88%86%E5%8C%BA%E6%95%B0%E6%B6%88%E8%B4%B9%E8%80%85%E6%95%B0.png" /><h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><p>物理概念，每个 Topic 包含一个或多个 Partition，一个 Partition 对应一个文件夹（命名规则：<code>Topic 名称+分区序号</code>），存储 Partition 的数据和索引文件（因为每个Partition又分为了多个<a href="#Segment">Segment</a>），每个 Partition 内部是有序的，且每个 Partition 中的消息不一样。</p><blockquote><p>由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位效率低，Kafka 采取了<strong>分片</strong>和<strong>索引</strong>机制，将每个 Partition 分为多个 <a href="#Segment">Segment</a></p></blockquote><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/kafka-%E5%88%86%E5%8C%BA%E6%95%B0%E6%B6%88%E8%B4%B9%E8%80%85%E6%95%B0.png" style="zoom:80%;" /><h3 id="分区分配策略"><a href="#分区分配策略" class="headerlink" title="分区分配策略"></a>分区分配策略</h3><blockquote><p>通过 <code>Partition.assignment.strategy</code> 配置</p></blockquote><ul><li>range：<strong>随机</strong>（默认）</li><li>roundrobin：<strong>循环</strong></li><li>StickyAssignor：粘性分配</li></ul><blockquote><p>当有下列情况发生的时候，Kafka会进行一次Partition分配（<strong>rebalance</strong>）：</p><ol><li>Topic 新增 Partition</li><li>Consumer Group 新增 consumer</li><li>consumer 离开所在 group （shut down / crashes(崩溃)）</li></ol></blockquote><h2 id="Segment"><a href="#Segment" class="headerlink" title="Segment"></a>Segment</h2><p>每个 Segment 文件包括 <code>.index</code> 文件 和 <code>.log</code> 文件，这些文件位于同一个 Partition 文件夹下。Segment文件大小默认1G。</p><blockquote><p>例如，Topic “first” 有三个分区，则其对应的文件夹为 <code>first-0</code>，<code>first-1</code>，<code>first-2</code></p></blockquote><p><code>.index</code> 和 <code>.log</code> 文件均以当前 Segment 的第一条消息的 offset 命名:</p><blockquote><p>在 Kafka 的 <code>server.properties</code> 配置的 <code>log.dirs</code> 为数据的目录，该目录下有文件夹 <code>Topic名-分区号</code>，每个分区中包含如下文件</p><pre><code class="hljs pgsql"><span class="hljs-number">00000000000000000000.</span><span class="hljs-keyword">index</span><span class="hljs-number">00000000000000000000.</span><span class="hljs-keyword">log</span><span class="hljs-number">00000000000000170410.</span><span class="hljs-keyword">index</span><span class="hljs-number">00000000000000170410.</span><span class="hljs-keyword">log</span><span class="hljs-number">00000000000000239430.</span><span class="hljs-keyword">index</span><span class="hljs-number">00000000000000239430.</span><span class="hljs-keyword">log</span><span class="hljs-number">00000000000000000000.</span>timeindexLeader-epoch-<span class="hljs-keyword">checkpoint</span></code></pre><p><code>.index</code> 文件存储索引信息，<code>.log</code> 文件存储数据，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址 <code>offset</code>。</p></blockquote><h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><h3 id="2种消息发送机制"><a href="#2种消息发送机制" class="headerlink" title="2种消息发送机制"></a>2种消息发送机制</h3><ul><li><p>Sync Producer：低延迟，低吞吐率，无数据丢失</p></li><li><p>Async Producer：高延迟，高吞吐率，可能会有数据丢失</p><pre><code class="hljs java"><span class="hljs-function">Future&lt;RecordMetadata&gt; <span class="hljs-title">send</span><span class="hljs-params">(ProducerRecord&lt;K, V&gt; record)</span></span>;<span class="hljs-function">Future&lt;RecordMetadata&gt; <span class="hljs-title">send</span><span class="hljs-params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span></span>;</code></pre></li></ul><h4 id="异步发送"><a href="#异步发送" class="headerlink" title="异步发送"></a>异步发送</h4><blockquote><p>在 Kafka 1.0 以后，客户端默认发送都是异步发送，首先追加到生产者的内存缓存中，其内存存储结构如下：</p><p><code>ConcurrentMap&lt;TopicPartition，Deque&lt;ProducerBatch&gt;&gt; batches</code></p><p>Producer 会为每一个 Topic 的每一个 Partition 单独维护一个队列，即 <code>ArrayDeque</code>，内部存放的元素就是一批消息 <code>ProducerBatch</code>，即Kafka消息发送是<strong>批量发送</strong>的。</p></blockquote><p>若需要同步发送，只要拿到 <code>send(record)</code> 方法返回的 <code>future</code>，调用get方法，此时如果消息未发送到Broker上，该方法就会被阻塞，等到 broker 返回消息发送结果后该方法会被唤醒并得到消息发送结果；</p><p>若需要异步发送，则建议使用 <code>send(ProducerRecord&lt; K, V &gt; record, Callback callback)</code>，但是不要调用get方法，Callback 会在收到 broker 的响应结果后被调用，并且支持<strong>拦截器</strong>。</p><blockquote><p>拦截器可以在 <code>消息发送前</code> 和 <code>回调函数被调用前</code> 触发。</p></blockquote><h3 id="发送确认机制"><a href="#发送确认机制" class="headerlink" title="发送确认机制"></a>发送确认机制</h3><p>通过<code>request.required.asks</code>配置</p><ul><li><strong>0</strong>：消息发送给Leader后，不需要确认。性能高，风险最大，如果broker宕机，宕机之后发送的消息就会丢失</li><li><strong>1</strong>：只要集群中的Leader确认即可返回</li><li><strong>-1</strong>：需要ISR中的所有Relica(副本)（集群中的所有broker）确认。还是有可能出现数据丢失，因为ISR可能缩小到只有一个Replica。</li></ul><h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><ul><li><p>消费者是主动 <code>pull</code> 消息</p><blockquote><p>因为 Broker 中的消息是无状态的，Broker 不知道哪个消息是可以消费的，这样还会降低Broker的压力。</p></blockquote></li><li><p>Consumer 消费消息之后必须要去通知 ZooKeeper 记录下消费的 offset（所以可能<a href="#%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9">重复消费</a>）</p></li></ul><h3 id="提交方式"><a href="#提交方式" class="headerlink" title="提交方式"></a>提交方式</h3><ul><li>自动提交</li><li>手动提交（灵活控制offset）</li></ul><h3 id="poll模型"><a href="#poll模型" class="headerlink" title="poll模型"></a>poll模型</h3><p>通过 <code>poll</code> 方法，先调用 <code>fetcher</code> 中的 <code>fetchedRecords</code> 方法</p><blockquote><p>如果 <code>fetchedRecords </code> 获取不到数据，就会发起一个新的 <code>sendFetches</code> 请求。</p></blockquote><p>而在消费数据的时候，每个批次从Kafka Broker Server中拉取数据是有最大数据量限制，由属性 <code>max.poll.records</code> 控制，默认是500条。</p><blockquote><p>提示：<code>max.poll.records</code> 返回的是一个poll请求的数据总和，<strong>与多少个分区无关</strong>；因此，每次Consumer所有分区中拉取Topic的消息数据，总条数不会超过max.poll.records所设置的值。</p></blockquote><p>而在Fetcher的类中，在sendFetches方法中有限制拉取数据容量的限制，由属性（max.partition.fetch.bytes），默认1MB。</p><blockquote><p><a href="https://matt33.com/2017/11/11/consumer-pollonce/#pollOnce-%E6%96%B9%E6%B3%95">https://matt33.com/2017/11/11/consumer-pollonce/#pollOnce-%E6%96%B9%E6%B3%95</a></p></blockquote><h1 id="消息持久化"><a href="#消息持久化" class="headerlink" title="消息持久化"></a>消息持久化</h1><ul><li><p><strong>LSO</strong>：Last Stable Offset, 日志开始偏移量, 标志日志文件起始处</p></li><li><p><strong>LEO</strong>：log end offset, 日志结束偏移量，表示当前日志文件中下一条待写入的消息的offset</p></li><li><p><strong>HW</strong>：High Watermark. 高水位, 表示特定的消息的offset, 消费者只能消费这个offset之前的消息</p></li><li><p><strong>LW</strong>：Low Watermark. 低水位, AR集合中最小的LSO值</p></li></ul><h3 id="删除策略"><a href="#删除策略" class="headerlink" title="删除策略"></a>删除策略</h3><p>Kafka日志管理器中会有一个专门的日志删除任务来<strong>周期性</strong>检测和删除不符合保留条件的日志分段文件，通过broker端参数 <code>log.retention.check.interval.ms</code> 来配置，默认值为 <code>300000</code> (5分钟)。</p><ul><li>基于时间</li><li>基于大小</li><li>基于起始偏移量</li></ul><h3 id="顺序写"><a href="#顺序写" class="headerlink" title="顺序写"></a>顺序写</h3><p>以为顺序写，所以读操作不会阻塞写操作</p><h1 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h1><p>总的来说Kafka快的原因：</p><ul><li>Partition顺序读写，充分利用磁盘特性，这是基础；</li><li>Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入；（<strong>mmap+write</strong>)</li><li>Customer从broker读取数据时，Kafka使用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。(<strong>sendfile</strong>)</li></ul><h1 id="事务特性"><a href="#事务特性" class="headerlink" title="事务特性"></a>事务特性</h1><p>主要就是将多条消息的发送作为一个事务，要么都发送成功要么都失败。</p><h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><img alt="Producer连接Kafka集群" src="https://raw.githubusercontent.com/melopoz/pics/master/img/kakfa%E9%9B%86%E7%BE%A4.png" style="zoom:80%;" /><h4 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h4><blockquote><p>Kafka集群中的一个broker会被选举为controller，负责Partition的管理和replica状态管理，也会执行Partition重分配的任务。</p></blockquote><p>Leader</p><blockquote><p>Leader通过单独的线程定期检测ISR中Follower</p></blockquote><h4 id="Replica-副本"><a href="#Replica-副本" class="headerlink" title="Replica 副本"></a>Replica 副本</h4><blockquote><p><a href="https://blog.51cto.com/zero01/2501495#h3">https://blog.51cto.com/zero01/2501495#h3</a></p></blockquote><ul><li>副本集是指将日志复制多份（Kafka的数据是存储在日志文件中的，这就相当于数据的备份、冗余）</li><li>可以为每个Topic设置副本集，所以副本集是相对于Topic来说的</li><li>可以配置默认的副本集数量</li></ul><p>为了提高数据的可靠性</p><blockquote><p>一个Topic的副本集可以分布在多个Broker中，当一个Broker挂掉了，其他的Broker上还有数据。</p><p>每个Partition在每个broker上最多只能有一个replica（也因此可以由Broker id指定Partition的具体replica；replica<strong>默认均匀分布</strong>到所以broker上）</p></blockquote><p>我们都知道在Kafka中的Topic只是个逻辑概念，实际存储数据的是物理分区Partition，所以真正被复制的也是Partition。如下图：</p><img alt="kafka副本" src="https://raw.githubusercontent.com/melopoz/pics/master/img/kafka%20replica.png" style="zoom:50%;" /><h5 id="副本因子"><a href="#副本因子" class="headerlink" title="副本因子"></a>副本因子</h5><p>副本因子其实决定了一个Partition的副本数量是多少</p><blockquote><p>例如副本因子为1，则代表将Topic中的所有Partition按照Broker的数量复制一份，并分布到各个Broker上（每个broker上都有备份）</p></blockquote><h5 id="副本分配算法"><a href="#副本分配算法" class="headerlink" title="副本分配算法"></a>副本分配算法</h5><p>将所有 <code>N</code> 个 Broker 和待分配的 <code>i</code> 个 Partition 排序</p><p>将第 <code>i</code> 个Partition 分配到第 <code>(i mod n)</code> 个 Broker 上</p><p>将第 <code>i</code> 个Partition 的第 <code>j</code> 个副本分配到第 <code>((i + j) mod n)</code> 个 Broker 上</p><h5 id="Replica-分为-Leader-和-Follower"><a href="#Replica-分为-Leader-和-Follower" class="headerlink" title="Replica 分为 Leader 和 Follower"></a>Replica 分为 Leader 和 Follower</h5><ul><li><strong>Leader</strong>：只有Leader对外提供服务（生产、消费），producer和consumer都是和Leader交互。</li><li><strong>Follower</strong>：同步的时候数据是由Follower周期性尝试将数据pull过来，副本的同步机制是 <strong>ISR</strong>。不完全同步，也不完全异步。</li></ul><h5 id="副本数据同步策略-ISR-OSR-AR"><a href="#副本数据同步策略-ISR-OSR-AR" class="headerlink" title="副本数据同步策略 ISR (OSR / AR)"></a>副本数据同步策略 ISR (OSR / AR)</h5><blockquote><p>AR：Assigned Replicas 所有副本</p><p>ISR：In-Sync Replicas 与Leader保持一定程度同步的副本（包括Leader副本）</p><p>OSR：Out-Sync Replicas 与Leader副本同步落后过多的副本（不包括Leader副本）</p></blockquote><p>AR = ISR + OSR</p><blockquote><p>正常情况下，所有Follower副本都应该与Leader副本保持一定程度的同步，即AR=ISR，OSR为空。</p></blockquote><p>Leader负责跟踪<strong>ISR</strong>中Follower副本的之后状态，掉队就移除。</p><blockquote><p>只有ISR集合中的副本才有资格被选举为Leader</p></blockquote><p><code>replica.lag.time.max.ms</code>：Follower能落后Leader的最长时间间隔，默认 10s。</p><blockquote><p>Follower因不能及时跟上Leader的同步而被踢出ISR之后还会继续同步，之后如果跟上了Leader，还会被加入ISR。</p></blockquote><p>ISR的管理在zookeeper中的节点位置：<code>/brokers/Topics/[Topic]/Partitions/[Partition]/state</code></p><h5 id="备份恢复机制"><a href="#备份恢复机制" class="headerlink" title="备份恢复机制"></a>备份恢复机制</h5><p>如果Leader挂掉了，会从replica中选取一个做为新的Leader，并且从ISR中移除原Leader。</p><p>如果所有的副本都宕机后，有两种策略：</p><ol><li>等待ISR中的任意一个replica恢复，并选举为Leader；如果ISR中一个也不能恢复，该Partition永久不可用。相对较少丢失数据。</li><li>选取第一个恢复的replica作为Leader，不论是不是在ISR中（可能是OSR）。较高的可用性但是可能会丢失数据。</li></ol><h5 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h5><p>直接从ISR中选一个最快的设为Leader</p><h1 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h1><p>基于TCP</p><blockquote><p><a href="http://09itblog.site/?p=867">http://09itblog.site/?p=867</a></p></blockquote><h1 id="常见问题☆"><a href="#常见问题☆" class="headerlink" title="常见问题☆"></a>常见问题☆</h1><p>消息丢失</p><p><a href="https://blog.csdn.net/weixin_39983554/article/details/110361423">https://blog.csdn.net/weixin_39983554/article/details/110361423</a></p><p>数据大小限制？</p><p><a href="https://blog.csdn.net/qq_37502106/article/details/80271800">https://blog.csdn.net/qq_37502106/article/details/80271800</a></p><p>问题集锦</p><p><a href="https://blog.csdn.net/chenwiehuang/article/details/100172204">https://blog.csdn.net/chenwiehuang/article/details/100172204</a></p><h4 id="消息丢失"><a href="#消息丢失" class="headerlink" title="消息丢失"></a>消息丢失</h4><ul><li><p>生产端</p><blockquote><p>同步模式下：消息确认模式为1的时候(保证写入Leader成功)，如果刚好Leader Partition挂了，会丢失数据。</p><p>异步模式下：缓存区满了，消息确认模式为0的时候(消息发出不需要确认)，会丢失数据。</p></blockquote></li><li><p>消费端</p><blockquote><p>consumer从Topic中拉取到消息，还没有消费成功就提交了offset。</p></blockquote></li></ul><h4 id="重复消费"><a href="#重复消费" class="headerlink" title="重复消费"></a>重复消费</h4><ol><li><p>强行kill线程、消费系统宕机、重启等各种原因导致消费数据后，<strong>offset没有成功提交</strong>；</p></li><li><p>设置offset为自动提交，如果在close之前（提交offset），调用了consumer.unsubscribe()就有可能部分offset还没提交，下次就会重复消费；</p></li><li><p>Consumer消费消息需要太长时间导致会话超时（或心跳机制检测出问题）</p><blockquote><pre><code class="hljs stylus">session<span class="hljs-selector-class">.timeout</span><span class="hljs-selector-class">.ms</span> 默认 <span class="hljs-number">10s</span>group<span class="hljs-selector-class">.min</span><span class="hljs-selector-class">.session</span><span class="hljs-selector-class">.timeout</span><span class="hljs-selector-class">.ms</span> 默认 <span class="hljs-number">6s</span>group<span class="hljs-selector-class">.max</span><span class="hljs-selector-class">.session</span><span class="hljs-selector-class">.timeout</span><span class="hljs-selector-class">.ms</span> 默认 <span class="hljs-number">30</span>min</code></pre><p>当Consumer处理消费的业务逻辑的时候，如果在<code>10s</code>内没有处理完，那么消费者客户端就会与Kafka Broker Server断开，即使Consumer设置了<strong>自动提交</strong>属性，也会报错（提交失败），broker会认为这个Consumer出问题了所以把这个Partition的消息rebalance到其他的Consumer，导致重新消费。</p><p>所以每次拉取的消息数 和 timeout 要合理。</p></blockquote></li></ol><h5 id="如何保证不重复消费"><a href="#如何保证不重复消费" class="headerlink" title="如何保证不重复消费"></a>如何保证不重复消费</h5><p>只好结合业务场景对消息消费做<strong>幂等处理</strong>。</p><blockquote><p>比如在redis或数据库记录已消费的消息，producer生产消息的时候入库消息未消费，consumer消费完在数据库update为已消费。</p><p>或者换RocketMQ…</p></blockquote><h4 id="如何处理replica的全部宕机"><a href="#如何处理replica的全部宕机" class="headerlink" title="如何处理replica的全部宕机"></a>如何处理replica的全部宕机</h4><p><a href="#%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%9C%BA%E5%88%B6">备份恢复机制</a></p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>配置文件<code>config/server.properties</code></p><pre><code class="hljs properties"><span class="hljs-comment">#日志所在目录</span><span class="hljs-meta">log.dirs</span>=<span class="hljs-string">/tmp/Kafka-logs</span><span class="hljs-comment">#开启可能会造成数据丢失</span><span class="hljs-meta">unclean.Leader.election.enable</span>=<span class="hljs-string">false</span><span class="hljs-comment">#如果Leader发现Follower有 多久(10s) 没有发送fetch请求了，那么Leader就把它从ISR移除。</span><span class="hljs-meta">replica.lag.time.max.ms</span>=<span class="hljs-string">10000</span><span class="hljs-comment">#至少保证ISR中有几个replica</span><span class="hljs-meta">min.insync.replicas</span>=<span class="hljs-string">1</span><span class="hljs-comment">#发送确认机制：0/1/-1</span><span class="hljs-meta">request.required.asks</span>=<span class="hljs-string">0</span></code></pre><h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><pre><code class="hljs sh">bin/Kafka-server-start.sh config/server.properties <span class="hljs-comment">#启动</span>bin/Kafka-server-start.sh -daemon config/server.properties <span class="hljs-comment">#后台启动</span></code></pre><p>命令均在Kafka的bin目录下</p><pre><code class="hljs sh"><span class="hljs-comment">#创建Topic</span>bin/Kafka-Topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --Partitions 1 --Topic <span class="hljs-built_in">test</span><span class="hljs-comment">#查看Topic列表</span>bin/Kafka-Topics.sh --list --zookeeper localhost:2181<span class="hljs-comment">#产生消息，创建消息生产者</span>bin/Kafka-console-producer.sh --broker-list localhost:9092 --Topic <span class="hljs-built_in">test</span><span class="hljs-comment">#消费消息，创建消息消费者</span>bin/Kafka-console-consumer.sh --broker-list localhost:9092 --Topic <span class="hljs-built_in">test</span><span class="hljs-comment">#查看Topic的消息</span>bin/Kafka-Topics.sh --describe --zookeeper localhost:2181 --Topic <span class="hljs-built_in">test</span><span class="hljs-comment">#删除Topic</span>bin/Kafka-Topics.sh --delete --zookeeper localhost:2181 --Topic <span class="hljs-built_in">test</span><span class="hljs-comment">#修改分区数为6</span>bin/Kafka-Topics.sh --alter --Partitions 6 --zookeeper localhost:2181 --Topic <span class="hljs-built_in">test</span></code></pre>]]></content>
    
    
    <categories>
      
      <category>MQ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>内存分配算法</title>
    <link href="/blog/2021/01/01/OS_%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AE%97%E6%B3%95/"/>
    <url>/blog/2021/01/01/OS_%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h3 id="常见的内存分配器实现-jemalloc-ptmalloc-tcmalloc"><a href="#常见的内存分配器实现-jemalloc-ptmalloc-tcmalloc" class="headerlink" title="常见的内存分配器实现: jemalloc, ptmalloc, tcmalloc"></a>常见的内存分配器实现: jemalloc, ptmalloc, tcmalloc</h3><p>ptmalloc: per thread malloc</p><blockquote><p>基于glibc(<code>glibc是linux系统中最底层的api</code>)实现的, 是一个标准实现, 兼容性好</p><p>由于过于考虑性能, 多线程之间内存不共享, 各线程使用独立内存, 所以在内存开销很大.</p></blockquote><p>tcmalloc: thread caching malloc</p><blockquote><p>为每个线程分配一个局部缓存, 小对象直接有线程局部缓存来完成分派, 大对象用自旋锁减少锁竞争.</p></blockquote><p>jemalloc: </p><blockquote><p>将内存分配粒度划分为 small,large,huge ,并记录mate数据, 空间占用略大于tcmalloc, 内存碎片少于tcmalloc</p></blockquote><h3 id="常用的内存分配器算法"><a href="#常用的内存分配器算法" class="headerlink" title="常用的内存分配器算法"></a>常用的内存分配器算法</h3><h4 id="动态内存分配"><a href="#动态内存分配" class="headerlink" title="动态内存分配"></a>动态内存分配</h4><p>Dynamic memory allocation , 又称 堆内存分配, 简称DMA</p><blockquote><p>DMA 是从一整块内存中按需分配，对于分配出的内存会记录元数据，同时还会使用空闲分区链维护空闲内存，便于在内存分配时查找可用的空闲分区</p></blockquote><p>常用的三种查找策略</p><ol><li><p>首次适应算法 first fit</p><blockquote><p>每次分配都从低地址开始查找 造成低地址会不断被分配, 也会产生很多小的空闲分区</p></blockquote></li><li><p>循环首次适应算法 next fit</p><blockquote><p>在first fit 的基础上, 每次分配不从头开始查找, 而是从上次的位置开始查找</p><p>查找效率提升, 但是空闲分区链中的大空闲分区越来越少!</p></blockquote></li><li><p>最佳适应算法 best fit</p><blockquote><p>每次分配完把链表按照 空闲分区大小递增 的顺序保持.</p><p>第一个满足分配条件的空间分区就是最优解. 但是维护这个排序会损耗性能.</p></blockquote></li></ol><h4 id="伙伴算法"><a href="#伙伴算法" class="headerlink" title="伙伴算法"></a>伙伴算法</h4><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D-%E4%BC%99%E4%BC%B4%E7%AE%97%E6%B3%95.png" style="zoom:33%;" /><p>将物理内存按照2的次幂进行划分, 分配时也是按照2的次幂按需分配,  2KB, 4KB, 8KB, 16KB… </p><p>比如请求10KB的内存就会按照16KB分配. 具体过程:</p><blockquote><ol><li>找到存储 2^4=16 的连续 page 对应的链表, 即数组中下标为4 (拉链)</li><li>从找到的链表中寻找空闲的内存块, 找到则分配;</li><li>找不到, 就沿着数组向上寻找, 即从 下标为5的链表寻找空闲的page</li><li>找到空闲的page之后,将其分为 2 个 2^4 的内存块(16Page), 其中一块分配给进程, 另一块链接到 数组中下标为4的链表.</li></ol></blockquote><p>释放内存时的过程:</p><blockquote><ol><li>检查伙伴块是否也已释放(是否为空闲) , 如果已释放(空闲), 将两个块合成更大的块</li><li>再 判断当前链表的内存块个数 是否 小于 阈值, 如果不小于 就会再次执行这个检查流程</li></ol></blockquote><blockquote><p>弊: 减少了外部碎片, 增加了内部碎片(最多50%)</p></blockquote><h5 id="内存碎片"><a href="#内存碎片" class="headerlink" title="* 内存碎片"></a>* 内存碎片</h5><p><strong>内部碎片</strong>: 内存按照page分配, 即使只需要很少的内存, 操作系统至少分配4K的page, 那么这个page中未使用的部分就形成了内存碎片.</p><p><strong>外部碎片</strong>: 如果需要一大块内存, 操作系统会分配连续的page, 如果前边的page被回收, 就出现了外部碎片</p><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87-%E5%A4%96%E9%83%A8%E7%A2%8E%E7%89%87.png" style="zoom:33%;" /><h4 id="Slab算法"><a href="#Slab算法" class="headerlink" title="Slab算法"></a>Slab算法</h4><p>在伙伴算法的基础上优化对小内存的分配, 解决内部碎片问题.</p><blockquote><p>在 Slab 算法中维护着大小不同的 Slab 集合，在最顶层是 cache_chain，cache_chain 中维护着一组 kmem_cache 引用，kmem_cache 负责管理一块固定大小的对象池。通常会提前分配一块内存，然后将这块内存划分为大小相同的 slot，不会对内存块再进行合并，同时使用位图 bitmap 记录每个 slot 的使用情况。</p><p>kmem_cache 中包含三个 Slab 链表：<strong>完全分配使用 slab_full</strong>、<strong>部分分配使用 slab_partial</strong> 和<strong>完全空闲 slabs_empty</strong>，这三个链表负责内存的分配和释放。每个链表中维护的 Slab 都是一个或多个连续 Page，每个 Slab 被分配多个对象进行存储。Slab 算法是基于对象进行内存管理的，它把相同类型的对象分为一类。当分配内存时，从 Slab 链表中划分相应的内存单元；当释放内存时，Slab 算法并不会丢弃已经分配的对象，而是将它保存在缓存中，当下次再为对象分配内存时，直接会使用最近释放的内存块。</p><p>单个 Slab 可以在不同的链表之间移动，例如当一个 Slab 被分配完，就会从 slab_partial 移动到 slabs_full，当一个 Slab 中有对象被释放后，就会从 slab_full 再次回到 slab_partial，所有对象都被释放完的话，就会从 slab_partial 移动到 slab_empty。</p></blockquote><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AE%97%E6%B3%95-Slab%E7%AE%97%E6%B3%95.png" style="zoom:33%;" /><h2 id="jemalloc"><a href="#jemalloc" class="headerlink" title="jemalloc"></a>jemalloc</h2><p><a href="https://kaiwu.lagou.com/course/courseInfo.htm?sid=&amp;courseId=516&amp;lagoufrom=noapp&amp;sharetype=wx_friend&amp;wxinfo=2#/detail/pc?id=4925">https://kaiwu.lagou.com/course/courseInfo.htm?sid=&amp;courseId=516&amp;lagoufrom=noapp&amp;sharetype=wx_friend&amp;wxinfo=2#/detail/pc?id=4925</a></p><p>……..</p>]]></content>
    
    
    <categories>
      
      <category>OS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OS</tag>
      
      <tag>内存管理</tag>
      
      <tag>about netty</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一台计算机供电之后...</title>
    <link href="/blog/2021/01/01/OS_%E5%BC%95%E5%AF%BC%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E6%A6%82%E6%B5%81%E7%A8%8B/"/>
    <url>/blog/2021/01/01/OS_%E5%BC%95%E5%AF%BC%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%A4%A7%E6%A6%82%E6%B5%81%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<p>给主板供电，让CPU运行BIOS，BIOS会按顺序走引导程序，装系统的时候不就是这样嘛  把macos系统引导放到了win boot前边就默认走macos了，the hackintosh。。</p><blockquote><p>BIOS（Base Input/Output System)一般存在主板的ROM（Read Only Memory）中。</p></blockquote><blockquote><p>总线：数据总线，地址总线，控制总线。  总线其实就是数据线，一根传1位，32位有32根并排着，64位有64根并排着。</p></blockquote><h4 id="base"><a href="#base" class="headerlink" title="base"></a>base</h4><p>内存：存储数据，输入地址信号输出数据（命令，代码，数据）</p><p>CPU：从内存中拿到数据（命令）并执行</p><blockquote><p>如果是在执行命令，命令肯定会提供内存地址，但是最源头的时候，比如CPU刚通电的时候，这个地址就得是硬编码写死的了。</p></blockquote><blockquote><p>如果通过地址找不到数据，就会导致缺页异常，详见 内存映射…</p></blockquote><blockquote><p>当CPU正在处理内部数据时，外界发生了紧急情况，要求CPU暂停当前的工作转去处理这个紧急事件。处理完毕后，再回到原来被中断的地址，继续原来的工作，这样的过程称为中断</p></blockquote><blockquote><p>CPU的寻址空间   详见 内存管理…</p></blockquote><blockquote><p>cpu从寄存器拿地址，从内存中拿数据(命令)并执行，</p></blockquote><blockquote><p>内存中不能存储全部数据(命令，代码),</p><p>加载 load  把磁盘中的数据复制到 内存中</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>OS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BIOS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HDFS</title>
    <link href="/blog/2021/01/01/%E5%88%86%E5%B8%83%E5%BC%8F_HDFS/"/>
    <url>/blog/2021/01/01/%E5%88%86%E5%B8%83%E5%BC%8F_HDFS/</url>
    
    <content type="html"><![CDATA[<p>目录树结构</p><p>角色namenode datanode 角色即进程</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><h4 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h4><p>基于内存存储文件元数据、目录结构、文件block的映射</p><p>需要持久化方案提供数据可靠性</p><p>提供副本放置策略</p><h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><p>基于本地磁盘存储block（块）（以文件形式）</p><p>保存block的校验和数据 保证block的可靠性</p><p>和NameNode保持心跳，汇报block的列表状态</p><h3 id="数据恢复策略："><a href="#数据恢复策略：" class="headerlink" title="数据恢复策略："></a>数据恢复策略：</h3><ul><li><p>日志文件(记录所有操作，恢复时重新执行一遍)</p><blockquote><p>恢复慢 数据全</p></blockquote></li><li><p>镜像 快照 dump db 序列化</p><blockquote><p>恢复快 数据不全(因为只能间隔一段时间备份一下)</p></blockquote></li></ul><h4 id="HDFS的数据恢复策略："><a href="#HDFS的数据恢复策略：" class="headerlink" title="HDFS的数据恢复策略："></a>HDFS的数据恢复策略：</h4><ul><li>EditsLog  日志</li><li>FsImage  镜像、快照</li></ul><blockquote><p>EditsLog和FsImage存储在本地磁盘</p></blockquote><p>HDFS采用最近时间点的FsImage + 增量的EditsLog</p><blockquote><p>任何修改文件系统元数据的操作，NameNode都会使用EditsLog记录到事务日志</p><p>使用FsImage存储内存中所有元数据状态</p></blockquote><h3 id="Block的副本放置策略"><a href="#Block的副本放置策略" class="headerlink" title="Block的副本放置策略"></a>Block的副本放置策略</h3><p>默认为每个数据块放3个副本，按照部署在NameNode上的默认机架感知策略存放数据副本。</p><ul><li><p>第一个block副本放在上传文件的datanode，如果是集群外上传文件到hdfs，则随机挑选一个磁盘剩余空间大，cpu比较轻松的datanode；</p></li><li><p>第二个block副本放在和第一个副本 不同机架 中的另一个datanode（随机选择）；</p></li><li><p>第三个block副本放在和第二个副本 相同机架 中的节点；</p><blockquote><p>这样就只通过一个交换机(当前机架的交换机)，如果放在其他机架，就要通过更多交换机传输，效率会变低</p></blockquote></li><li><p>第n个block副本放在 随机节点。</p></li></ul><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/hdfs-%E5%89%AF%E6%9C%AC%E4%BD%8D%E7%BD%AE.png" style="zoom:33%;" /><h3 id="HDFS写流程"><a href="#HDFS写流程" class="headerlink" title="HDFS写流程"></a>HDFS写流程</h3><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/hdfs-%E5%86%99%E6%B5%81%E7%A8%8B.png" /><blockquote><p>block 块  packet小包(64kb)  chunk大块(512kb)</p><p>写入数据的时候DN以chunk为单位进行数据校验。</p></blockquote><p>想NN请求上传文件，NN返回是否可以上传，client对文件进行切分(比如一个block64M，200M的文件就会分成64 64 64 8)，client向NN请求第一个block应该存储到的DN服务器，NN返回第一个DN服务器，client请求第一个DN(RPC调用，建立pipeline)，client发送第一个packet到DN1，传输完成像DN1发送第二个packet，同时DN1向DN2发送第一个packet… …  以此类推。</p><blockquote><p> 这样就比client发送整个大包到DN1，传输完成DN1发送打包到DN2… 效率要高很多</p></blockquote><p>第一个block传输完成，client再次请求NN上传第二个block</p><h3 id="HDFS读流程"><a href="#HDFS读流程" class="headerlink" title="HDFS读流程"></a>HDFS读流程</h3><ol><li>跟NN通信查询元数据(block所在的DN的节点)，找到文件块所在的DN的服务器。</li><li>挑选一台DN（就近原则，然后随机）服务器，请求建立socket流。</li><li>DN开始发送数据（从磁盘里读取数据放入流，以packet为单位做校验）</li><li>客户端以packet为单位接收，先在本地缓存，然后写入目标文件中，后面的block块就相当于append到前面的block块，最后合成最终需要的文件</li></ol><h4 id="读取某个指定的block"><a href="#读取某个指定的block" class="headerlink" title="读取某个指定的block"></a>读取某个指定的block</h4><p>下载一个文件：（获取文件的所有block元数据）</p><ul><li>client和NN交互文件元数据获取fileBlockLocation</li><li>NN按距离策略排序返回</li><li>client尝试下载block并校验数据完整性</li></ul><p>”下载一个文件“的子集：获取某些block</p><blockquote><p> HDFS支持client给出我文件的offset，自定义连接某个block所在的DN，自定义获取数据.</p><p>这是支持计算层分治、并行计算的核心</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop</title>
    <link href="/blog/2021/01/01/%E5%88%86%E5%B8%83%E5%BC%8F_Hadoop/"/>
    <url>/blog/2021/01/01/%E5%88%86%E5%B8%83%E5%BC%8F_Hadoop/</url>
    
    <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>主要包括ResourceManager、NodeManager</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>安装好jdk1.8的linux系统下</p><ol><li><p>创建hadoop用户</p><pre><code class="hljs sh">$ sudo useradd -m hadoop -s /bin/bash  <span class="hljs-comment">#创建hadoop用户，并使用/bin/bash作为shell</span>$ sudo passwd hadoop                   <span class="hljs-comment">#为hadoop用户设置密码，之后需要连续输入两次密码</span>$ sudo adduser hadoop sudo             <span class="hljs-comment">#为hadoop用户增加管理员权限</span>$ su - hadoop                          <span class="hljs-comment">#切换当前用户为用户hadoop</span>$ sudo apt-get update                  <span class="hljs-comment">#更新hadoop用户的apt,方便后面的安装</span></code></pre></li><li><p>设置ssh和无密码登陆</p><pre><code class="hljs sh">$ sudo apt-get install openssh-server   <span class="hljs-comment">#安装SSH server</span><span class="hljs-comment">#需要版本对应，安装报依赖不合格的话就apt install 对应版本的client即可</span>$ ssh localhost                         <span class="hljs-comment">#登陆SSH，第一次登陆输入yes</span>$ <span class="hljs-built_in">exit</span>                                  <span class="hljs-comment">#退出登录的ssh localhost</span>$ <span class="hljs-built_in">cd</span> ~/.ssh/                            <span class="hljs-comment">#如果没法进入该目录，执行一次ssh localhost</span>$ ssh-keygen -t rsa　<span class="hljs-comment">#然后的三次输入都确定即可 直接回车</span>$ cat ./id_rsa.pub &gt;&gt; ./authorized_keys <span class="hljs-comment">#加入授权</span>$ ssh localhost                         <span class="hljs-comment">#此时已不需密码即可登录localhost，如果失败则可以搜索SSH免密码登录来寻求答案</span></code></pre></li><li><p>下载hadoop-xxx.tar.gz解压到/usr/local/hadoop…</p><pre><code class="hljs sh">   sudo tar -zxvf hadoop-xxx.tar.gz -C /usr/<span class="hljs-built_in">local</span>   <span class="hljs-built_in">cd</span> /usr/<span class="hljs-built_in">local</span>mv hadoop-xxx/ hadoop/ <span class="hljs-comment">#将/usr/local/hadoop-xxx 改名为 /usr/local/hadoop</span>   sudo chown -R hadoop ./hadoop <span class="hljs-comment">#授权  </span>sudo chmod 777 /usr/<span class="hljs-built_in">local</span>/hadoop</code></pre></li><li><p>配置环境变量 (已配置JAVA的环境变量)</p><pre><code class="hljs shell">sudo vim /etc/profile</code></pre><pre><code class="hljs sh"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/<span class="hljs-built_in">local</span>/jdk1.8<span class="hljs-built_in">export</span> HADOOP_HOME=/usr/<span class="hljs-built_in">local</span>/hadoop<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_HOME</span>/bin:<span class="hljs-variable">$HADOOP_HOME</span>/sbin:<span class="hljs-variable">$JAVA_HOME</span>/bin<span class="hljs-comment">#export CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$CLASSPATH</span><span class="hljs-built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/lib/native<span class="hljs-comment">#export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib:$HADOOP_COMMON_LIB_NATIVE_DIR&quot;</span></code></pre><pre><code class="hljs sh"><span class="hljs-built_in">source</span> /etc/profile <span class="hljs-comment">#使配置文件生效</span></code></pre></li><li><p><code>hadoop version</code>即可查看版本</p></li></ol><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>可以在官网下查看各配置作用,左下角config</p><pre><code class="hljs http">https://hadoop.apache.org/docs/r2.10.0/</code></pre><p>hadoop有默认配置文件和自定义配置文件，jar包中可以找到default.xml文件</p><ul><li><p>默认配置文件</p><table><thead><tr><th>默认文件</th><th align="left">jar包</th></tr></thead><tbody><tr><td>core-default.xml</td><td align="left">hadoop-common-x.x.x.jar</td></tr><tr><td>hdfs-default.xml</td><td align="left">hadoop-hdfs-x.x.x.jar</td></tr><tr><td>yarn-default.xml</td><td align="left">hadoop-yarn-common-x.x.x.jar</td></tr><tr><td>mapred-default.xml</td><td align="left">hadoop-mapreduce-client-core-.x.x.x.jar</td></tr></tbody></table></li><li><p>自定义配置文件</p><table><thead><tr><th>默认文件</th><th align="left">jar包</th></tr></thead><tbody><tr><td>core-site.xml</td><td align="left">hadoop-common-x.x.x.jar</td></tr><tr><td>hdfs-site.xml</td><td align="left">hadoop-hdfs-x.x.x.jar</td></tr><tr><td>yarn-site.xml</td><td align="left">hadoop-yarn-common-x.x.x.jar</td></tr><tr><td>mapred-site.xml</td><td align="left">hadoop-mapreduce-client-core-.x.x.x.jar</td></tr></tbody></table></li></ul><h3 id="伪分布式配置"><a href="#伪分布式配置" class="headerlink" title="伪分布式配置"></a>伪分布式配置</h3><blockquote><p>cd /usr/local/hadoop</p></blockquote><ol><li><p>配置hadoop-env.sh,添加环境变量</p><pre><code class="hljs sh"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/<span class="hljs-built_in">local</span>/jdk1.8</code></pre></li><li><p>修改core-site.xml文件</p><blockquote><p>file:/  本地模式使用的协议</p><p>hdfs://  分布式模式使用的协议</p></blockquote><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><span class="hljs-comment">&lt;!--其他临时目录--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>Abase for other temporary directories.<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-comment">&lt;!--默认文件系统的名称。一个URI，其模式和权限决定文件系统的实现。uri的模式决定了命名文件系统实现类的配置属性(fs. schema .impl)。uri的权限用于确定文件系统的主机、端口等。默认file:///--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://localhost:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre></li><li><p>修改hdfs-site.xml</p><blockquote><p> dfs.replication副本数：默认3</p></blockquote><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><span class="hljs-comment">&lt;!--默认的块复制。可以在创建文件时指定复制的实际数目。如果在创建时未指定复制，则使用默认值 3--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-comment">&lt;!-- 确定DFS数据节点应该将其块存储在本地文件系统的哪个位置。如果这是一个以逗号分隔的目录列表，那么数据将存储在所有命名的目录中，通常在不同的设备上。对于HDFS存储策略，目录应该使用相应的存储类型([SSD]/[DISK]/[ARCHIVE]/[RAM_DISK])进行标记。如果目录没有显式标记的存储类型，则默认存储类型为DISK。如果本地文件系统权限允许，将创建不存在的目录。默认值 file://$&#123;hadoop.tmp.dir&#125;/dfs/data --&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre></li><li><p>格式化NameNode</p><pre><code class="hljs sh">bin/hdfs namenode -format</code></pre><blockquote><p>有数据的时候格式化namenode会使/usr/local/hadoop/tmp/dfs/data/name/current/VERSION中的clusterID会和datanode的clusterID不一致,所以必须先删除DataNode中的数据</p></blockquote></li><li><p>启动</p><pre><code class="hljs shell">sbin/start-all.sh</code></pre><p>启动完成可以使用jps查看进程</p><blockquote><p>DataNode</p><p>NameNode</p><p>NodeManager</p><p>ResourceManager</p><p>SecondaryNameNode</p></blockquote></li><li><p>配置yarn (非必须)  重启</p><blockquote><ol><li><p>在/usr/local/hadoop-xxx/etc/hadoop目录下</p><pre><code class="hljs shell">cp mapred-site.xml.template mapred-site.xml</code></pre></li><li><p>修改mapred-site.xml</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><span class="hljs-comment">&lt;!-- 用于执行MapReduce作业的运行时框架。可以是local, classic 或者 yarn --&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre></li><li><p>修改yarn-site.xml</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><span class="hljs-comment">&lt;!-- 一个逗号分隔的服务列表，其中服务名应该只包含A- z a - z 0 -9_，并且不能以数字开头。 shuffle混洗重组模式 --&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre></li><li><p>单独启动resourcemanager 和 nodemaneger</p><pre><code class="hljs shell">sbin/yarn-daemon.sh start resourcemanagersbin/yarn-daemon.sh start nodemanager</code></pre></li></ol></blockquote></li><li><p>启动历史资源管理器</p><blockquote><p> 就能在8088的记录中点击<u>history</u>链接，展示对历史mp的history链接中显示详细信息</p></blockquote><ul><li><p>配置mapred-site.xml</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>localhost:10020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>localhost:19888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></code></pre></li><li><p>启动/关闭 历史服务器</p><pre><code class="hljs shell">sbin/mr-jobhistory-daemon.sh start historyserversbin/mr-jobhistory-daemon.sh stop historyserver</code></pre></li></ul></li><li><p>配置日志聚集 (需要重启NodeNanager ResourceNanager HistoryNanager)</p><blockquote><p>应用运行完成之后，将运行日志信息上传到hdfs。方便开发调试。</p></blockquote><ul><li><p>配置yarn-site.xml</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-comment">&lt;!--日志保留7天--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>604800<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></code></pre></li></ul></li></ol><h6 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h6><pre><code class="hljs sh">bin/hadoop dfsadmin -safemode leave<span class="hljs-comment">#enter - 进入安全模式</span><span class="hljs-comment">#leave - 强制NameNode离开安全模式</span><span class="hljs-comment">#get - 返回安全模式是否开启的信息</span><span class="hljs-comment">#wait - 等待，一直到安全模式结束。</span></code></pre><h2 id="hadoop-example"><a href="#hadoop-example" class="headerlink" title="hadoop example"></a>hadoop example</h2><h3 id="词频统计-wordcount"><a href="#词频统计-wordcount" class="headerlink" title="词频统计 wordcount"></a>词频统计 wordcount</h3><ol><li><p>本地创建words.txt并写入一些单词</p><blockquote><p>touch ~/test/words.txt</p></blockquote></li><li><p>上传到hdfs</p><blockquote><p>hdfs dfs -put ~/test /input</p></blockquote></li><li><p>map reduce</p><pre><code class="hljs sh">hadoop jar /usr/<span class="hljs-built_in">local</span>/hadoop-2.10.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar wordcount /input /output</code></pre></li><li><p>查看结果</p><blockquote><p>hdfs dfs -cat /output/part-r-00000</p></blockquote></li></ol><h3 id="正则抽取-grep"><a href="#正则抽取-grep" class="headerlink" title="正则抽取 grep"></a>正则抽取 grep</h3><pre><code class="hljs gradle">hadoop jar <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/hadoop-2.10.0/</span>share<span class="hljs-regexp">/hadoop/m</span>apreduce<span class="hljs-regexp">/hadoop-mapreduce-examples-2.10.0.jar grep /i</span>nput /output-<span class="hljs-keyword">grep</span> <span class="hljs-string">&#x27;正则表达式&#x27;</span></code></pre><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h3><ul><li><p>创建文件夹</p><blockquote><p>hdfs dfs -mkdir [xx] /…</p><p>​    -p 多级创建  可以-mkdir -p /first/second/xx</p></blockquote></li><li><p>查看ls</p><blockquote><p>hdfs dfs -ls [xx] /…</p><p>​    -R 多级查看  可以将父目录下的子目录也显示出来</p></blockquote></li><li><p>上传到hdfs</p><blockquote><p>hdfs dfs -put 本地路径 hdfs路径、</p></blockquote></li><li><p>删除</p><blockquote><p>hdfs dfs -rm -r /xx  #删除文件夹</p><p>hdfs dfs -rm /xxx/xx.text  #删除文件</p></blockquote></li></ul><h3 id="安全模式-1"><a href="#安全模式-1" class="headerlink" title="安全模式"></a>安全模式</h3><pre><code class="hljs sh">bin/hadoop dfsadmin -safemode leave<span class="hljs-comment">#enter - 进入安全模式</span><span class="hljs-comment">#leave - 强制NameNode离开安全模式</span><span class="hljs-comment">#get - 返回安全模式是否开启的信息</span><span class="hljs-comment">#wait - 等待，一直到安全模式结束。</span></code></pre><h2 id="shuffle"><a href="#shuffle" class="headerlink" title="shuffle"></a>shuffle</h2><p>混洗重组</p><h2 id="分布式搭建"><a href="#分布式搭建" class="headerlink" title="分布式搭建"></a>分布式搭建</h2><ol><li>克隆4台虚拟机，并分别配置ip</li></ol><p>。。。</p>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>CDN(Content Delivery Network，内容分发网络)</title>
    <link href="/blog/2021/01/01/%E7%BD%91%E7%BB%9C_CDN/"/>
    <url>/blog/2021/01/01/%E7%BD%91%E7%BB%9C_CDN/</url>
    
    <content type="html"><![CDATA[<p>CDN ( Content Delivery Network，内容分发网络）</p><p>通过将网站内容（如图片、JavaScript 、CSS、网页等）分发至全网加速节点，配合精准调度系统和边缘缓存，使最终用户可以就近获取所需内容，有效解决互联网网络拥塞问题，提高终端用户访问网站的响应速度和可用性，与此同时，可大幅降低源站压力。</p><h4 id="加速原理"><a href="#加速原理" class="headerlink" title="加速原理"></a>加速原理</h4><p>假设我们（client）访问的域名为<a href="http://www.example.com，该域名已经接入到CDN服务器，那么请求流程就是：">www.example.com，该域名已经接入到CDN服务器，那么请求流程就是：</a></p><p>HTTP请求流程说明：</p><ol><li>用户在浏览器输入要访问的网站域名<a href="http://www.example.com,向本地dns发起域名解析请求./">www.example.com，向本地DNS发起域名解析请求。</a></li><li>本地DNS检查缓存中是否有<a href="http://www.example.com的ip地址记录.如果有,则直接返回给终端用户;如果没有,则向网站授权dns查询./">www.example.com的IP地址记录。如果有，则直接返回给终端用户；如果没有，则向网站授权DNS查询。</a></li><li>网站DNS服务器解析发现域名已经解析到了CNAME：<a href="http://www.example.com.c.cdnhwc1.com./">www.example.com.c.cdnhwc1.com。</a></li><li>请求被指向CDN服务。</li><li>CDN对域名进行智能解析，将响应速度最快的CDN节点IP地址返回给本地DNS。</li><li>用户获取响应速度最快的CDN节点IP地址。</li><li>浏览器在得到最佳节点的IP地址以后，向CDN节点发出访问请求。<ul><li>如果该IP地址对应的节点已缓存该资源，节点将数据直接返回给用户，如图中步骤7和8，请求结束。</li><li>如果该IP地址对应的节点未缓存该资源，节点回源拉取资源。获取资源后，结合用户自定义配置的缓存策略，将资源缓存至节点，如图中的北京节点，并返回给用户，请求结束。配置缓存策略的操作方法，请参见<a href="https://support.huaweicloud.com/usermanual-cdn/cdn_01_0116.html">缓存配置</a>。</li></ul></li></ol><h4 id="CDN是否支持对动态内容进行加速？"><a href="#CDN是否支持对动态内容进行加速？" class="headerlink" title="CDN是否支持对动态内容进行加速？"></a>CDN是否支持对动态内容进行加速？</h4><p>动态内容是指不同的请求访问中获得不同数据的内容，例如：网站中的.asp、.jsp、.php、.perl、.cgi文件、API接口和动态交互请求（post、put和patch等请求）。</p><p>对于动态请求的内容，CDN必然不能缓存实时变化的内容，需要用户每次回源访问您的源站服务器。只能是择优选择源服务器返回源服务器IP。</p><h4 id="还可用来可减轻DDoS攻击"><a href="#还可用来可减轻DDoS攻击" class="headerlink" title="还可用来可减轻DDoS攻击"></a>还可用来可减轻DDoS攻击</h4><p>DDoS（Distributed Denial of Service，分布式拒绝服务攻击）用多台肉鸡服务器同时请求同一服务器，耗尽该服务器的资源，从而让该服务器不能为其用户提供正常服务。</p><p>ps：直接去CDN服务提供商官网肯定能看到产品介绍和工作原理</p><p>又拍云：<a href="https://help.upyun.com/knowledge-base/cdn-product/">https://help.upyun.com/knowledge-base/cdn-product/</a></p><p>华为云：<a href="https://support.huaweicloud.com/productdesc-cdn/cdn_01_0109.html">https://support.huaweicloud.com/productdesc-cdn/cdn_01_0109.html</a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>关于IP地址</title>
    <link href="/blog/2021/01/01/%E7%BD%91%E7%BB%9C_IP/"/>
    <url>/blog/2021/01/01/%E7%BD%91%E7%BB%9C_IP/</url>
    
    <content type="html"><![CDATA[<p>ipv4地址</p><p>比如：192.168.1.1</p><p>转换成二进制</p><p>0000 0000.0000 0000.0000 0000.0000 0000</p><p>​     8   *   4</p><table><thead><tr><th>ipv4地址类别</th><th>二进制格式</th><th>范围</th><th></th></tr></thead><tbody><tr><td>A类</td><td>0xxx xxxx(1+7位网络号).0000 0000.0000 0000.0000 0000(8*3位主机号)</td><td>1.0.0.0—126.0.0.0</td><td>10.X.X.X是私有地址；127.X.X.X是保留地址,用做循环测试用的</td></tr><tr><td>B类</td><td>10xx xxxx.xxxx xxxx(2+14位网络号).0000 0000.0000 0000(8*2位主机号)</td><td>128.0.0.0—191.255.0.0</td><td>172.16.0.0—172.31.255.255是私有地址；169.254.X.X是保留地址；191.255.255.255是广播地址，不能分配</td></tr><tr><td>C类</td><td>110x xxxx.xxxx xxxx.xxxx xxxx(3+21位网络号).0000 0000(8位主机号)</td><td>192.0.0.0—223.255.255.0</td><td>192.168.X.X是私有地址；</td></tr><tr><td>D类</td><td>1110 xxxx.xxxx xxxx.xxxx xxxx.xxxx xxxx(多播地址)</td><td>224.0.0.0—239.255.255.255</td><td>不分网络地址和主机地址</td></tr><tr><td>E类</td><td>1111 xxxx.xxxx xxxx.xxxx xxxx.xxxx xxxx(保留今后使用)</td><td>240.0.0.0—255.255.255.254</td><td>不分网络地址和主机地址</td></tr></tbody></table><p>主机号全为0表示网络本身。比如，在192.168.0.0/24的子网中，192.168.0.0表示这个子网本身。<br>主机号全为1表示本网络的广播地址。比如，在192.168.0.0/24的子网中，192.168.0.255表示这个子网的广播地址。</p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Nginx</title>
    <link href="/blog/2021/01/01/%E7%BD%91%E7%BB%9C_Nginx/"/>
    <url>/blog/2021/01/01/%E7%BD%91%E7%BB%9C_Nginx/</url>
    
    <content type="html"><![CDATA[<p>官方中文文档：<a href="https://www.nginx.cn/doc">https://www.nginx.cn/doc</a></p><p>功能：免费开源的 <strong>高性能的HTTP服务器</strong>、<strong>反向代理</strong>、<strong>IMAP/POP3代理服务器</strong>。</p><p>特点：稳定，轻量级，配置简单，资源消耗低，功能丰富！</p><p>相同功能还有Apache的Httpd，架构比较笨重，性能不如nginx，主要不会玩。</p><h1 id="配置服务器名称（域名）"><a href="#配置服务器名称（域名）" class="headerlink" title="配置服务器名称（域名）"></a>配置服务器名称（域名）</h1><blockquote><p>nginx通过请求的请求头中的Host获取要访问的server,</p></blockquote><p>可用<code>精确名称</code>、<code>通配符</code>、<code>正则表达式</code></p><p>按照顺序选择第一个匹配：</p><blockquote><p>精确名称，以’<em>‘开头的最长的通配符，以’</em>‘结尾的最长的通配符，第一个匹配的正则表达式</p></blockquote><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span>       <span class="hljs-number">80</span>;    <span class="hljs-comment"># 精确名称</span>    <span class="hljs-attribute">server_name</span>  example.org  www.example.org;    <span class="hljs-comment"># 或 *开头的通配符（以&#x27;example.org&#x27;结尾的都算）</span>    <span class="hljs-attribute">server_name</span>  <span class="hljs-regexp">*.example.org</span>;<span class="hljs-comment">#如果有&#x27;*&#x27;，则&#x27;*&#x27;必须在&#x27;.&#x27;的旁边</span>    <span class="hljs-comment"># 或 *结尾的通配符（以&#x27;mail.&#x27;开头的都算）</span>    <span class="hljs-attribute">server_name</span>  <span class="hljs-regexp">mail.*</span>;    <span class="hljs-comment"># 或 正则</span>    <span class="hljs-attribute">server_name</span>  ~^(?&lt;user&gt;.+)\.example\.net$;<span class="hljs-comment"># 使用正则表达式时，服务器名称必须使用波浪线&#x27;~’开头</span>        ...&#125;</code></pre><blockquote><p>精确名称、以星号开头的通配符、以星号结尾的通配符是分别被存储在绑定到监听端口上的三张哈希表中。</p><p>存放精确名称的哈希表最先被搜索；其次以星号开头的通配符哈希表；最后搜索以星号结尾的哈希表。</p></blockquote><p>一种特殊形式的通配符<code>.example.org</code>可以用来匹配精确名称<code>example.org</code>和通配符<code>*.example.org</code>  ,这种特殊的通配符形式<code>.example.org</code>是存储在通配符名称的哈希表中。</p><p>所以能写</p><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span> <span class="hljs-number">80</span>;    <span class="hljs-attribute">server_name</span> example.org  www.example.org  <span class="hljs-regexp">*.example.org</span>;<span class="hljs-comment">#更高效</span>    <span class="hljs-attribute">server_name</span> .example.org;    ...&#125;</code></pre><h5 id="指定正则表达式捕获片段之后可以当做一个变量来使用："><a href="#指定正则表达式捕获片段之后可以当做一个变量来使用：" class="headerlink" title="指定正则表达式捕获片段之后可以当做一个变量来使用："></a>指定<strong>正则</strong>表达式<strong>捕获片段</strong>之后可以<strong>当做一个变量</strong>来使用：</h5><blockquote><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">server_name</span>   ~^(www\.)?(?&lt;domain&gt;.+)$;    <span class="hljs-attribute">location</span> / &#123;        <span class="hljs-attribute">root</span>   /sites/$domain;    &#125;&#125;</code></pre><p>PCRE库支持以下语法使用捕获片段：</p><blockquote><p><code>?&lt;name&gt;</code>： Perl 5.10兼容语法，从PCRE-7.0开始支持<br><code>?&#39;name&#39;</code>： Perl 5.10兼容语法，从PCRE-7.0开始支持<br><code>?P&lt;name&gt;</code>： Python兼容语法，从PCRE-4.0开始支持</p></blockquote><p>如果 NGINX 启动失败，并且显示错误信息：<br><code>pcre_compile() failed: unrecognized character after (?&lt; in ...</code><br>说明PCRE库太老了，这种语法“?P<name>”应该被替换。</p><p>捕获片段也可以使用数字形式引用：</p><blockquote><p>这种使用方式尽量限制在简单案例中使用，因为数字引用形式很容易被覆盖。</p><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">server_name</span>   ~^(www\.)?(.+)$;    <span class="hljs-attribute">location</span> / &#123;        <span class="hljs-attribute">root</span>   /sites/<span class="hljs-variable">$2</span>;    &#125;&#125;</code></pre></blockquote></blockquote><h5 id="如果请求头中没有Host，则会用默认服务器来处理请求，"><a href="#如果请求头中没有Host，则会用默认服务器来处理请求，" class="headerlink" title="如果请求头中没有Host，则会用默认服务器来处理请求，"></a>如果请求头中没有Host，则会用<strong>默认服务器</strong>来处理请求，</h5><blockquote><pre><code class="hljs nginx"><span class="hljs-section">http</span> &#123;    <span class="hljs-comment"># 如果没有显式声明 default server 则第一个 server 会被隐式的设为 default server,建议显示声明一下default server</span>    <span class="hljs-section">server</span> &#123;        <span class="hljs-attribute">listen</span> <span class="hljs-number">80</span>;        <span class="hljs-attribute">server_name</span> www.aaa.com;        ...    &#125;    <span class="hljs-section">server</span> &#123;        <span class="hljs-attribute">listen</span> <span class="hljs-number">80</span>;        <span class="hljs-attribute">server_name</span> www.bbb.com;        ...    &#125;    <span class="hljs-comment"># 显示的定义一个 default server</span>    <span class="hljs-section">server</span> &#123;        <span class="hljs-attribute">listen</span> <span class="hljs-number">80</span> default_server;        <span class="hljs-attribute">server_name</span> _;        <span class="hljs-attribute">return</span> <span class="hljs-number">403</span>; <span class="hljs-comment"># 403 forbidden</span>    &#125;    <span class="hljs-comment">#---让default server返回403，可以禁止ip访问，也可以禁止未知域名访问</span>&#125;</code></pre></blockquote><p>如果请求直接输入ip，nginx会把请求随机分配到某个域名上，</p><h5 id="如果想让直接用ip的请求打到指定的某个域名上"><a href="#如果想让直接用ip的请求打到指定的某个域名上" class="headerlink" title="如果想让直接用ip的请求打到指定的某个域名上"></a>如果想让直接用ip的请求打到指定的某个域名上</h5><p>则需要配置该server为</p><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span> x.x.x.x:<span class="hljs-number">80</span>;    <span class="hljs-comment">#或者</span>    <span class="hljs-attribute">listen</span> x.x.x.x;<span class="hljs-comment">#（默认80嘛）</span>    <span class="hljs-attribute">server_name</span> _;    ...&#125;</code></pre><h1 id="配置HTTPS"><a href="#配置HTTPS" class="headerlink" title="配置HTTPS"></a>配置HTTPS</h1><p>在server块中监听指令后 <code>启用ssl</code> 并指定证书和私钥的位置</p><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span> <span class="hljs-number">443</span> ssl;<span class="hljs-comment">#启用ssl</span>    <span class="hljs-comment">#-----或-------</span>    <span class="hljs-attribute">listen</span> <span class="hljs-number">443</span>;    <span class="hljs-attribute">ssl</span> <span class="hljs-literal">on</span>;    <span class="hljs-comment">#--------------</span>    <span class="hljs-attribute">server_name</span> www.melopoz.top;    <span class="hljs-attribute">ssl_certificate</span> /usr/local/crt/melopoz.top.pem;<span class="hljs-comment">#证书位置</span>    <span class="hljs-attribute">ssl_certificate_key</span> /usr/local/crt/melopoz.top.key;<span class="hljs-comment">#私钥位置</span><span class="hljs-attribute">ssl_protocols</span> TLSv1 TLSv1.<span class="hljs-number">1</span> TLSv1.<span class="hljs-number">2</span>;<span class="hljs-comment">#默认的不用写 不过每个版本不太一样</span>    <span class="hljs-attribute">ssl_ciphers</span> HIGH:!aNULL:!MD5;<span class="hljs-comment">#默认的不用写 不过每个版本不太一样</span>    ...&#125;<span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span> <span class="hljs-number">80</span>;    <span class="hljs-attribute">server_name</span> melopoz.top;    <span class="hljs-comment">#将请求转成https</span>    <span class="hljs-attribute">rewrite</span><span class="hljs-regexp"> ^(.*)$</span> https://$host<span class="hljs-variable">$1</span> <span class="hljs-literal">permanent</span>;&#125;</code></pre><p>私钥应该限制访问权限，如果证书和私钥都在一个文件里的话，也只有证书会发送到客户端。</p><h4 id="虚拟主机，多个域名都监听443端口，但证书不同"><a href="#虚拟主机，多个域名都监听443端口，但证书不同" class="headerlink" title="虚拟主机，多个域名都监听443端口，但证书不同"></a>虚拟主机，多个域名都监听443端口，但证书不同</h4><p>配置如下：</p><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span>          <span class="hljs-number">443</span> ssl;    <span class="hljs-attribute">server_name</span>     www.aaa.com;    <span class="hljs-attribute">ssl_certificate</span> www.aaa.com.crt;    ...&#125;<span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span>          <span class="hljs-number">443</span> ssl;    <span class="hljs-attribute">server_name</span>     www.bbb.org;    <span class="hljs-attribute">ssl_certificate</span> www.bbb.org.crt;    ...&#125;</code></pre><p>因为https是先建立SSL连接，再建立HTTP连接，在进行SSL连接的时候还不知道请求的服务器的名称（域名）是什么(不懈怠)，所以nginx只能把默认的服务器证书(aaa的crt)给到客户端，如果请求的是bbb，按说应该是行不通的。。。。。</p><p>后来，2006年，TLS协议加入了一个<a href="http://tools.ietf.org/html/rfc4366">Server Name Indication扩展</a>，请求可以携带客户端要访问的域名。</p><p><strong>所以如上配置现在是没问题的，ssl握手也可以正确拿到要请求的域名对应的证书</strong></p><h4 id="多个域名的SSL证书"><a href="#多个域名的SSL证书" class="headerlink" title="多个域名的SSL证书"></a>多个域名的SSL证书</h4><p>还有其他方法允许在几个HTTPS虚拟主机服务器之间共享单个IP地址。然而，他们都有自己的缺点。其中一种方法是在证书的 SubjectAltName 字段中使用多个名称，例如 <code>www.example.com</code> 和 <code>www.example.org</code> 。 但是， SubjectAltName 字段长度有限。</p><p>另一种方法是使用带有通配符名称的证书，例如 <code>*.example.org</code> 。 通配符证书能保护指定域的所有子域，但只限一个级别。此证书与 <code>www.example.org</code> 匹配，但不匹配 <code>example.org</code> 和 <code>www.sub.example.org</code> 。这两种方法也可以结合。证书可以在 SubjectAltName 字段中包含完全匹配和通配符名称，例如 <code>example.org</code> 和 <code>*.example.org</code> 。</p><p>最好在配置文件的 <code>http</code>区块中放置具有多个名称的证书文件及其私钥文件，以在所有其下的虚拟主机服务器中继承其单个内存副本：</p><pre><code class="hljs nginx"><span class="hljs-attribute">ssl_certificate</span>     common.crt;<span class="hljs-attribute">ssl_certificate_key</span> common.key;<span class="hljs-comment">#通用</span><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span>          <span class="hljs-number">443</span> ssl;    <span class="hljs-attribute">server_name</span>     www.example.com;    ...&#125;<span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span>          <span class="hljs-number">443</span> ssl;    <span class="hljs-attribute">server_name</span>     www.example.org;    ...&#125;</code></pre><p>从<code>github 的 nginx-tutorial</code>nginx-教程 看到</p><h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><p>可选策略：</p><ul><li>轮询（默认）</li><li>最少连接（下次请求分配给 连接数最少的机器（分给最不忙的机器））</li><li>IP哈希（基于客户端的IP地址进行hash，一个客户端的请求每次都是被同一个机器处理（机器没有下线））</li></ul><pre><code class="hljs nginx"><span class="hljs-section">http</span> &#123;    <span class="hljs-attribute">upstream</span> myapp1 &#123;        <span class="hljs-comment"># ---这里配置使用的负载均衡策略</span>        <span class="hljs-comment"># 默认轮询</span>        <span class="hljs-comment"># least_conn</span>        <span class="hljs-comment"># ip_hash</span>                        <span class="hljs-attribute">server</span> srv1.example.com weight=<span class="hljs-number">3</span>;<span class="hljs-comment">#可以根据机器的性能分配一个合适的权重</span>        <span class="hljs-attribute">server</span> srv2.example.com;        <span class="hljs-attribute">server</span> srv3.example.com;    &#125;    <span class="hljs-section">server</span> &#123;        <span class="hljs-attribute">listen</span> <span class="hljs-number">80</span>;        <span class="hljs-attribute">location</span> / &#123;            <span class="hljs-attribute">proxy_pass</span> http://myapp1;<span class="hljs-comment"># 如果是https 则直接用https即可</span>        &#125;    &#125;&#125;</code></pre><h1 id="压缩-解压"><a href="#压缩-解压" class="headerlink" title="压缩/解压"></a>压缩/解压</h1><p>由于压缩在运行时发生，所以会增加处理开销，这可能会对性能产生负面影响。 </p><p>在向客户端发送响应之前，NGINX 会执行压缩，但不会“重复压缩”已经压缩过的响应。</p><h4 id="启用压缩"><a href="#启用压缩" class="headerlink" title="启用压缩"></a>启用压缩</h4><p>要启用压缩，在 gzip 指令上请使用<code>on</code>参数:</p><pre><code class="hljs nginx"><span class="hljs-attribute">gzip</span> <span class="hljs-literal">on</span>;</code></pre><p>默认情况下，NGINX 仅压缩使用MIME 类型 为 <code>text/html</code>的响应。要压缩其他 MIME 类型的响应，请包含<code>gzip_types</code>指令并列出相应的类型。</p><pre><code class="hljs applescript">gzip_types <span class="hljs-built_in">text</span>/plain <span class="hljs-built_in">application</span>/xml;</code></pre><p>要指定要压缩的响应的最小长度，请使用<code>gzip_min_length</code>指令。默认值为20字节，下面示例调整为1000：</p><pre><code class="hljs abnf">gzip_min_length <span class="hljs-number">1000</span><span class="hljs-comment">;</span></code></pre><p>默认情况下，NGINX 不会压缩对代理请求的响应（来自代理服务器的请求）。请求是否来自代理服务器是由请求中 <code>Via</code> 头字段的是否存来确定的。</p><p>使用<code>gzip_proxied</code> 配置这些响应的压缩，该指令具有多个参数来指定 NGINX 应压缩哪种代理请求。</p><p>例如，仅对不会在代理服务器上缓存的请求进行压缩响应，为此，<code>gzip_proxied</code>指令具有指示 NGINX 在响应中检查 <code>Cache-Control</code> 头字段的参数，如果值是 no-cache、no-store 或 private，则压缩响应。</p><p>另外，您必须包括 expired 的参数来检查 <code>Expires</code> 头字段的值。这些参数在以下示例中与 auth 参数一起设置，该参数检查<code>Authorization</code>头字段的存在（授权响应特定于最终用户，并且通常不被缓存）：</p><pre><code class="hljs nginx"><span class="hljs-attribute">gzip_proxied</span> <span class="hljs-literal">no</span>-cache <span class="hljs-literal">no</span>-store private expired auth;</code></pre><p>与大多数其他指令一样，配置压缩的指令可以包含在<code>http</code>上下文中，也可以包含在 <code>server</code> 或 <code>location</code> 块中。</p><p>gzip 压缩的整体配置可能如下所示。</p><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">gzip</span> <span class="hljs-literal">on</span>;    <span class="hljs-attribute">gzip_types</span>      text/plain application/xml;    <span class="hljs-attribute">gzip_proxied</span>    <span class="hljs-literal">no</span>-cache <span class="hljs-literal">no</span>-store private expired auth;    <span class="hljs-attribute">gzip_min_length</span> <span class="hljs-number">1000</span>;    ...&#125;</code></pre><h4 id="启用解压"><a href="#启用解压" class="headerlink" title="启用解压"></a>启用解压</h4><pre><code class="hljs crmsh"><span class="hljs-keyword">location</span> <span class="hljs-title">/storage</span>/ &#123;    gunzip on;    ...&#125;</code></pre><p><code>gunzip</code>指令也可以在与<code>gzip</code>指令相同的上下文中指定：</p><pre><code class="hljs abnf">server &#123;    gzip on<span class="hljs-comment">;</span>    gzip_min_length <span class="hljs-number">1000</span><span class="hljs-comment">;</span>    gunzip on<span class="hljs-comment">;</span>    ...&#125;</code></pre><p>请注意，此指令在单独的模块中定义（见<code>ngx_http_gunzip_module</code><a href="http://nginx.org/en/docs/http/ngx_http_gunzip_module.html">http://nginx.org/en/docs/http/ngx_http_gunzip_module.html</a>），默认情况下可能不包含在开源 NGINX 构建中。</p><h4 id="发送压缩文件"><a href="#发送压缩文件" class="headerlink" title="发送压缩文件"></a>发送压缩文件</h4><p>要将文件的压缩版本发送到客户端而不是常规文件，请在适当的上下文中将<code>gzip_static</code>指令设置为 on。</p><pre><code class="hljs crmsh"><span class="hljs-keyword">location</span> <span class="hljs-title">/ &#123;</span><span class="hljs-title">    gzip_static</span> on;&#125;</code></pre><p>在这种情况下，为了服务<code>/path/to/file</code>的请求，NGINX 尝试查找并发送文件<code>/path/to/file.gz</code>。如果文件不存在，或客户端不支持 gzip，则 NGINX 将发送未压缩版本的文件。</p><p>请注意，<code>gzip_static</code>指令不启用即时压缩。它只是使用压缩工具预先压缩的文件。要在运行时压缩内容（而不仅仅是静态内容），请使用<code>gzip</code>指令。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>Ubuntu：</p><p>sudo apt-get update</p><p>sudo apt-get install nginx</p><blockquote><p>若安装过程报错：</p><p>W: GPG error: <a href="http://nginx.org/packages/ubuntu">http://nginx.org/packages/ubuntu</a> xenial Release: The following signatures couldn’t be verified because the public key is not available: NO_PUBKEY $key</p><p>则先执行<code>sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys $key</code></p><p>再执行安装</p></blockquote><p>启动</p><p>sudo service nginx start</p><p>访问localhost即可(默认80端口)</p><h1 id="改了配置-重新加载"><a href="#改了配置-重新加载" class="headerlink" title="改了配置 重新加载"></a>改了配置 重新加载</h1><p><code>nginx -s reload</code></p><h1 id="绑核"><a href="#绑核" class="headerlink" title="绑核"></a>绑核</h1><p>处理相同线程都用同一个CPU可以保证L1L2缓存的使用，减缓因切换使用的CPU带来的开销，所以如果指定进程使用的CPU可以提高性能。</p><p>因为是要用cpu的L1、L2缓存，所以这里绑定的是物理核心！</p><p>如果是四核四线程的CPU，则直接配置即可，如果是四核八线程(泛指这种虚拟核心的情况)，要先查看指定的CPU core id</p><h4 id="可以通过-cat-proc-cpuinfo-grep-quot-core-id-quot-命令查看CPU核心"><a href="#可以通过-cat-proc-cpuinfo-grep-quot-core-id-quot-命令查看CPU核心" class="headerlink" title="可以通过 cat /proc/cpuinfo |grep &quot;core id&quot; 命令查看CPU核心"></a>可以通过 <code>cat /proc/cpuinfo |grep &quot;core id&quot;</code> 命令查看CPU核心</h4><p>四核四线程：</p><blockquote><p>core id         : 0<br>core id         : 1<br>core id         : 2<br>core id         : 3</p></blockquote><p>四核八线程：</p><blockquote><p>可能是</p><p>core id         : 0<br>core id         : 1<br>core id         : 2<br>core id         : 3<br>core id         : 0<br>core id         : 1<br>core id         : 2<br>core id         : 3</p><p>可能是</p><p>core id         : 0<br>core id         : 0<br>core id         : 1<br>core id         : 1<br>core id         : 2<br>core id         : 2<br>core id         : 3<br>core id         : 3</p></blockquote><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>如果是第一种四核八线程需要配置 affinity 为：</p><pre><code class="hljs nginx"><span class="hljs-attribute">worker_processes</span> auto;<span class="hljs-comment"># cpu 核心数</span><span class="hljs-attribute">worker_cpu_affinity</span> <span class="hljs-number">0001</span> <span class="hljs-number">0010</span> <span class="hljs-number">0100</span> <span class="hljs-number">1000</span>;<span class="hljs-comment">#15 26 37 48分为四组，保证一个物理核心的两个逻辑核心处理的进程都用这个物理cpu</span><span class="hljs-attribute">worker_cpu_affinity</span> auto;<span class="hljs-comment"># cpu亲和性 就是绑核 1.9.几来着 可以设置 auto 了</span></code></pre>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP服务器</tag>
      
      <tag>反向代理</tag>
      
      <tag>负载均衡</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP &amp; HTTP &amp; HTTPS</title>
    <link href="/blog/2021/01/01/%E7%BD%91%E7%BB%9C_TCP%20&amp;%20HTTP%20&amp;%20HTTPS/"/>
    <url>/blog/2021/01/01/%E7%BD%91%E7%BB%9C_TCP%20&amp;%20HTTP%20&amp;%20HTTPS/</url>
    
    <content type="html"><![CDATA[<h1 id="OSI"><a href="#OSI" class="headerlink" title="OSI"></a>OSI</h1><p>七层模型，各种协议。。</p><p><a href="https://m.yisu.com/zixun/46320.html">https://m.yisu.com/zixun/46320.html</a></p><h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><img alt="TCP建立连接" src="https://raw.githubusercontent.com/melopoz/pics/master/img/TCP34.png" style="zoom:50%;" /><h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><blockquote><p>seq number (x和y) 真正数值均为随机数, 抓包看到的一般为相对的数字, 即 0 和 1</p></blockquote><ol><li><p>client 发送 SYN(seq=<strong>x</strong>) 到 server;   </p><blockquote><p>client进入<strong>SYN_SEND</strong>状态</p></blockquote><blockquote><p><strong>如果失败</strong>（server没有收到syn）：server就没收到请求，client也没收到ack，都不申请资源。</p></blockquote></li><li><p>server 收到并回应 SYN(seq=<strong>y</strong>), ACK(seq=<strong>x+1</strong>); </p><blockquote><p>server进入<strong>SYN_RECV</strong>状态</p></blockquote><blockquote><p><strong>如果失败</strong>（client没收到syn+ack）：server已经申请资源，等待client的ack；client不会申请资源；</p></blockquote></li><li><p>client 收到 server 的SYN报文, 回应一个 ACK(seq=<strong>y+1</strong>)</p><blockquote><p>client发送完进入<strong>ESTABLISHED</strong>状态, server收到也进入<strong>ESTABLISHED</strong>状态</p></blockquote><blockquote><p><strong>如果失败</strong>（server没收到ack）：client变成ESTABLISHED状态，准备发送数据；server还是<strong>SYN_RECV</strong>状态，根据 <strong>TCP的超时重传机制</strong>，会等待3秒、6秒、12秒后<strong>重新发送SYN+ACK包</strong>，如果最终还是超时，就关闭这个连接，释放资源；</p><blockquote><p>如果server没收到client的第三次握手就收到了client的数据包，会回复一个<strong>RST</strong>，client收到<strong>RST</strong>会重新开始握手</p></blockquote><blockquote><p>server重发syn+ack的次数可以通过<code>/proc/sys/net/ipv4/tcp_synack_retries</code>修改，默认为 5</p></blockquote></blockquote></li></ol><h3 id="为什么三次握手"><a href="#为什么三次握手" class="headerlink" title="为什么三次握手"></a>为什么三次握手</h3><blockquote><p>全双工可靠连接，必须保证双方都<strong>能接收 能发送</strong>，建立链接时必须证明<strong>自己能发送</strong>且**发送的信息被接受(收到ack)**了。</p></blockquote><p>两次可以保证双方都向对方发送了syn，但不能保证都收到对方的回应(ack)（<strong>server并不能确定自己发送的syn被client收到了，必须再收到客户端的ack才行</strong>）。</p><h5 id="呃…另外一个多余的原因："><a href="#呃…另外一个多余的原因：" class="headerlink" title="呃…另外一个多余的原因："></a>呃…另外一个多余的原因：</h5><p>并且三次握手可以<strong>防止已失效的连接请求报文段突然又传送到了服务端</strong>，具体场景如下：</p><blockquote><p>（如果仅需两次握手即可建立连接）：</p><ol><li><p>client发送syn（syn1），等待server的ack，server没收到；</p></li><li><p>client等不到server的ack，又发送syn（syn2），server收到并返回了ack，双方准备连接的资源；</p></li><li><p><strong>过了一会，server收到了syn1回复一个ack并准备资源</strong>；</p><blockquote><p>client莫名其妙收到一个ack。。不理睬，但是server已经开资源了，就会导致server资源浪费。</p><p>虽然server可以通过超时机制释放该资源，但是很多服务器还是不能容忍这种情况的。</p></blockquote></li></ol></blockquote><h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><blockquote><p>x、y ： 上次通信的x和y</p></blockquote><ol><li><p>client 发送 FIN(seq=x) 到 server；</p><blockquote><p>client进入<strong>FIN_WAIT_1</strong>状态；client只是不再发送数据，但还可以接受数据。</p></blockquote></li><li><p>server 回应 ACK(seq=x+1)；</p><blockquote><p>server进入<strong>CLOSE_WAIT</strong>，client收到后进入<strong>FIN_WAIT_2</strong>状态；server可能还需要发送数据，所以不能一并发送FIN。</p></blockquote></li><li><p>server 没有要发送的数据之后，向 client 发送 FIN(seq=y)；</p><blockquote><p>server进入<strong>LAST_ACK</strong>状态</p></blockquote></li><li><p>client 回应 ACK(seq=y+1)</p><blockquote><p>client发送完成进图<strong>established</strong>状态，server收到后进入<strong>CLOSED</strong>状态；</p><p>client在等待2MSL(两个最大生命周期)后，如果没有收到server重发的<strong>FIN</strong>包，则进入<strong>CLOSED</strong>状态。</p><blockquote><p>MSL：报文段最大生存时间（任何报文段被丢弃前网络内的最长时间）。</p></blockquote><blockquote><p><strong>如果失败</strong>（server没有收到client发送的ACK(y+1)）：</p><p>server就会超时重传FIN(seq=y)，如果 client 再次收到 FIN 就会再发送 ACK(y+1)，server 收到 ACK，断开连接。</p><p>也因此等待时间至少是 server 的 timeout＋FIN 的传输时间，保守起见，使用2MSL。</p></blockquote></blockquote></li></ol><h3 id="为什么四次挥手"><a href="#为什么四次挥手" class="headerlink" title="为什么四次挥手"></a>为什么四次挥手</h3><p>大致与握手相同，不过三次握手是因为server把ack和syn放到一起发送了，这样成了三次。</p><p>但是断开连接的时候server不能把要发送的ACK和FIN放到一起，因为主动发送FIN的意思是“我不在发送数据了”，而server其实可能还又要发送的数据。</p><h1 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h1><p>超文本传输协议，基于TCP</p><p>在 HTTP/1.0 中，一个服务器在完成HTTP响应之后会断开TCP链接，这样每次请求都会先建立 TCP 连接，最后再断开， 性能太差。</p><p>在 HTTP/1.1 中设置请求头 <code>Connection: keep-alive</code>， 默认开启长链接， 若要关闭则需要设置请求头： <code>Connection: close</code></p><blockquote><p>所以有时候刷新网页也不需要再建立SSL/TLS连接，非对称加密只用来对 秘钥进行加密，ssl连接建立之后就使用对称加密了。</p></blockquote><p>一个 TCP 连接在同一时刻只能处理一个请求， 即 两个请求的声明周期不能重叠。</p><p>浏览器对同一个 host 建立TCP连接有数量限制： Chrome 最多允许6个。</p><p>比如要请求上千张图片， 只用一个TCP连接肯定是太慢，</p><h3 id="HTTP-1-1-Pipelining-队头阻塞"><a href="#HTTP-1-1-Pipelining-队头阻塞" class="headerlink" title="HTTP/1.1 Pipelining   -队头阻塞"></a>HTTP/1.1 Pipelining   -队头阻塞</h3><p>HTTP/1.1 是有 Pipelining 技术的， 但是浏览器默认关闭这个功能。</p><blockquote><p>把多个HTTP请求放到同一个TCP连接中逐个发送， 不过不等待服务器的响应， 但是要按照发送请求的顺序来接收响应。</p><p>这样如果前一个请求的响应非常慢，后续的所有请求都要受到影响，即 <strong>队头阻塞</strong>。</p></blockquote><h3 id="HTTP-2"><a href="#HTTP-2" class="headerlink" title="HTTP/2"></a>HTTP/2</h3><ol><li>在应用层（HTTP）和传输层（TCP）之间添加了 <strong>二进制分帧层</strong>；</li><li>提供了 Multiplexing 多路传输特性， HTTP/2 的 TCP 连接建立之后， 请求以 stream 的方式发送，每个 stream 的基本组成单位是 frame（二进制帧）。 在传送这些消息时 乱序发送，再在接收端重新组合；</li><li>Header 压缩， 压缩了 HTTP/1.1 每次都要重复发送且带有大量信息的header； <code>HPACK</code></li><li>服务端推送， server 会主动将一些资源推送给 client 并缓存起来。</li></ol><p>HTTP/2 还是有 队头阻塞 问题，HTTP/2.0 只是解决了 HTTP 的队头阻塞问题， 并没有解决 TCP 的队头阻塞问题。</p><ol><li><p>如何解决了 HTTP 的队头阻塞？</p><blockquote><p>http 阻塞的原因是要按顺序接收response， 所以http2.0 直接乱序接收，最后再按顺序拼起来。</p></blockquote></li><li><p>但是 http 是基于 TCP 的， TCP 还是有队头阻塞问题</p></li><li><p>TCP 不能升级？  <strong>协议僵化</strong>， 太底层的协议了， 若要升级，需要更新很多基础硬件设施。。。</p></li></ol><h3 id="HTTP-3"><a href="#HTTP-3" class="headerlink" title="HTTP/3"></a>HTTP/3</h3><p>TCP 队头阻塞的问题解决不了， 那就不用 TCP 了。。</p><p>所以 <strong>HTTP/3 是基于 UDP 的</strong>。不过核心是围绕底层的 QUIC 协议实现的。</p><p>QUIC 是在用户层构建的， 不需要每次协议升级的时候进行内核修改。   <code>???????</code></p><p>新的HTTP头压缩机制： QPACK， 是 HPACK 的增强版。</p><p>嗯  所以呢？？？   不求甚解啦</p><h1 id="确保安全通信的三个原则"><a href="#确保安全通信的三个原则" class="headerlink" title="确保安全通信的三个原则"></a>确保安全通信的三个原则</h1><ol><li><p>数据内容加密</p></li><li><p>通信双方身份校验</p><blockquote><p>确保你是在给 （给你发消息的人）发消息</p></blockquote></li><li><p>数据内容完整</p><blockquote><p>确保对方能够完整地读完我的消息</p></blockquote></li></ol><p>http是明文, 不安全 所以需要加密来保证数据安全</p><h3 id="对称加密-和-非对称加密"><a href="#对称加密-和-非对称加密" class="headerlink" title="对称加密 和 非对称加密"></a>对称加密 和 非对称加密</h3><p>对称加密:</p><blockquote><p>使用同一个密钥进行加密和解密, 速度快, 但是必须在通信时告诉对方使用什么密钥, 一旦密钥被截获, 相当于仍然是明文.</p></blockquote><p>非对称加密:</p><blockquote><p>公钥随便发，通信双方各自保管私钥。使用私钥加密则必须用公钥解密，使用公钥加密则必须使用私钥解密。</p></blockquote><h1 id="HTTPS设计思路"><a href="#HTTPS设计思路" class="headerlink" title="HTTPS设计思路"></a>HTTPS设计思路</h1><ol><li>server为客户端生成一个公钥并发送给client；</li><li>client选择一个加密算法，用公钥把这个算法加密后发送给server；</li><li>server收到后用私钥解密得到加密算法，以后都用这个算法进行数据包的decode。</li></ol><h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><p>中间人可以对client伪装成server， 对server伪装成client， 仍然可以截获真数据包。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>既然在通信中发送公钥危险，那就别直接发送公钥了呗。把这个公钥交给可信任的第三方机构。</p><ol><li><p>由CA向 server 颁发证书，来证明服务器是安全的；</p></li><li><p>server 将证书（包含 server 的公钥）发送给 client；</p></li><li><p>client 收到加密后的公钥之后，用CA的公钥把server发来的公钥解密得到 通信中使用的公钥。</p><blockquote><p>操作系统或者浏览器本身就带有 CA 的公钥，server 发送给 client 的证书是由 CA 用私钥加密过的。</p></blockquote></li></ol><p>这样一来，中间人也就只能作为client请求server，但不能伪装成server回应client。</p><h3 id="SSL-TLS"><a href="#SSL-TLS" class="headerlink" title="SSL/TLS"></a>SSL/TLS</h3><p>也就是上述结局方案了。具体步骤为：</p><ol><li><p>client 发送请求到 server， 生成并携带随机数 random1 和 支持的加密算法； <code>Client Hello</code></p></li><li><p>server 取出random1和client支持的加密算法，从中取出一个算法，生成 random2；<code>Server Hello</code></p><p>server 将自己的数字证书（含有server的公钥）发送给 client，让 client 对自己进行身份校验； <code>Certificate</code></p><p>..”server 的工作完成了“   <code>Server Hello Done</code></p></li><li><p>client 校验证书是否合法，生成 random3，用服务器的公钥加密 random3 得到 premaster，并发送给 server；<code>Client Key Exchange</code> <code>Change Cipher Spec</code> <code>Encrypted Handshake Message </code> </p></li><li><p>server 收到加密的 random3（premaster）之后，用私钥解密，得到 random3 ， 用这三个随机数生成一个秘钥，这个秘钥将作为接下来 对通信数据进行对称加密 的秘钥；</p><p><code>New Session Ticket</code>  <code>Change Cipher Spec</code>  <code>Encryted Handshake Message</code> 接下来要使用对称加密了；</p><blockquote><p>session ticket ： 一个状态保存机制， 下次请求https的时候，携带这个ticket， 节省握手时间、资源消耗</p></blockquote></li><li><p>发送 加密后的 <code>Applation Data</code>   通信数据</p></li></ol><blockquote><p>清楚明了，无敌：<a href="http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html">http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html</a></p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>HTTPS = TLS 五次握手 + HTTP 三次握手</p><blockquote><p>举个例子。。。        TLS 110-120ms       TCP 50-60ms </p></blockquote><ol><li>因为TLS很耗性能耗时间， 所以使用非对称加密 把   对称加密中使用的秘钥a   加密，然后都用这个秘钥a进行对称加密。</li><li>服务器的公钥私钥只用来加密和解密“对话秘钥（sessionkey）”（对 ApplicationData 进行对称加密的秘钥），无其他作用。</li><li>一般还会使用 session ticket 或 session id 技术来提高性能。</li></ol><hr><blockquote><p>CA证书  只是证明 服务器的合法性</p><p>客户端安装了抓包工具的根证书，就会信任（伪装成server的）抓包工具， 这时抓包工具就可以伪装成服务器与客户端进行通信了。</p><p>而抓包工具与真服务器进行通信是不需要证明的， 因为在这个通信中（抓包工具）就是客户端。</p></blockquote><h1 id="自签名，-搭建HTTPS服务"><a href="#自签名，-搭建HTTPS服务" class="headerlink" title="自签名， 搭建HTTPS服务"></a>自签名， 搭建HTTPS服务</h1><h4 id="需要做的事："><a href="#需要做的事：" class="headerlink" title="需要做的事："></a>需要做的事：</h4><blockquote><ul><li>一个提供 https 服务的服务器需要有经过 CA 认证的数字证书和自己的公钥私钥（公钥放在证书里）</li><li>CA 认证是需要收费的，所以我们需要自建一个 CA 机构</li><li>自建的 CA 机构需要有标识自己身份的根证书（包含公钥），以及用来对服务器证书进行签名(加密)的私钥</li><li>一个 https 站点，收到客户端访问时下发自己的数字证书</li><li>客户端需要持有 CA 的根证书，所以我们需要手动导入自建 CA 的证书</li></ul></blockquote><hr><p>自己通过 keytool 生成一个证书，</p><ol><li><p>生成服务端私钥 generate private key（.key)</p><pre><code class="hljs pgsql"># Key considerations <span class="hljs-keyword">for</span> algorithm &quot;RSA&quot; ≥ <span class="hljs-number">2048</span>-<span class="hljs-type">bit</span>openssl genrsa -<span class="hljs-keyword">out</span> <span class="hljs-keyword">server</span>.key <span class="hljs-number">2048</span># Key considerations <span class="hljs-keyword">for</span> algorithm &quot;ECDSA&quot; ≥ secp384r1# List ECDSA the supported curves (openssl ecparam -list_curves)openssl ecparam -genkey -<span class="hljs-type">name</span> secp384r1 -<span class="hljs-keyword">out</span> <span class="hljs-keyword">server</span>.key</code></pre></li><li><p>生成服务端自签名证书</p><p><code>openssl req -new -x509 -sha256 -key server.key -out -server.crt -days 3560</code></p></li><li><p>填写信息：</p><pre><code class="hljs less"><span class="hljs-selector-tag">Country</span> <span class="hljs-selector-tag">Name</span> (<span class="hljs-number">2</span> letter code) <span class="hljs-selector-attr">[AU]</span>:<span class="hljs-selector-tag">CN</span><span class="hljs-selector-tag">State</span> <span class="hljs-selector-tag">or</span> <span class="hljs-selector-tag">Province</span> <span class="hljs-selector-tag">Name</span> (full name) <span class="hljs-selector-attr">[Some-State]</span>:<span class="hljs-selector-tag">Guangdong</span><span class="hljs-selector-tag">Locality</span> <span class="hljs-selector-tag">Name</span> (eg, city) <span class="hljs-selector-attr">[]</span>:<span class="hljs-selector-tag">FoShan</span><span class="hljs-selector-tag">Organization</span> <span class="hljs-selector-tag">Name</span> (eg, company) <span class="hljs-selector-attr">[Internet Widgits Pty Ltd]</span>:<span class="hljs-selector-tag">TestCA</span><span class="hljs-selector-tag">Organizational</span> <span class="hljs-selector-tag">Unit</span> <span class="hljs-selector-tag">Name</span> (eg, section) <span class="hljs-selector-attr">[]</span>:<span class="hljs-selector-tag">Common</span> <span class="hljs-selector-tag">Name</span> (e.g. server FQDN or YOUR name) <span class="hljs-selector-attr">[]</span>:<span class="hljs-selector-tag">xxx</span><span class="hljs-selector-class">.com</span> #域名<span class="hljs-selector-tag">Email</span> <span class="hljs-selector-tag">Address</span> <span class="hljs-selector-attr">[]</span>:</code></pre></li></ol><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.cnblogs.com/Hui4401/p/14128112.html">https://www.cnblogs.com/Hui4401/p/14128112.html</a></p><p><a href="https://blog.csdn.net/u010983881/article/details/83588326">https://blog.csdn.net/u010983881/article/details/83588326</a></p><p><a href="https://juejin.cn/post/6844903522333376525">https://juejin.cn/post/6844903522333376525</a>    RSA非对称加密算法</p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>http</tag>
      
      <tag>https</tag>
      
      <tag>对称/非对称加密</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SpringCloud</title>
    <link href="/blog/2021/01/01/1_redo_%E5%88%86%E5%B8%83%E5%BC%8F_SpringCloud/"/>
    <url>/blog/2021/01/01/1_redo_%E5%88%86%E5%B8%83%E5%BC%8F_SpringCloud/</url>
    
    <content type="html"><![CDATA[<h2 id="微服务架构要处理的四个问题："><a href="#微服务架构要处理的四个问题：" class="headerlink" title="微服务架构要处理的四个问题："></a>微服务架构要处理的四个问题：</h2><ol><li>api</li><li>通信：http、RPC</li><li>服务注册和发现（解决高可用问题）</li><li>熔断机制</li></ol><h2 id="CAP原则："><a href="#CAP原则：" class="headerlink" title="CAP原则："></a>CAP原则：</h2><ul><li>C    consistency    强一致性</li><li>A     availability      可用性</li><li>P      partition tolerance      分区容错性  （分区相当于对通信的时限要求）</li></ul><p>只能满足其中两点。P：当系统不能在时限内完成数据一致性，就需要在C和A之间做出选择。</p><p>zookeeper：CP</p><p>Eureka：AP</p><blockquote><p>所以Eureka的自我保护机制可以很好地应对网络故障导致很多节点失去联系的情况，不会像zookeeper那样整个集群都不可用了。</p></blockquote><h2 id="目前的三个解决方案："><a href="#目前的三个解决方案：" class="headerlink" title="目前的三个解决方案："></a>目前的三个解决方案：</h2><ol><li><p>Apache Dubbo Zookeeper</p><p>api：需要整合第三方 或者自行实现</p><p>通信：dubbo通信框架可以使用RPC或HTTP</p><p>服务注册：zookeeper</p><p>熔断机制：无</p></li><li><p>Spring Cloud NetFlix</p><p>api：网关，zuul组件</p><p>通信：Feign  HttpClient     http通信方式，同步，阻塞</p><p>服务注册：Eureka</p><p>熔断机制：Hystrix</p><p>负载均衡：Ribbon</p></li><li><p>Spring Cloud Alibaba</p><p>2019.9开始使用 一站式解决方案</p></li></ol><p>Dubbo是指RPC框架，Spring Cloud是微服务架构的一站式解决方案。本质不同。</p><h1 id="Spring-Cloud"><a href="#Spring-Cloud" class="headerlink" title="Spring Cloud"></a>Spring Cloud</h1><p>使用restful的http通信</p><h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><ul><li><p>后端api项目(provider)：使用controller提供api。</p></li><li><p>前端consumer项目：使用RestTemplate发送restful请求，调用api项目提供的服务。</p></li><li><p>使用Eureka当做服务注册中心。</p></li></ul><h3 id="Eureka-服务注册中心"><a href="#Eureka-服务注册中心" class="headerlink" title="Eureka 服务注册中心"></a>Eureka 服务注册中心</h3><h5 id="两个组件："><a href="#两个组件：" class="headerlink" title="两个组件："></a>两个组件：</h5><blockquote><p> Eureka Server 和 Eureka Client</p></blockquote><ul><li><p>server提供服务注册服务，就像zookeeper</p></li><li><p> client是一个java客户端，有一个内置复杂均衡器(轮询)。 应用启动之后想server发送心跳，server在多个心跳周期中没有收到服务提供者的心跳，就移除该provider。</p></li></ul><h5 id="三个角色："><a href="#三个角色：" class="headerlink" title="三个角色："></a>三个角色：</h5><blockquote><p>Eureka Server  Eureka Provider  Eureka Consumer: </p></blockquote><h5 id="一个EurekaServer项目"><a href="#一个EurekaServer项目" class="headerlink" title="一个EurekaServer项目"></a>一个EurekaServer项目</h5><p>依赖</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>           <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>           <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-eureka-server<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>           <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.4.4.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>       <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>   <span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span></code></pre><p>启动类</p><pre><code class="hljs java"><span class="hljs-meta">@SpringBootApplication</span><span class="hljs-meta">@EnableEurekaServer</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">EurekaServer</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;        SpringApplication.run(EurekaServer.class, args);    &#125;&#125;</code></pre><p>application.yml</p><pre><code class="hljs yaml"><span class="hljs-attr">server:</span>  <span class="hljs-attr">port:</span> <span class="hljs-number">9101</span><span class="hljs-attr">spring:</span>  <span class="hljs-attr">application:</span>    <span class="hljs-attr">name:</span> <span class="hljs-string">eureka-server</span><span class="hljs-attr">eureka:</span>  <span class="hljs-attr">instance:</span>    <span class="hljs-attr">hostname:</span> <span class="hljs-string">eureka9101.com</span>  <span class="hljs-attr">client:</span>    <span class="hljs-attr">register-with-eureka:</span> <span class="hljs-literal">false</span> <span class="hljs-comment">#不登记 表示自己是注册中心</span>    <span class="hljs-attr">fetch-registry:</span> <span class="hljs-literal">false</span> <span class="hljs-comment">#不抓取注册中心 自己作为注册中心</span>    <span class="hljs-attr">service-url:</span>      <span class="hljs-comment">#单机</span>      <span class="hljs-comment">#defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka #注册服务的地址</span>      <span class="hljs-comment">#集群 将其他的eureka注册中心写进来</span>      <span class="hljs-attr">defaultZone:</span> <span class="hljs-string">http://eureka9102.com:9102/eureka,http://eureka9103.com:9103/eureka</span></code></pre><h5 id="一个EurekaClient-服务提供者项目-后端api"><a href="#一个EurekaClient-服务提供者项目-后端api" class="headerlink" title="一个EurekaClient-服务提供者项目(后端api)"></a>一个EurekaClient-服务提供者项目(后端api)</h5><blockquote><p>​    springboot项目结构</p></blockquote><p>依赖</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!--boot web starter 版本控制在父pom的dependenciesManager--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><span class="hljs-comment">&lt;!--eureka--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-eureka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.4.4.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><span class="hljs-comment">&lt;!--actuator--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.1.14.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><p>启动类</p><pre><code class="hljs java"><span class="hljs-meta">@SpringBootApplication</span><span class="hljs-comment">//...其他注解</span><span class="hljs-meta">@EnableEurekaClient</span> <span class="hljs-comment">//eureka client</span><span class="hljs-meta">@EnableDiscoveryClient</span> <span class="hljs-comment">//完善注册中心的信息</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ApiApplication</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;        SpringApplication.run(ApiApplication.class, args);    &#125;&#125;</code></pre><p>application.yml</p><pre><code class="hljs yaml"><span class="hljs-attr">server:</span>  <span class="hljs-attr">port:</span> <span class="hljs-number">9001</span><span class="hljs-attr">spring:</span>  <span class="hljs-attr">application:</span>    <span class="hljs-attr">name:</span> <span class="hljs-string">playerapi</span><span class="hljs-attr">eureka:</span>  <span class="hljs-attr">client:</span>    <span class="hljs-attr">service-url:</span>      <span class="hljs-attr">defaultZone:</span> <span class="hljs-string">http://eureka9101.com:9100/eureka,http://eureka9102.com:9102/eureka,http://eureka9103.com:9103/eureka</span>  <span class="hljs-attr">instance:</span>    <span class="hljs-attr">instance-id:</span> <span class="hljs-string">api</span><span class="hljs-comment">#可以在eureka中显示的服务实例的actuator/info中看到 需要spring-boot-starter-actuator依赖</span><span class="hljs-attr">info:</span>  <span class="hljs-attr">api.name:</span> <span class="hljs-string">firstspringcloud-api</span>  <span class="hljs-attr">api.msg:</span> <span class="hljs-string">this</span> <span class="hljs-string">is</span> <span class="hljs-string">api</span></code></pre><h3 id="Feign-使用接口方式调用服务，类似Dubbo"><a href="#Feign-使用接口方式调用服务，类似Dubbo" class="headerlink" title="Feign 使用接口方式调用服务，类似Dubbo"></a>Feign 使用接口方式调用服务，类似Dubbo</h3><p>前端app调用后端api服务的方式：</p><ul><li><p>使用RestTemplate</p><blockquote><h5 id="一个前端-服务消费者-项目-boot-web-consumer-使用RestTemplate通信"><a href="#一个前端-服务消费者-项目-boot-web-consumer-使用RestTemplate通信" class="headerlink" title="一个前端(服务消费者)项目(boot web) consumer 使用RestTemplate通信"></a>一个前端(服务消费者)项目(boot web) consumer 使用RestTemplate通信</h5><p>依赖</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.melopoz<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0-SNAPSHOT<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-comment">&lt;!--Ribbon--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-ribbon<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.4.4.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-comment">&lt;!--eureka--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-eureka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.4.4.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span></code></pre><p>启动类</p><pre><code class="hljs java"><span class="hljs-meta">@SpringBootApplication</span><span class="hljs-meta">@EnableEurekaClient</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FrontApplication1</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;        SpringApplication.run(FrontApplication1.class, args);    &#125;&#125;</code></pre><p>config</p><pre><code class="hljs java"><span class="hljs-meta">@Configuration</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Beans</span> </span>&#123;    <span class="hljs-meta">@Bean</span>    <span class="hljs-meta">@LoadBalanced</span><span class="hljs-comment">//负载均衡的restTemplate</span>    <span class="hljs-function">RestTemplate <span class="hljs-title">restTemplate</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> RestTemplate();    &#125;&#125;</code></pre><p>controller</p><pre><code class="hljs java"><span class="hljs-comment">// PLAYERAPI 是Eureka中的服务的Application的名称  </span><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String baseUrl = <span class="hljs-string">&quot;http://PLAYERAPI/player&quot;</span>;   <span class="hljs-meta">@Autowired</span>   <span class="hljs-keyword">private</span> RestTemplate restTemplate;   <span class="hljs-meta">@GetMapping(&quot;/list&quot;)</span>   <span class="hljs-function"><span class="hljs-keyword">public</span> List <span class="hljs-title">list</span><span class="hljs-params">()</span> </span>&#123;       <span class="hljs-keyword">return</span> restTemplate.getForObject(baseUrl + <span class="hljs-string">&quot;/list&quot;</span>, List.class);   &#125;</code></pre><p>application.yml</p><pre><code class="hljs yaml"><span class="hljs-attr">server:</span>  <span class="hljs-attr">port:</span> <span class="hljs-number">10001</span><span class="hljs-attr">eureka:</span>  <span class="hljs-attr">client:</span>    <span class="hljs-attr">register-with-eureka:</span> <span class="hljs-literal">false</span> <span class="hljs-comment">#不向eureka注册自己</span>    <span class="hljs-attr">service-url:</span>      <span class="hljs-attr">defaultZone:</span> <span class="hljs-string">http://eureka9101.com:9101/eureka,http://eureka9102.com:9102/eureka,http://eureka9103.com:9103/eureka</span></code></pre></blockquote></li><li><p>在commons中做公共service包，使用Feign进行服务注册</p><blockquote><p>commons项目 依赖</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!--feign--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-feign<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.4.4.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><p>commons项目 service包</p><pre><code class="hljs java"><span class="hljs-meta">@Component</span><span class="hljs-meta">@FeignClient(value = &quot;PLAYERAPI&quot;, fallbackFactory = FrontPlayerServiceFallbackFactory.class)</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">FrontPlayerService</span> </span>&#123;    <span class="hljs-meta">@GetMapping(&quot;/player/list&quot;)</span>    <span class="hljs-function">List&lt;Player&gt; <span class="hljs-title">list</span><span class="hljs-params">()</span></span>;    <span class="hljs-meta">@GetMapping(&quot;/player/&#123;id&#125;&quot;)</span><span class="hljs-comment">//在Service中必须有value=，不然报错</span>    <span class="hljs-function">Player <span class="hljs-title">getById</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(value = &quot;id&quot;)</span> Long id)</span></span>;    <span class="hljs-meta">@GetMapping(&quot;/player/test&quot;)</span>    <span class="hljs-function">Player <span class="hljs-title">test</span><span class="hljs-params">()</span></span>;&#125;</code></pre><p>feignFront项目 依赖</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.melopoz<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0-SNAPSHOT<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-comment">&lt;!--eureka--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-eureka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.4.4.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-comment">&lt;!--feign 可以没有 commons已经引入--&gt;</span>    <span class="hljs-comment">&lt;!-- &lt;dependency&gt;</span><span class="hljs-comment">        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</span><span class="hljs-comment">        &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;</span><span class="hljs-comment">        &lt;version&gt;1.4.4.RELEASE&lt;/version&gt;</span><span class="hljs-comment">    &lt;/dependency&gt; --&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span></code></pre><p>controller</p><pre><code class="hljs java"><span class="hljs-meta">@RestController</span><span class="hljs-meta">@RequestMapping(&quot;/player&quot;)</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PlayerController</span> </span>&#123;    <span class="hljs-meta">@Autowired</span>    <span class="hljs-keyword">private</span> FrontPlayerService frontPlayerService; <span class="hljs-comment">//直接注入commons项目中的service</span>    <span class="hljs-meta">@GetMapping(&quot;/list&quot;)</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> List <span class="hljs-title">list</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> frontPlayerService.list();    &#125;    <span class="hljs-meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span><span class="hljs-comment">//@PathVariable在Service接口中必须有value=</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> Player <span class="hljs-title">getById</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable</span> Long id)</span> </span>&#123;        <span class="hljs-keyword">return</span> frontPlayerService.getById(id);    &#125;    <span class="hljs-meta">@GetMapping(&quot;/test&quot;)</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> Player <span class="hljs-title">test</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> frontPlayerService.test();    &#125;&#125;</code></pre></blockquote></li></ul><h3 id="Ribbon-负载均衡"><a href="#Ribbon-负载均衡" class="headerlink" title="Ribbon 负载均衡"></a>Ribbon 负载均衡</h3><blockquote><p>在前端项目(consumer)实现负载均衡</p></blockquote><pre><code class="hljs java"><span class="hljs-meta">@Configuration</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Beans</span> </span>&#123;    <span class="hljs-meta">@Bean</span>    <span class="hljs-meta">@LoadBalanced</span><span class="hljs-comment">//负载均衡的restTemplate</span>    <span class="hljs-function">RestTemplate <span class="hljs-title">restTemplate</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> RestTemplate();    &#125;&#125;</code></pre><p>轮询 随机 权重。。也可以自定义实现负载均衡算法</p><h3 id="Hystrix-服务熔断-服务降级"><a href="#Hystrix-服务熔断-服务降级" class="headerlink" title="Hystrix 服务熔断 服务降级"></a>Hystrix 服务熔断 服务降级</h3><blockquote><ul><li>服务熔断：如果后端api中的某个服务在相应的时候超时、抛异常了。就返回另一个备用方法。是为了安全</li><li>服务降级：如果某个时间段要调用太多A服务，几乎不调用B服务。就直接使用B服务备用方法的返回值，不让b服务真正运行，从而减小服务器的负载，让服务器更有性能去运行a服务。是为了效率</li></ul><p>备用方法：返回当前服务不可用的信息。</p></blockquote><p>后端实现服务熔断的三种方法：</p><ol><li>超时熔断</li><li>线程池隔离</li><li>信号量隔离</li></ol><h5 id="demo"><a href="#demo" class="headerlink" title="demo:"></a>demo:</h5><ul><li><p>使用RestTemplate调用，并在后端模拟服务故障，实现<strong>服务熔断</strong></p><blockquote><p>在后端提供api服务的项目的controller层的接口方法中如果有异常，就调用熔断的方法(返回null格式的数据)</p><p>启动类</p><pre><code class="hljs java"><span class="hljs-meta">@EnableCircuitBreaker</span><span class="hljs-comment">//hystix  开启熔断机制</span></code></pre><p>controller</p><pre><code class="hljs java">xxxController &#123;   <span class="hljs-comment">// 模拟服务调用异常，熔断</span>    <span class="hljs-meta">@HystrixCommand(fallbackMethod = &quot;hystrixGetById&quot;)</span> <span class="hljs-comment">// 熔断后调用的方法</span>    <span class="hljs-meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> Player <span class="hljs-title">getById</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable</span> Long id)</span> </span>&#123;        Player player = playerService.getById(id);        <span class="hljs-keyword">if</span> (player == <span class="hljs-keyword">null</span>) &#123;            System.out.println(<span class="hljs-string">&quot;throw exception...&quot;</span>);            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> RuntimeException(<span class="hljs-string">&quot;不存在id为&quot;</span> + id + <span class="hljs-string">&quot;的Player数据&quot;</span>);        &#125;        <span class="hljs-keyword">return</span> player;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> Player <span class="hljs-title">hystrixGetById</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable</span> Long id)</span> </span>&#123;        System.out.println(<span class="hljs-string">&quot;hystrixGetById()...&quot;</span>);        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Player().setId(id);    &#125;    <span class="hljs-comment">// ...</span>    <span class="hljs-comment">//模拟服务调用超时，降级</span><span class="hljs-comment">//超时降级配置</span><span class="hljs-meta">@HystrixCommand(</span><span class="hljs-meta">      commandKey = &quot;list&quot;,</span><span class="hljs-meta">      commandProperties = &#123;</span><span class="hljs-meta">       @HystrixProperty(name = &quot;execution.timeout.enabled&quot;,value = &quot;true&quot;),</span><span class="hljs-meta">       @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;,</span><span class="hljs-meta">                    value = &quot;2000&quot;),</span><span class="hljs-meta">      &#125;,</span><span class="hljs-meta">      fallbackMethod = &quot;listFallbackMethod4Timeout&quot;</span><span class="hljs-meta">    )</span>    <span class="hljs-meta">@GetMapping(&quot;/list&quot;)</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> List&lt;Player&gt; <span class="hljs-title">list</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">try</span> &#123;            <span class="hljs-keyword">int</span> ms = <span class="hljs-keyword">new</span> Random().nextInt(<span class="hljs-number">5</span>);            System.out.println(<span class="hljs-string">&quot;休眠&quot;</span> + ms + <span class="hljs-string">&quot;s&quot;</span>);            Thread.sleep(ms * <span class="hljs-number">1000</span>);        &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;            e.printStackTrace();        &#125;        <span class="hljs-keyword">return</span> playerService.list();    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> List&lt;Player&gt; <span class="hljs-title">listFallbackMethod4Timeout</span><span class="hljs-params">()</span> </span>&#123;        System.out.println(<span class="hljs-string">&quot;listFallbackMethod4Timeout()...list调用超时了&quot;</span>);        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> ArrayList&lt;Player&gt;();    &#125;&#125;</code></pre></blockquote></li><li><p>使用feign接口方式调用服务，并在前端实现<strong>服务降级</strong></p><blockquote><p>使用Feign的接口方式调用的时候，在service中加入FallbackFactory，create()方法返回新的service接口的实例，实现服务降级</p><p>在commons项目中</p><p>service.xxxService</p><pre><code class="hljs java"><span class="hljs-meta">@Component</span><span class="hljs-meta">@FeignClient(value = &quot;PLAYERAPI&quot;, </span><span class="hljs-meta">             // 加入fallback处理</span><span class="hljs-meta">             fallbackFactory = FrontPlayerServiceFallbackFactory.class)</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">FrontPlayerService</span> </span>&#123;    <span class="hljs-meta">@GetMapping(&quot;/player/list&quot;)</span>    <span class="hljs-function">List&lt;Player&gt; <span class="hljs-title">list</span><span class="hljs-params">()</span></span>;    <span class="hljs-meta">@GetMapping(&quot;/player/&#123;id&#125;&quot;)</span><span class="hljs-comment">//在Service中必须有value=，不然报错</span>    <span class="hljs-function">Player <span class="hljs-title">getById</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(value = &quot;id&quot;)</span> Long id)</span></span>;    <span class="hljs-meta">@GetMapping(&quot;/player/test&quot;)</span>    <span class="hljs-function">Player <span class="hljs-title">test</span><span class="hljs-params">()</span></span>;&#125;</code></pre><p>config.fallbackFactory</p><pre><code class="hljs java"><span class="hljs-meta">@Component</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FrontPlayerServiceFallbackFactory</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">FallbackFactory</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> FrontPlayerService <span class="hljs-title">create</span><span class="hljs-params">(Throwable throwable)</span> </span>&#123;        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> FrontPlayerService() &#123;            <span class="hljs-function"><span class="hljs-keyword">public</span> List&lt;Player&gt; <span class="hljs-title">list</span><span class="hljs-params">()</span> </span>&#123;                System.out.println(<span class="hljs-string">&quot;服务降级...list()...&quot;</span>);                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> ArrayList&lt;Player&gt;();            &#125;            <span class="hljs-function"><span class="hljs-keyword">public</span> Player <span class="hljs-title">getById</span><span class="hljs-params">(Long id)</span> </span>&#123;                System.out.println(<span class="hljs-string">&quot;服务降级...getById()...&quot;</span>);                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Player().setId(id);            &#125;            <span class="hljs-function"><span class="hljs-keyword">public</span> Player <span class="hljs-title">test</span><span class="hljs-params">()</span> </span>&#123;                System.out.println(<span class="hljs-string">&quot;服务降级...test()...&quot;</span>);                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Player();            &#125;        &#125;;    &#125;&#125;</code></pre><p>application.yml</p><pre><code class="hljs yml"><span class="hljs-attr">feign:</span>  <span class="hljs-attr">hystrix:</span>    <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#开启服务降级</span></code></pre></blockquote></li></ul><h3 id="Dashboard-监控"><a href="#Dashboard-监控" class="headerlink" title="Dashboard 监控"></a>Dashboard 监控</h3><ol><li><p>导入依赖</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!--consumer项目依赖加--&gt;</span><span class="hljs-comment">&lt;!--hystrix dashboard--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-hystrix-dashboard<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.4.4.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><p>provider项目需要有</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!--actuator--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.1.14.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><p>给要被监控的api项目的启动类添加servletBean</p><p><strong>并且只能对有熔断机制的api进行监控</strong></p><pre><code class="hljs java"><span class="hljs-meta">@SpringBootApplication</span><span class="hljs-meta">@EnableTransactionManagement</span><span class="hljs-meta">@MapperScan(&quot;com.melopoz.mapper&quot;)</span><span class="hljs-meta">@EnableEurekaClient</span><span class="hljs-meta">@EnableDiscoveryClient</span><span class="hljs-meta">@EnableCircuitBreaker</span><span class="hljs-comment">//hystix  开启熔断机制</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HystrixApiApplication</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;        SpringApplication.run(HystrixApiApplication.class, args);    &#125;    <span class="hljs-meta">@Bean</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> ServletRegistrationBean <span class="hljs-title">hystrixMetricsStreamServlet</span><span class="hljs-params">()</span> </span>&#123;        ServletRegistrationBean registrationBean = <span class="hljs-keyword">new</span> ServletRegistrationBean(<span class="hljs-keyword">new</span> HystrixMetricsStreamServlet());        registrationBean.addUrlMappings(<span class="hljs-string">&quot;/hystrix.stream&quot;</span>);        <span class="hljs-keyword">return</span> registrationBean;    &#125;&#125;</code></pre></li><li><p>创建启动类</p><pre><code class="hljs java"><span class="hljs-meta">@SpringBootApplication</span><span class="hljs-meta">@EnableHystrixDashboard</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DashBordApplication</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;        SpringApplication.run(DashBordApplication.class, args);    &#125;&#125;</code></pre></li><li><p>application.yml</p><pre><code class="hljs yaml"><span class="hljs-attr">server:</span>   <span class="hljs-attr">port:</span> <span class="hljs-number">9999</span></code></pre><p>访问<a href="http://localhost:9999/hystrix">http://localhost:9999/hystrix</a></p></li></ol><h3 id="Gateway-网关"><a href="#Gateway-网关" class="headerlink" title="Gateway 网关"></a>Gateway 网关</h3><p>分发请求到提供服务的api</p><ol><li><p>依赖</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!--dashboard依赖 加--&gt;</span><span class="hljs-comment">&lt;!--zuul--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-zuul<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.4.4.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre></li><li><p>启动类</p><pre><code class="hljs java"><span class="hljs-meta">@SpringBootApplication</span><span class="hljs-meta">@EnableZuulProxy</span> <span class="hljs-comment">//使用zuul网关</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ZuulGatewayApplication</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;        SpringApplication.run(ZuulGatewayApplication.class, args);    &#125;&#125;</code></pre></li><li><p>application.yml</p><pre><code class="hljs yaml"><span class="hljs-attr">server:</span>  <span class="hljs-attr">port:</span> <span class="hljs-number">9090</span><span class="hljs-attr">spring:</span>  <span class="hljs-attr">application:</span>    <span class="hljs-attr">name:</span> <span class="hljs-string">zuul-gateway</span><span class="hljs-attr">eureka:</span>  <span class="hljs-attr">client:</span>    <span class="hljs-attr">service-url:</span>      <span class="hljs-attr">defaultZone:</span> <span class="hljs-string">http://eureka9101.com:9101/eureka,http://eureka9102.com:9102/eureka,http://eureka9103.com:9103/eureka</span>  <span class="hljs-attr">instance:</span>    <span class="hljs-attr">instance-id:</span> <span class="hljs-string">zuul-gateway</span>    <span class="hljs-attr">prefer-ip-address:</span> <span class="hljs-literal">true</span> <span class="hljs-comment"># 显示服务的ip</span><span class="hljs-attr">zuul:</span>  <span class="hljs-attr">routes:</span> <span class="hljs-comment"># 一个map 自定义</span>    <span class="hljs-attr">playerApi.serverId:</span> <span class="hljs-string">player</span>    <span class="hljs-attr">playerApi.path:</span> <span class="hljs-string">/player/**</span>  <span class="hljs-attr">ignored-services:</span> <span class="hljs-string">playerapi</span> <span class="hljs-comment">#隐藏 不可用这个访问</span>  <span class="hljs-attr">prefix:</span> <span class="hljs-string">/mp</span><span class="hljs-attr">info:</span>  <span class="hljs-attr">name:</span> <span class="hljs-string">firstspringcloud-zuul</span> <span class="hljs-string">gateway</span>  <span class="hljs-attr">msg:</span> <span class="hljs-string">this</span> <span class="hljs-string">is</span> <span class="hljs-string">zuul-gateway</span></code></pre></li></ol><h3 id="Spring-Cloud-Config"><a href="#Spring-Cloud-Config" class="headerlink" title="Spring Cloud Config"></a>Spring Cloud Config</h3><p>使用git统一配置项目的config文件。</p>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>redo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OS</title>
    <link href="/blog/2021/01/01/OS/"/>
    <url>/blog/2021/01/01/OS/</url>
    
    <content type="html"><![CDATA[<h1 id="操作系统四大特征："><a href="#操作系统四大特征：" class="headerlink" title="操作系统四大特征："></a>操作系统四大特征：</h1><h3 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h3><p>两个事件在<strong>同一段时间内</strong>发生，即宏观上同时运行；<strong>并行</strong>是两个事件在统一时刻发生，多(核)CPU可支持并行</p><h3 id="共享（资源复用）"><a href="#共享（资源复用）" class="headerlink" title="共享（资源复用）"></a>共享（资源复用）</h3><p>多个并发执行的进程共同使用同一系统资源，比如内存</p><blockquote><p>互斥共享：同一时刻只有一个进程可以访问，需要同步机制来实现互斥。互斥的资源成为<strong>临界资源</strong>。e.g.:摄像头</p><p>同时访问：允许多个进程在<strong>同一段时间内</strong>访问同一资源，即宏观上的同时。（微观上还是交替进行）e.g.:磁盘</p></blockquote><h3 id="虚拟"><a href="#虚拟" class="headerlink" title="虚拟"></a>虚拟</h3><p>程序需要放到内存中才能运行，但是太大的程序（比如10个G）不能都放到内存中，只把部分数据放到内存中，让4G内存也能运行10G的程序。</p><blockquote><p><strong>时分复用</strong>（把时间段分片）；<strong>空分复用</strong>（把较宽的信道分成多个较窄的信道）</p><p>空分复用 e.g.：需要100M内存的程序只用30M的内存，因为程序总是趋向于使用最近使用过的数据和指令，所以内存中只存放一部分，用完内存中这部分或必须要用内存中没有的数据，则把其他部分换进来</p></blockquote><blockquote><p>相关：虚拟内存，内存映射…</p></blockquote><h3 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h3><p>因为任务多，资源少的情况，所以进程通常都是走走停停的方式进行。</p><h1 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h1><blockquote><p><strong>Register</strong> ：寄存器，是CPU对接收到的信息直接处理的地方</p><p><strong>word</strong>：字，MIPS指令集术语，一个32bit的二进制串，组成一个word，一个register可load一个word，一个instruction可以是一个word</p><p><strong>Instruction</strong>：指令，32位的cpu通常就是指这个instruction的长度为32bit</p></blockquote><h2 id="寻址空间"><a href="#寻址空间" class="headerlink" title="寻址空间"></a>寻址空间</h2><p>32位CPU， 理论上 寻址空间 2^32, 4GB（32bit，可以表示2^32^ = 4G 种可能(不是4GByte)）</p><p>64位CPU， 理论上 寻址空间 2^64, 16EB = 160亿GB（只是理论上支持，但是大多64位PC也只能到32GB）</p><p>但实际寻址空间还取决于<strong>总线宽度</strong>，而且一般没有那么大内存，64位机器常用的也就<code>2^42~2^47</code>（<code>4T~</code>）吧</p><h1 id="总线-Bus"><a href="#总线-Bus" class="headerlink" title="总线 Bus"></a>总线 Bus</h1><p>数据总线</p><p>地址总线</p><p>控制总线</p><h1 id="内核态-用户态"><a href="#内核态-用户态" class="headerlink" title="内核态 / 用户态"></a>内核态 / 用户态</h1><p>内核态：操作系统管理程序运行时的状态。运行在内核态的程序可以访问计算机的任何资源，比如协调CPU，分配内存资源；</p><p>用户态：应用程序运行时的状态。用户态的程序只能访问当前CPU上执行的程序所在的地址空间。</p><p>区分内核态和用户态是为了<strong>安全，控制权限，保护操作系统程序</strong>。</p><p>OS在内核态会在合适的情况（比如执行完某IO命令）把CPU使用权还给应用程序，即转换回用户态。但是从用户态转换到内核态，只能通过<a href="#%E4%B8%AD%E6%96%AD%E6%9C%BA%E5%88%B6">中断机制</a>来实现。</p><h3 id="Linux内核空间"><a href="#Linux内核空间" class="headerlink" title="Linux内核空间"></a>Linux内核空间</h3><p>Linux会给程序分配4G（2^32）的虚拟地址空间（<a href="#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98">虚拟内存</a>），这4G又分为3G用户空间和1G内核空间（只能在内核态访问）（Windows为2:2），</p><blockquote><p>使用命令<code>cat /proc/cpuinfo</code> 可以查看到 <code>address sizes   : 36 bits physical, 48 bits virtual</code> （在win10的Ubuntu子系统中）</p><p>2^32^物理地址空间，2^48^虚拟地址空间</p></blockquote><h1 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h1><blockquote><p>进程：程序的执行过程，是暂时的。 （也可以说包含正在运行的程序实体和其占据的所有系统资源, CPU,内存,网络）</p><p>进程又可以有多个线程，需要操作系统来执行上下文切换，让多个进程/线程使用同一个CPU资源</p></blockquote><h3 id="进程调度"><a href="#进程调度" class="headerlink" title="进程调度"></a>进程调度</h3><p>多任务系统中用于管理CPU的时间片分配，OS<strong>内核</strong>必须有能力挂起正在 CPU 上运行的进程，并恢复以前挂起的某个进程的执行。</p><blockquote><p>进程在不同的操作系统中有些称为process，有些称为task。操作系统中进程数据结构包含了很多元素，往往用链表连接。</p><p>进程相关的内容主要包括：虚拟地址空间，优先级，生命周期(阻塞，就绪，运行等)，占有的资源(例如信号量，文件等)。</p><p>CPU在每个系统滴答(Tick)中断产生的时候检查就绪队列里面的进程(遍历链表中的进程struct)，如有符合调度算法的新进程需要切换，保存当前运行的进程的信息(包括栈信息等)后挂起当前进程，选择新的进程运行，这就是<strong>进程调度</strong>。</p></blockquote><blockquote><p>进程的优先级差异是CPU调度的基本依据，调度的终极目标是让高优先级的活动能够即时得到CPU的计算资源(即时响应)，低优先级的任务也能公平分配到CPU资源。因为需要保存进程运行的上下文(process context)等，<strong>进程的切换本身是有成本的</strong>，调度算法在进程切换频率上也需要考虑效率。</p></blockquote><h4 id="CFS：Completely-Fair-Scheduler"><a href="#CFS：Completely-Fair-Scheduler" class="headerlink" title="CFS：Completely Fair Scheduler"></a>CFS：Completely Fair Scheduler</h4><blockquote><p>在<strong>早期的Linux</strong>操作系统中，主要采用的是<strong>时间片轮转算法</strong>(Round-Robin)，内核在就绪的进程队列中选择高优先级的进程运行，每次运行相等的时间。该算法简单直观，但仍然会导致某些低优先级的进程长时间无法得到调度。为了提高调度的公平性，在Linux 2.6.23之后，引入了称为<strong>完全公平调度器CFS</strong>(Completely Fair Scheduler)。</p><p>CPU在任何时间点只能运行一个程序，用户在使用优酷APP看视频时，同时在微信中打字聊天，优酷和微信是两个不同的程序，为什么看起来像是在同时运行？CFS的目标就是让所有的程序看起来都是以相同的速度在多个并行的CPU上运行，即nr_running 个运行的进程，每个进程以1/nr_running的速度并发执行，例如如有2个可运行的任务，那么每个以50%的CPU物理能力并发执行。</p><p>CFS引入了”虚拟运行时间”的概念，虚拟运行时间用p-&gt;se.vruntime (nanosec-unit) 表示，通过它记录和度量任务应该获得的”CPU时间”。在理想的调度情况下，任何时候所有的任务都应该有相同的p-&gt;se.vruntime值(上面提到的以相同的速度运行)。因为每个任务都是并发执行的，没有任务会超过理想状态下应该占有的CPU时间。CFS选择需要运行的任务的逻辑基于p-&gt;se.vruntime值，非常简单：它总是挑选p-&gt;se.vruntime值最小的任务运行(最少被调度到的任务)。</p><p>CFS使用了基于时间排序的红黑树来为将来任务的执行排时间线。所有的任务按p-&gt;se.vruntime关键字排序。CFS从树中选择最左边的任务执行。随着系统运行，执行过的任务会被放到树的右边，逐步地地让每个任务都有机会成为最左边的任务，从而在一个可确定的时间内获得CPU资源。</p><p>总结来说，CFS首先运行一个任务，当任务切换(或者Tick中断发生的时候)时，该任务使用的CPU时间会加到p-&gt;se.vruntime里，当p-&gt;se.vruntime的值逐渐增大到别的任务变成了红黑树最左边的任务时(同时在该任务和最左边任务间增加一个小的粒度距离，防止过度切换任务，影响性能)，最左边的任务被选中执行，当前的任务被抢占。</p><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/CFS%E5%AE%8C%E5%85%A8%E5%85%AC%E5%B9%B3%E8%B0%83%E5%BA%A6.png" style="zoom:50%;" /></blockquote><p>参考：<a href="https://blog.csdn.net/weixin_39722375/article/details/111206454">https://blog.csdn.net/weixin_39722375/article/details/111206454</a></p><h3 id="进程阻塞"><a href="#进程阻塞" class="headerlink" title="进程阻塞"></a>进程阻塞</h3><p>正在执行的进程，<code>请求系统资源失败</code>、<code>等待某种操作的完成</code>、<code>新数据尚未到达</code>或<code>无新任务可以执行</code>等，则由系统自动执行阻塞原语(<code>Block</code>)，使自己由运行状态变为阻塞状态。</p><p>是进程自身的一种主动行为，只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。<code>当进程进入阻塞状态，会释放CPU资源</code></p><h3 id="中断机制"><a href="#中断机制" class="headerlink" title="中断机制"></a>中断机制</h3><blockquote><p>CPU正常运行期间，停止当前操作，执行其他特殊操作的行为就叫中断，负责跳转的指令就是<code>中断指令</code>。</p></blockquote><ul><li>内部中断：中断信号来源于CPU内部，如地址越界、除数为0；</li><li>外部中断：如IO完成、时钟中断（线程切换）、控制台中断（Ctrl+C）</li></ul><h4 id="缺页中断"><a href="#缺页中断" class="headerlink" title="缺页中断"></a>缺页中断</h4><p>每当所要访问的内存页不在时，会产生一次<code>缺页中断</code>，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。 </p><blockquote><p>缺页中断是一种特殊的中断，它与一般的中断的区别是：</p><ol><li><p>在指令执行期间产生和处理中断信号</p><p>CPU通常在一条指令执行完后检查是否有中断请求，而缺页中断是在指令执行时间，发现所要访问的指令或数据不在内存时产生和处理的。</p></li><li><p>一条指令在执行期间可能产生多次缺页中断</p><p>如一条读取数据的多字节指令，指令本身跨越两个页面，若指令后一部分所在页面和数据所在页面均不在内存，则该指令的执行至少产生两次缺页中断。</p></li></ol></blockquote><h1 id="缓存IO"><a href="#缓存IO" class="headerlink" title="缓存IO"></a>缓存IO</h1><blockquote><p>缓存 IO 又被称作标准 IO，大多数文件系统的默认 IO 操作都是缓存 IO</p></blockquote><p>在 Linux 的缓存 IO 机制中，OS会将 IO 的数据缓存在文件系统的页缓存<code>page cache</code>(在内存中)中，也就是说：</p><blockquote><p>数据会先被拷贝到<code>操作系统内核的缓冲区</code>中（disk -&gt; memory）</p><p>然后才会从<code>操作系统内核的缓冲区</code>拷贝到<code>应用程序的地址空间</code>（用户态，虚拟地址对应的物理地址）</p></blockquote><p>也就是需要 两次拷贝，这些数据拷贝操作所带来的 CPU 以及内存开销非常大，</p><p>所以很多应用程序会利用<a href="#%E9%9B%B6%E6%8B%B7%E8%B4%9D">零拷贝</a>技术来避免这种多次拷贝操作的发生以提高性能。</p><blockquote><p>补充：（个人理解是这样）</p><p>page cache：页缓存，用来存储文件数据中的业务数据部分。重点是cache（缓存）</p><p>buffer cache：针对磁盘块的缓存，存储任意一个扇区的数据。重点是buffer（缓冲），比如MySQL的插入缓冲，读写的时候 放到buffer中，然后由OS决定何时刷到磁盘。</p><blockquote><p>也就是说在没有文件系统的情况下（准确的表达是，无论有否文件系统的存在，设备驱动程序读取的数据（也即直接对磁盘进行操作的数据）都是缓存到buffer cache中的），直接对磁盘进行操作的数据会缓存到buffer cache中，例如，文件系统的元数据都会缓存到buffer cache中</p></blockquote></blockquote><h1 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h1><p>内存 本来存放的是正在运行的程序相关的数据，但是因为物理内存大小限制，只能把必须的、使用频繁的部分放入内存，内存满了就在内存中删除非必须的，加载必须的数据。</p><blockquote><p>RAM（<strong>Random Access</strong> Memory）：随机读写存储，主内存</p><p>ROM（<strong>Read Only</strong> Memory）：只读内存，比如主板上用来存放BIOS程序。</p></blockquote><p>首先，CPU是通过地址从<code>RAM/ROM/外设</code>中获取数据（程序、数据）以执行/运算；CPU能识别多大范围内的地址，取决于CPU的<a href="#%E5%AF%BB%E5%9D%80%E7%A9%BA%E9%97%B4">寻址空间</a></p><p>如果执行的程序都放进内存，可能会导致内存不够用，所以使用了<a href="#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98">虚拟内存</a>技术，<strong>让程序看起来内存空间足够大并且可用地址是连续的</strong></p><h2 id="交换空间-swap"><a href="#交换空间-swap" class="headerlink" title="交换空间 swap"></a>交换空间 swap</h2><p>如果物理内存不够用，则会通过swap将暂时不用的物理页换到硬盘上。</p><blockquote><p>由物理内存和一部分磁盘空间组成</p><p>如果物理内存不够用了 ， 就通过LRU算法把最近使用频率最低的内存数据放到磁盘（交换空间）</p><p>如果这块内存需要被使用，再通过缺页异常，把磁盘中那部分数据刷回内存</p></blockquote><p>Linux内核就是维护了一张表来记录每一页存储在物理内存还是交换空间(磁盘)。</p><h3 id="页面置换算法"><a href="#页面置换算法" class="headerlink" title="页面置换算法"></a>页面置换算法</h3><p>LRU、OPT、FIFO…算了 哥   <code>https://www.google.com/search?q=页面置换算法</code></p><h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><p>又叫 <code>线性地址</code>、<code>虚拟地址空间</code></p><p>OS使用<code>虚拟内存</code>抽象了物理内存的使用，上层（应用）调用的时候使用虚拟地址，让CPU转换成实际的物理地址再去访问内存。</p><blockquote><p>最大的地址空间和实际系统有多少物理内存无关，也因此称为<strong>虚拟</strong>地址空间。Linux是通过<strong>段页机制</strong>来将虚拟地址和物理地址进行映射。</p></blockquote><blockquote><p><strong>MMU</strong>（内存管理单元）：CPU中用来管理虚拟存储器、物理存储器的控制线路，同时也<strong>负责虚拟地址映射为物理地址</strong>，以及提供硬件机制的内存访问授权</p><blockquote><p>CPU通过<strong>TLB</strong>（Translation Lookaside Buffer，转换检测缓冲区）提升虚拟地址到物理地址的转换速度</p></blockquote></blockquote><p>绝大多数情况下，虚拟地址空间比实际系统可用的物理内存(RAM)大，内核和CPU必须考虑如何将实际可用的物理内存映射到虚拟地址空间。一个方法是通过页表(Page Table)将虚拟地址映射到物理地址。每个单元格是一个<code>page frame</code>。<a href="#%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84mmap">内存映射mmap</a></p><img alt="mmap" src="https://raw.githubusercontent.com/melopoz/pics/master/img/mmap.png" style="zoom:50%;" /><blockquote><p>有可能 <code>虚拟内存中的某个地址并未使用</code> 或者 <code>对应的数据还没有被加载到内存</code>，或者<code>物理内存页被置换到了硬盘上</code>，这时候会导致<a href="#%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD">缺页中断</a>，由中断处理程序将数据放到内存中之后再继续执行。</p></blockquote><h5 id="多级页表"><a href="#多级页表" class="headerlink" title="多级页表"></a>多级页表</h5><blockquote><p>因为虚拟地址空间的绝大多数区域实际并没有使用，这些页实际并没有和page frame关联，引入多级页表(multilevel paging)能极大降低页表使用的内存，提高查询效率。<a href="https://www.zhihu.com/question/63375062">https://www.zhihu.com/question/63375062</a></p></blockquote><h2 id="内存映射mmap"><a href="#内存映射mmap" class="headerlink" title="内存映射mmap"></a>内存映射mmap</h2><blockquote><p>Memory Mapping，底层的一个函数 <code>mmap()</code></p></blockquote><p>内存映射是将来自某个数据源的数据(也可以是某个设备的I/O端口等)转移到某个进程的虚拟内存空间。</p><blockquote><p>任何<strong>对内存的改动会自动转移到原数据源</strong>，例如将某个文件的内容映射到内存中，只需要通过读该内存来获取文件的内容，通过将改动写到该内存来修改文件的内容，<strong>内核确保任何改动都会自动体现到文件里</strong>。</p><p>在内核中，<strong>实现设备驱动</strong>时，外设(外部设备)的输入和输出区域可以被映射到虚拟地址空间，读写这些空间会被系统重定向到设备，从而对设备进行操作，极大地简化了驱动的实现。</p></blockquote><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/%E6%96%87%E4%BB%B6%E6%98%A0%E5%B0%84%E5%88%B0%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98.png" style="zoom:50%;" /><blockquote><p>内核必须跟踪哪些物理页已经被分配了，哪些还是空闲的，避免两个进程使用RAM中的同一个区域。内存的分配和释放是非常频繁的任务，内核必须确保完成的速度尽量快，所以<strong>内核只能分配整个page frame</strong>，它将<code>把内存分为更小的部分的任务</code>交给了用户空间，用户空间的程序库可以将<code>从内核收到的page frame</code>分成更小的区域后分配给进程。</p></blockquote><p>mmap() 函数：</p><blockquote><p>在驱动程序的<code>mmap()</code>系统调用中，使用<code>remap_page_range()</code>将<strong>该块ROM映射到用户虚拟空间</strong>。这样内核空间和用户空间都能访问这段被映射后的虚拟地址。</p><p><code>remap_page_range()</code>函数的功能是<code>构造用于映射一段物理地址的新页表</code>，<strong>实现了内核空间与用户空间的映射</strong>。</p><p>在内核<strong>驱动程序的初始化阶段</strong>，通过<code>ioremap()</code><strong>将物理地址映射到内核虚拟空间</strong>；</p></blockquote><h4 id="Java中的应用："><a href="#Java中的应用：" class="headerlink" title="Java中的应用："></a>Java中的应用：</h4><blockquote><p>MappedByteBuffer使用mmap的文件映射，在full gc时才会进行释放。</p><p>当close时，需要手动清除内存映射文件，可以反射调用sun.misc.Cleaner方法</p></blockquote><h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><blockquote><p><strong>零拷贝</strong>（<strong>Zero-copy</strong>）技术是指计算机执行操作时，CPU不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于<strong>通过网络传输文件时节省CPU周期和内存带宽</strong>。</p></blockquote><p>并不是真的<strong>零</strong>拷贝，只是减少内核态和用户态的切换次数 和 数据拷贝次数。</p><h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><h4 id="mmap-read-write"><a href="#mmap-read-write" class="headerlink" title="mmap+read/write"></a>mmap+read/write</h4><p>直接调用系统的<code>read()</code>和 内存映射文件并读取<code>mmap()</code>的区别：</p><ul><li><p>直接调用<code>read()</code>，需要内核来调用，步骤：1）从硬盘拷贝到内核缓冲区(内核空间)，2）从内核空间拷贝到用户空间；（即需要用到<a href="#%E7%BC%93%E5%AD%98IO">缓存IO</a>）</p><blockquote><p>首先将文件内容从硬盘拷贝到内核空间的一个缓冲区，然后再将这些数据拷贝到用户空间，这个过程实际上发生了<strong>两次</strong>数据拷贝；</p></blockquote></li><li><p>普通文件/设备通过<code>mmap()</code>被映射到进程地址空间（虚拟内存）后，进程可以像访问普通内存一样对文件进行访问，只要在分配的地址范围内进行读取或者写入即可，不必再调用 read / write。具体步骤如下：</p><blockquote><p>调用<code>mmap()</code>返回一个虚拟空间的指针<code>ptr</code>，指向进程逻辑空间（虚拟内存）中的一个地址，进程再操作这个数据的时候，相当于读写内存：</p><blockquote><p>由MMU将逻辑地址转换为物理地址，如果没能找到对应的物理地址，会引发缺页中断，CPU的中断处理程序会在swap中寻找对应的数据页，如果再找不到，就会使用mmap()建立的映射关系，将硬盘文件的数据读取到物理内存中。</p></blockquote></blockquote></li></ul><p><code>mmap()</code>虽然也是系统调用，但它没有直接调用<code>read()</code>进行数据拷贝，<strong>真正的数据拷贝是在缺页中断处理时进行的</strong>，由于mmap()将文件直接映射到用户空间，所以<strong>中断处理程序</strong>根据这个映射关系，<strong>直接将文件从硬盘拷贝到用户空间</strong>，<strong>只进行</strong>了<strong>一次数据拷贝</strong> 。因此，内存映射的效率要比read/write效率高。</p><blockquote><p>零拷贝是有一次拷贝过程，但是该拷贝操作如果存在，也不是直接属于此进程，而是由中断处理程序处理一个缺页异常，这样看来进程其实是没有进行拷贝操作的。估计因此才叫的<strong>零</strong>拷贝，该拷贝操作是无法避免的，必须得读取文件到内存中。</p></blockquote><p>所以mmap()对<strong>处理大文件</strong>提高了效率。</p><h4 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h4><p>Linux2.1的sendfile()如下，<strong>三次拷贝</strong>（两次DMA拷贝，一次CPU拷贝）</p><img alr="Linux2.1 sendfile()" src="https://raw.githubusercontent.com/melopoz/pics/master/img/linux2.1-sendfile.png" style="zoom:50%;" /><blockquote><p>图片来自<a href="https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA">https://mp.weixin.qq.com/s/dt0h2UhaoRECvjpeMZMsUA</a></p></blockquote><h4 id="Linux2-4-sendfile：DMA-Scatter-Gatter"><a href="#Linux2-4-sendfile：DMA-Scatter-Gatter" class="headerlink" title="Linux2.4-sendfile：DMA Scatter/Gatter"></a>Linux2.4-sendfile：DMA Scatter/Gatter</h4><blockquote><p>DMA（Direct Memory Access，直接存储器访问）</p><p>引入新的硬件支持 – Scatter/Gatter（分散/聚集）（两次DMA拷贝，没有CPU拷贝）</p></blockquote><img alr="Linux2.4 sendfile()" src="https://raw.githubusercontent.com/melopoz/pics/master/img/Linux-2.4-sendfile.png" style="zoom:50%;" /><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>RocketMQ</p><blockquote><p>mmap+read/write</p></blockquote><p>Kafka</p><blockquote><p>持久化使用 mmap+write</p><p>发送数据使用 sendfile</p></blockquote><p>java.nio.channels.FileChannel#transferFrom()/transferTo()</p><blockquote><p>使用 sendfile</p><pre><code class="hljs java">File file = <span class="hljs-keyword">new</span> File(<span class="hljs-string">&quot;demo.zip&quot;</span>);RandomAccessFile raf = <span class="hljs-keyword">new</span> RandomAccessFile(file, <span class="hljs-string">&quot;rw&quot;</span>);FileChannel fileChannel = raf.getChannel();SocketChannel socketChannel = SocketChannel.open(<span class="hljs-keyword">new</span> InetSocketAddress(<span class="hljs-string">&quot;&quot;</span>, <span class="hljs-number">1234</span>));<span class="hljs-comment">// 直接使用了transferTo()进行通道间的数据传输</span>fileChannel.transferTo(<span class="hljs-number">0</span>, fileChannel.size(), socketChannel);</code></pre><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/java-nio-sendfile.png" style="zoom:50%;" /></blockquote><h2 id="mmap-和-sendfile总结"><a href="#mmap-和-sendfile总结" class="headerlink" title="mmap 和 sendfile总结"></a>mmap 和 sendfile总结</h2><p>1、都是Linux内核提供、实现零拷贝的API；<br>2、sendfile 是将读到内核空间的数据，转到socket buffer，进行网络发送；<br>3、mmap将磁盘文件映射到内存，支持读和写，对内存的操作会反映在磁盘文件上。</p><h1 id="IO设备管理"><a href="#IO设备管理" class="headerlink" title="IO设备管理"></a>IO设备管理</h1><p>操作系统向I/O设备发送命令，比如访问设备、读写数据、读写设备配置，还要捕捉中断，处理设备的错误，并提供设备功能的抽象。</p><h1 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a>文件管理</h1><p>将硬盘的扇区组织成文件系统，实现文件读写操作</p><p>比如 win使用NTFS、FAT32、FAT16；macOS使用APFS（apple file system）；linux使用EXT2 等等</p><blockquote><p>一个操作系统可以支持多种底层不同的文件系统（比如NTFS, FAT, ext3, ext4），为了给内核和用户进程提供统一的文件系统视图，Linux在用户进程和底层文件系统之间加入了一个抽象层，即<strong>虚拟文件系统(Virtual File System, VFS)</strong></p><p>进程所有的文件操作都通过VFS，由VFS来适配各种底层不同的文件系统，完成实际的文件操作。</p></blockquote><p>Linux 内核 看去吧…</p><p><a href="https://www.kernel.org/doc/html/v4.14/index.html">https://www.kernel.org/doc/html/v4.14/index.html</a></p>]]></content>
    
    
    <categories>
      
      <category>OS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>内存管理</tag>
      
      <tag>零拷贝</tag>
      
      <tag>IO多路复用</tag>
      
      <tag>select</tag>
      
      <tag>poll</tag>
      
      <tag>epoll</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis</title>
    <link href="/blog/2021/01/01/NOSQL_Redis/"/>
    <url>/blog/2021/01/01/NOSQL_Redis/</url>
    
    <content type="html"><![CDATA[<p>配置文件示例</p><p><a href="http://download.redis.io/redis-stable/redis.conf">http://download.redis.io/redis-stable/redis.conf</a></p><hr><h3 id="本地缓存和分布式缓存"><a href="#本地缓存和分布式缓存" class="headerlink" title="本地缓存和分布式缓存"></a>本地缓存和分布式缓存</h3><blockquote><p>本地缓存，比如java中的map，guava实现，轻量、快速，但是如果有多个实例，就需要每个实例都保存一份缓存，不具有一致性。</p></blockquote><blockquote><p> 分布式缓存，比如redis、memcached，缓存具有一致性。但是需要保持服务的高可用。</p></blockquote><hr><h3 id="redis-VS-memcached"><a href="#redis-VS-memcached" class="headerlink" title="redis VS memcached"></a>redis VS memcached</h3><ol><li>redis数据类型丰富，memcached只支持string；</li><li>redis支持数据持久化，可以在宕机、重启之后进行数据恢复。memcached只能存储在内存；</li><li>redis原生支持集群cluster，memcached没有原生集群模式；</li><li>redis使用单线程的IO多路复用模型，memcached是<strong>多线程</strong>、非阻塞的IO复用的网络模型。redis6也使用了多线程IO</li></ol><hr><h3 id="redis-工作模式"><a href="#redis-工作模式" class="headerlink" title="redis 工作模式"></a>redis 工作模式</h3><p>多个cli连接server</p><blockquote><p>redis需要处理cli的命令(get,set,lpush,rpop…)，对<code>接收客户端链接，处理请求，返回命令结果</code>等任务，redis使用主进程和主线程完成。</p><p>redis后台还有RDB持久化，AOF重写等任务，这些任务会启动子进程来完成。</p></blockquote><hr><h3 id="redis-线程模型"><a href="#redis-线程模型" class="headerlink" title="redis 线程模型"></a>redis 线程模型</h3><p><a href="https://www.jianshu.com/p/8f2fb61097b8">https://www.jianshu.com/p/8f2fb61097b8</a> 这个图更清楚一点</p><blockquote><p>redis内部使用文件事件处理器（file event handler），这个handler是单线程的，所有请求都要经过这个入口才能被处理，自然就有了先后顺序，所以说是单线程模型。</p></blockquote><blockquote><p>在这个模型中，Redis 服务器用主线程执行 I/O 多路复用程序、文件事件分派器以及事件处理器。而且，尽管多个文件事件可能会并发出现，Redis 服务器是顺序处理各个文件事件的。        ——《Redis设计与实现》</p></blockquote><blockquote><p>IO多路复用的 Reactor 模式</p></blockquote><p>master线程监听多个socket，将产生的事件加入任务队列，事件分派器从队列中取出事件并执行，这也就保证按顺序执行。</p><p><img src="https://raw.githubusercontent.com/melopoz/pics/master/img/redis%E5%A4%84%E7%90%86%E4%B8%80%E6%AC%A1%E5%91%BD%E4%BB%A4%E8%BF%87%E7%A8%8B.png" alt="redis处理客户端一个命令的过程"></p><hr><h3 id="redis6线程模型"><a href="#redis6线程模型" class="headerlink" title="redis6线程模型"></a>redis6线程模型</h3><p>采用多线程处理IO(默认不开启)，事件处理器仍然是单线程。</p><blockquote><pre><code class="hljs coffeescript">io-threads-<span class="hljs-keyword">do</span>-reads <span class="hljs-literal">no</span> <span class="hljs-comment">#yes开启  多线程</span>io-threads <span class="hljs-number">4</span> <span class="hljs-comment">#配置&lt;=cpu核数性能最高，之前单线程就是只能谁用一个cpu，现在如果线程数量过多增加了线程上下文切换的话性能可能不会提升</span><span class="hljs-comment">#官方建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程，线程数一定要小于机器核数。</span><span class="hljs-comment">#官方认为线程数并不是越大越好，超过了8个基本就没什么意义了</span></code></pre></blockquote><img alt="redis6线程模型" src="https://i.loli.net/2021/04/02/bEgYzjoiDw1HF9q.png" /><blockquote><p>以前redis是主线程使用IO多路复用对socket进行读写。现在改成主线程把IO分配给多个IO线程 批量读、批量写。</p></blockquote><ul><li>所以 <strong>IO线程只能是同时都在读</strong> 或者 <strong>同时都在写</strong>；</li><li>IO线程时负责读写socket解析命令，命令处理还是通过单线程的文件事件处理器处理；</li></ul><blockquote><ol><li><p>主线程把准备好了的socket放到等待队列，然后阻塞等待IO线程去处理socket</p><blockquote><p>感觉就相当于 用多线程IO同时对一批socket进行处理，以提高QPS</p></blockquote></li><li><p>主线程顺序处理事件（交由对应的处理器处理），处理结果再交给IO线程写到对应的socket</p></li><li><p>等待IO线程的写操作都完成，解除IO线程和等待队列中的socket的绑定，清空等待队列（socket都处理完了嘛）</p></li><li><p>再走1   这么个循环。</p></li></ol><p>以前是：</p><pre><code class="hljs c"><span class="hljs-keyword">while</span>(<span class="hljs-literal">true</span>) &#123;    epoll_wait(..关注的fd.)    <span class="hljs-keyword">for</span> (fd <span class="hljs-keyword">int</span> readyfd) &#123;        read(fd)    &#125;    push 到任务队列    ...<span class="hljs-comment">// 从任务队列取出处理完成的事件 写回到对应socket</span>&#125;</code></pre><p>redis6是</p><pre><code class="hljs c"><span class="hljs-keyword">while</span>(<span class="hljs-literal">true</span>) &#123;    epoll_wait(..关注的fd.)    <span class="hljs-keyword">for</span> (fd <span class="hljs-keyword">int</span> readyfd) &#123;        把fd分配给等待队列的IO线程    &#125;    ...<span class="hljs-comment">// 阻塞 把等待队列中的IO读完的数据 解析并push到任务队列</span>    ...<span class="hljs-comment">// 从任务队列取出处理完成的事件 写回到对应socket</span>&#125;</code></pre></blockquote><blockquote><p>redis源码   <a href="https://github.com/redis/redis.git">https://github.com/redis/redis.git</a></p></blockquote><hr><h3 id="fork子线程时-主线程阻塞"><a href="#fork子线程时-主线程阻塞" class="headerlink" title="fork子线程时 主线程阻塞"></a>fork子线程时 主线程阻塞</h3><h4 id="直观感受"><a href="#直观感受" class="headerlink" title="直观感受"></a>直观感受</h4><p>在Redis的实践中，众多因素限制了Redis单机的内存不能过大，例如：</p><ul><li>当请求暴增，需要扩容时，Redis内存过大会导致扩容时间太长；</li><li>当主机宕机时，切换主机后需要挂载从库，Redis内存过大导致挂载速度过慢；</li><li>以及持久化过程中的<code>fork</code>操作。</li></ul><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>父进程通过<code>fork</code>操作可以创建子进程；</p><p>子进程创建后，与父子进程共享代码段，不共享进程的数据空间，所以子进程会获得父进程的数据空间的副本。</p><blockquote><p>在操作系统<code>fork</code>的实际实现中，基本都采用了写时复制技术：<strong>copy on write</strong></p><blockquote><p>即在父/子进程试图修改数据空间之前，父子进程实际上共享数据空间；</p><p>但是当父/子进程的任何一个试图修改数据空间时，操作系统会为修改的那一部分(内存的一页)制作一个副本。</p></blockquote></blockquote><blockquote><p>虽然<code>fork</code>时，子进程不会复制父进程的数据空间，只是会复制内存页表（页表相当于内存的索引、目录）</p></blockquote><p>父进程的数据空间越大，内存页表越大，所以fork时复制耗时也会越多。</p><h4 id="影响"><a href="#影响" class="headerlink" title="影响"></a>影响</h4><p>在Redis中，无论是RDB持久化的<code>bgsave</code>，还是AOF重写的<code>bgrewriteaof</code>，都需要fork出子进程来进行操作。</p><p>如果Redis内存过大，会导致fork操作时复制内存页表耗时过多，而Redis主进程又是单线程的，在进行fork时，是完全阻塞的，也就意味着无法响应客户端的请求，会造成请求延迟过大。</p><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ol><li>限制单机内存；</li><li>适度放宽AOF重写的触发条件；</li><li>砸钱（硬件搞强一点）</li><li>非要用虚拟机就用使用Vmware或KVM虚拟机，不要使用Xen虚拟机</li></ol><p>对于不同的硬件、不同的操作系统，fork操作的耗时会有所差别，一般来说，如果Redis单机内存达到了<strong>10GB</strong>，fork时耗时可能会达到<strong>百毫秒级别</strong>（如果使用Xen虚拟机，这个耗时可能达到秒级别）。</p><blockquote><p>因此，一般来说Redis单机内存一般要限制在10GB以内；不过这个数据并不是绝对的，可以通过观察线上环境fork的耗时来进行调整。</p><blockquote><p>执行命令<code>info stats</code>，查看<code>latest_fork_usec</code>的值，单位为微秒。</p></blockquote></blockquote><hr><h3 id="redis-常用命令"><a href="#redis-常用命令" class="headerlink" title="redis 常用命令"></a>redis 常用命令</h3><ul><li><p><strong>del</strong>、<strong>exists</strong>、<strong>type</strong></p></li><li><p>redis <strong>expires</strong></p><p>在redis中添加元素的时候设置过期时间：set key value 存活时间</p></li><li><p><strong>expire</strong>  重新设置key的存活时间</p></li><li><p><strong>persist</strong> 去掉一个key的过期时间，使之成为持久化key</p></li><li><p><strong>ttl</strong>  以秒为单位，返回 key 的剩余生存时间</p></li><li><p><strong>rename</strong> 对一个key改名，之后存活时间继续计时</p></li><li><p><strong>setnx</strong>  不存在就插入</p></li></ul><pre><code class="hljs shell">localhost:6379&gt; config get auto-aof-rewrite-min-size1)&quot;auto-aof-rewrite-min-size&quot;2)&quot;67108864&quot;localhost:6379&gt; info persistence  #持久化信息1) aof_current_size:1492) aof_base_size:149</code></pre><h3 id="数据类型-操作"><a href="#数据类型-操作" class="headerlink" title="数据类型-操作"></a>数据类型-操作</h3><h4 id="string"><a href="#string" class="headerlink" title="string"></a>string</h4><p><code>set</code>、<code>mset</code>、<code>get</code>、<code>mget</code>、<code>getset</code>、<code>strlen</code>、<code>incr</code>、<code>incrby</code>、<code>decr</code>、<code>decrby</code>（原子增量）</p><h4 id="list"><a href="#list" class="headerlink" title="list"></a>list</h4><p><code>lpush</code>、<code>rpush</code>、<code>lpop</code>、<code>rpop</code>、<code>llen</code>  查看list中元素的个数</p><blockquote><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> rpush mylist 1 2 3 4 5 <span class="hljs-string">&quot;foo bar&quot;</span></span>(integer) 9</code></pre></blockquote><p><code>lrange [key] [indexStart] [indexEnd]</code> 遍历get</p><blockquote><p>两个索引参数都可以为负，-1是列表的最后一个元素，-2是列表的倒数第二个元素，依此类推。</p><pre><code class="hljs tcl">&gt; <span class="hljs-keyword">lrange</span> mylist <span class="hljs-number">0</span> <span class="hljs-number">-1</span><span class="hljs-number">1</span>) <span class="hljs-string">&quot;first&quot;</span><span class="hljs-number">2</span>) <span class="hljs-string">&quot;A&quot;</span><span class="hljs-number">3</span>) <span class="hljs-string">&quot;B&quot;</span><span class="hljs-number">4</span>) <span class="hljs-string">&quot;1&quot;</span><span class="hljs-number">5</span>) <span class="hljs-string">&quot;2&quot;</span><span class="hljs-number">6</span>) <span class="hljs-string">&quot;3&quot;</span><span class="hljs-number">7</span>) <span class="hljs-string">&quot;4&quot;</span><span class="hljs-number">8</span>) <span class="hljs-string">&quot;5&quot;</span><span class="hljs-number">9</span>) <span class="hljs-string">&quot;foo bar&quot;</span></code></pre></blockquote><p><code>ltrim [key] [indexStart] [indexEnd]</code> 修剪</p><blockquote><p>仅保留<code>indexStart</code>到<code>indexEnd</code>的元素并返回，范围之外的全都丢弃。</p></blockquote><p><code>brpop [key] [timeout]</code>、<code>blpop ..</code> </p><blockquote><p>b：blocked阻塞</p><pre><code class="hljs accesslog"><span class="hljs-number">127.0.0.1:7963</span>&gt; brpop list1 list2 <span class="hljs-number">5</span>(nil)(<span class="hljs-number">5</span>.06s)</code></pre></blockquote><p><code>lpoprpush [key1] [key2]</code>   转移列表的数据</p><p><code>linsert</code>  插入到指定位置 </p><p><code>linsert [list1] [before/after] [v1] [v2]</code>  在v1前边插入一个v2，返回新len，如果a不存在返回-1</p><p>使用场景</p><blockquote><ul><li>用户的最新动态（最近5、10条）</li><li>队列（不安全）</li></ul></blockquote><p>注意事项</p><blockquote><p>因为不能对集合中每项都设置TTL，但是可以对整个集合设置TTL。<strong>所以，我们可以将每个时间段的数据放在一个集合中。然后对这个集合设置过期时间。</strong></p></blockquote><h4 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h4><p>命令：<code>hset</code>，<code>hget</code>，<code>hmset</code>，<code>hmget</code>，<code>hgetall</code>，<code>hexists</code>，<code>hsetnx</code> 见名知意吧</p><h4 id="set"><a href="#set" class="headerlink" title="set"></a>set</h4><p><code>sadd [key] [v1] [v2] ...</code></p><p>``spop [key]`</p><p><code>sismember [key] [value]</code>  set中是否存在这个value，返回 1 / 0</p><p><code>smembers [key]</code>   所有元素</p><p><code>srandmember [key] [n]</code>  随机n个元素，比如随机两个  <code>srandmember setdemo 2</code></p><p><code>sunion [key1] [key2]</code>   并集</p><h4 id="zset"><a href="#zset" class="headerlink" title="zset"></a>zset</h4><p>sortedset，增加了权重参数score，使集合中的元素按照score有序排列</p><pre><code class="hljs sh">zadd zset 1 one  <span class="hljs-comment">#如果one已经存在，就会覆盖原来的分数</span>zadd zset 2 two  zadd zset 3 threezincrby zset 1 one <span class="hljs-comment">#增长分数</span>zscore zset two <span class="hljs-comment">#获取分数</span>zrange zset 0 -1 withscores <span class="hljs-comment">#范围遍历</span>zrangebyscore zset 10 25 withscores <span class="hljs-comment">#指定范围的值</span>zrangebyscore zset 10 25 withscores <span class="hljs-built_in">limit</span> 1 2 <span class="hljs-comment">#分页</span>Zrevrangebyscore zset 10 25 withscores  <span class="hljs-comment">#指定范围的值</span>zcard zset  <span class="hljs-comment">#元素数量</span>Zcount zset <span class="hljs-comment">#获得指定分数范围内的元素个数</span>Zrem zset one two <span class="hljs-comment">#删除一个或多个元素</span>Zremrangebyrank zset 0 1 <span class="hljs-comment">#按照排名范围删除元素</span>Zremrangebyscore zset 0 1 <span class="hljs-comment">#按照分数范围删除元素</span>Zrank zset 0 -1 <span class="hljs-comment">#分数最小的元素排名为0</span>Zrevrank zset 0 -1 <span class="hljs-comment">#分数最大的元素排名为0</span>Zinterstore <span class="hljs-comment">#</span>zunionstore rank:last_week 7 rank:20150323 rank:20150324 rank:20150325  weights 1 1 1 1 1 1 1</code></pre><blockquote><p>zset集合的所有元素均 <code>&lt; 64byte</code>，并且<code>数量 &lt; 128</code> 时，使用压缩列表 <code>ZipList</code>，否则使用跳表 <code>SkipList</code></p></blockquote><hr><h4 id="hash扩容：渐进式扩容"><a href="#hash扩容：渐进式扩容" class="headerlink" title="hash扩容：渐进式扩容"></a>hash扩容：渐进式扩容</h4><p>hash字典的初始容量为4（3.2.8版本是这样）</p><p>redis的hash类型在    <strong>元素数量与数组size相同时（且没有在进行bgsave）</strong> 或  <strong>元素数量是数组size的5倍（不论是否在bgsave）</strong>的时候就会开始扩容，新数组的size为元素数量*2。</p><p>redis hash 维护一个rehashidx来表示重新hash的索引，默认值为 -1，如果 &gt;=0 说明开始 rehash 了，则每次对这个hash进行操作的时候将 rehashidx 处的元素进行rehash，当idx进行到最后的时候再置为-1结束扩容。这样在rehash过程中也能正常提供服务。</p><h4 id="hash缩容"><a href="#hash缩容" class="headerlink" title="hash缩容"></a>hash缩容</h4><p>当hash数组中的元素数量所占比例小于负载因子（0.1），不论是否正在bgsave或者bgwriteaof，都会进行缩容</p><hr><h3 id="删除过期key"><a href="#删除过期key" class="headerlink" title="删除过期key"></a>删除过期key</h3><blockquote><p>定期删除+惰性删除</p></blockquote><ul><li><p>定期删除（redis默认100ms）</p><p>redis默认每隔100ms就<strong>随机抽取</strong>一些设置了过期时间的key，检查并删除。</p><blockquote><p>随机抽取的原因：如果key数量巨大，每隔100ms遍历所有设置过期时间的key，可能严重增大CPU的负载。</p></blockquote></li><li><p>惰性删除</p><p>redis的定期删除可能导致一些key没有及时删除。如果一个key已经过期但还留在内存，只有查到了这个key，这个key才会被删除。</p></li></ul><p>如果redis的定期删除漏掉了很多过期的key，并且没有及时查这些key，就会浪费内存。解决这个问题就需要<strong>redis内存淘汰机制</strong>。</p><hr><h3 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h3><blockquote><p> 数据库中有2000w数据，redis中只存20w数据，如何保证redis中的数据是热点数据？</p></blockquote><h4 id="8种数据淘汰策略："><a href="#8种数据淘汰策略：" class="headerlink" title="8种数据淘汰策略："></a>8种数据淘汰策略：</h4><p>当内存不足以容纳新写入数据时，</p><ol><li>volatile-lru   <code>从 已设置ex的数据集中 移除 最近最少使用的key</code></li><li>volatile-random   <code>从 已设置ex的数据集中 移除 随机key</code></li><li>volatile-lfu   <code>从 已设置ex的数据集中 移除 最不经常使用的 key </code></li><li>volatile-ttl   <code>从 已设置ex的数据集中 优先移除有更早过期时间的key </code></li><li>allkeys-lru   <code>从 键空间 移除 最近最少使用的key</code></li><li>allkeys-random   <code>从 键空间 移除 随机key</code></li><li>allkeys-lfu   <code>从 键空间 移除 最不经常使用的 key</code></li><li>no-eviction   <code>禁止淘汰，内存不足直接报错。</code></li></ol><blockquote><p> 注 7、8 为 Redis 4.0 新增。</p><p> <strong>volatile</strong>为前缀的策略都是从<strong>已过期的数据集</strong>中进行淘汰。</p><p> <strong>allkeys</strong>为前缀的策略都是面向<strong>所有key</strong>进行淘汰。</p><p> <strong>LRU</strong>（least recently used）最近最少用到的。</p><p> <strong>LFU</strong>（Least Frequently Used）最不常用的。</p></blockquote><hr><h3 id="持久化机制"><a href="#持久化机制" class="headerlink" title="持久化机制"></a>持久化机制</h3><p>redis支持持久化，这是redis不同于memcached很重要的一点。</p><h4 id="1-快照-snapshotting-（RDB）（默认）"><a href="#1-快照-snapshotting-（RDB）（默认）" class="headerlink" title="1. 快照 snapshotting （RDB）（默认）"></a>1. 快照 snapshotting （RDB）（默认）</h4><p>在redis.conf中有如下配置</p><pre><code class="hljs properties"><span class="hljs-attr">save</span> <span class="hljs-string">900 1#在900s(15min)之后，至少1个key发生变化，自动触发BGSAVE命令创建快照</span><span class="hljs-attr">save</span> <span class="hljs-string">300 10#在300s(5min)之后，至少10个key发生变化，snapshot</span><span class="hljs-attr">save</span> <span class="hljs-string">60 10000#在60s(1min)之后，至少1w个key发生变化，snapshot</span></code></pre><h4 id="2-追加文件-append-only-（AOF）"><a href="#2-追加文件-append-only-（AOF）" class="headerlink" title="2. 追加文件 append-only （AOF）"></a>2. 追加文件 append-only （AOF）</h4><blockquote><p>特点：实时性，数据全</p></blockquote><h5 id="开启AOF"><a href="#开启AOF" class="headerlink" title="开启AOF"></a>开启AOF</h5><p>在redis.conf中配置<code>appendonly yes</code></p><blockquote><p>开启AOF之后，redis会将每条会更改redis中的数据的命令写入硬盘的aof文件，aof文件位置和rdb文件相同，通过dir参数设置，默认文件名是<code>appendonly.aof</code>。</p></blockquote><h5 id="三种不同的AOF方式："><a href="#三种不同的AOF方式：" class="headerlink" title="三种不同的AOF方式："></a>三种不同的AOF方式：</h5><p>在redis.conf中</p><pre><code class="hljs properties"><span class="hljs-attr">appendfsync</span> <span class="hljs-string">always# 每次发生数据修改都会写入AOF，(严重降低redis的速度)</span><span class="hljs-attr">appendfsync</span> <span class="hljs-string">everysec# 每秒同步一次</span><span class="hljs-attr">appendfsync</span> <span class="hljs-string">no# 由操作系统决定何时同步</span></code></pre><h4 id="3-混合持久化-RDB-AOP"><a href="#3-混合持久化-RDB-AOP" class="headerlink" title="3. 混合持久化 RDB+AOP"></a>3. 混合持久化 RDB+AOP</h4><blockquote><p>4.0开始支持， 默认关闭。 通过配置项  <code>aof-use-rdb-preamble</code>  开启。</p></blockquote><p>混合持久化在AOF重写的时候把RDB的内容写入到aof文件的开头。</p><blockquote><p>优点：重启之后恢复加载更快，避免丢失过多数据</p><p>缺点：aof文件中的rdb部分的压缩格式不再是aof格式，可读性差，aof文件可能过大。</p></blockquote><p>在执行GBREWRITEAOF命令时，redis服务器维护一个aof重写缓冲区，并开启一个子进程<strong>重写AOF</strong>，在子进程工作期间，将所有命令记录到缓冲区，当子进程创建完aof文件之后，将缓冲区的内容追加到新aof文件末尾，使新aof文件和数据库状态一致，最后用新aof文件替换旧aof文件。</p><blockquote><p>命令：<code>BGREWRITEAOF</code>  <code>bgrewriteaof</code></p><p>解决AOF文件体积过大的问题，用户可以使用这个命令让redis重写aof文件（手动rewrite）。</p></blockquote><h5 id="重写AOF-压缩AOF：（目的是减小AOF文件体积）（手动触发、自动触发）"><a href="#重写AOF-压缩AOF：（目的是减小AOF文件体积）（手动触发、自动触发）" class="headerlink" title="重写AOF/压缩AOF：（目的是减小AOF文件体积）（手动触发、自动触发）"></a>重写AOF/压缩AOF：（目的是减小AOF文件体积）（手动触发、自动触发）</h5><blockquote><p>aof文件会越来越大，aof重写是<strong>从redis服务器中的数据</strong>转化为写命令存到新的aof文件中，<strong>不会读旧的aof文件</strong>，所以<strong>过期的数据不再写入aof</strong>，<strong>无效的命令不再写入aof</strong>，<strong>多条命令可能合并成一个（注）</strong>。</p><blockquote><p><strong>注</strong></p><p>不过为了<strong>防止单条命令过大</strong>造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令；而是以某个常量为界将命令拆分为多条。这个常量的配置为</p><p><code>define REDIS_AOF_REWRITE_ITEMS_PER_CMD 64</code></p></blockquote></blockquote><h4 id="AOF配置"><a href="#AOF配置" class="headerlink" title="AOF配置"></a>AOF配置</h4><pre><code class="hljs properties"><span class="hljs-comment">#是否开启AOF</span><span class="hljs-attr">appendonly</span> <span class="hljs-string">no </span><span class="hljs-comment">#AOF文件名</span><span class="hljs-attr">appendfilename</span> <span class="hljs-string">&quot;appendonly.aof&quot;</span><span class="hljs-comment">#RDB文件和AOF文件所在目录</span><span class="hljs-attr">dir</span> <span class="hljs-string">./</span><span class="hljs-comment">#fsync持久化策略</span><span class="hljs-attr">appendfsync</span> <span class="hljs-string">everysec</span><span class="hljs-comment">#AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡</span><span class="hljs-meta">no-appendfsync-on-rewrite</span> <span class="hljs-string">no</span><span class="hljs-comment">#如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件</span><span class="hljs-meta">aof-load-truncated</span> <span class="hljs-string">yes</span><span class="hljs-comment">#执行AOF重写时，文件的最小体积，默认值为64MB。文件重写触发条件之一</span><span class="hljs-meta">auto-aof-rewrite-percentage</span> <span class="hljs-string">100</span><span class="hljs-comment">#执行AOF重写时，当前AOF大小(即aof_current_size)和上一次重写时AOF大小(aof_base_size)的比值。文件重写触发条件之一</span><span class="hljs-meta">auto-aof-rewrite-min-size</span> <span class="hljs-string">64mb</span><span class="hljs-comment">#只有当auto-aof-rewrite-min-size和auto-aof-rewrite-percentage两个参数同时满足时，才会自动触发AOF重写，即bgrewriteaof操作。</span></code></pre><hr><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>穿透  <code>同时大量请求一个不存在的key</code></p><blockquote><p>一个<strong>不存在</strong>的key，缓存不会起作用，请求直接打到DB，如果流量大，DB危险</p></blockquote><p>解决方案：</p><blockquote><ol><li><p>严格参数验证。例如id&lt;0直接拦截。</p></li><li><p>如果DB查询key也不存在，就缓存key=null,expires=较短时间。可以防止用这个id反复请求的暴力攻击。</p></li><li><p>根据业务情况，使用<strong>布隆过滤器</strong>，如果key根本不可能存在，直接拦截。</p><p>3+2更安全，因为布隆过滤器有一定误判率，只能说key可能存在。</p></li></ol></blockquote><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>击穿  <code>同时大量请求一个存在但是失效的key，这个key失效</code></p><blockquote><p>一个<strong>存在</strong>的key，在缓存过期的一刻，同时大量请求这个key，这些请求都会打到DB</p></blockquote><p>解决方案：</p><blockquote><ol><li><p>设置热点数据永不过期（因为大量请求说明可能是热点数据）。</p></li><li><p>加锁。</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> V <span class="hljs-title">getData</span><span class="hljs-params">(K key)</span> <span class="hljs-keyword">throws</span> InterruptException </span>&#123;    V v = getDataFromCache(key);    <span class="hljs-keyword">if</span> (v == <span class="hljs-keyword">null</span>)&#123; <span class="hljs-comment">// cache未命中</span>        <span class="hljs-keyword">if</span> (reentrantLock.tryLock())&#123; <span class="hljs-comment">// 获取DB锁，如果能细化到key更好</span>            <span class="hljs-keyword">try</span> &#123;                v = getDataFromDB(key);                <span class="hljs-keyword">if</span> (v != <span class="hljs-keyword">null</span>) &#123; <span class="hljs-comment">// DB中有数据</span>                    setDataToCache(key, v); <span class="hljs-comment">// 同步到cache </span>                &#125; <span class="hljs-keyword">else</span> &#123;                    <span class="hljs-comment">//如果key不存在,并且请求也很多,都走这个同步可能服务超时,不同步可能会缓存穿透,可以在cache设置key=null,expires=30s.</span>                &#125;            &#125; <span class="hljs-keyword">finally</span> &#123; <span class="hljs-comment">// 释放锁</span>                reentrantLock.unlock();            &#125;        &#125; <span class="hljs-keyword">else</span> &#123; <span class="hljs-comment">// 拿不到锁就过一会重新拿</span>            Thread.sleep(<span class="hljs-number">1000</span>);            v = getData(key);        &#125;    &#125;    <span class="hljs-keyword">return</span> v;&#125;</code></pre></li></ol></blockquote><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><blockquote><p>缓存中的数据<strong>同时大面积失效</strong>，就会有大量请求打到数据库</p></blockquote><p>解决方案：</p><blockquote><ol><li>热点数据永不过期</li><li>失效时间设置随机</li></ol></blockquote><p>具体：</p><p>事前：保证redis集群的高可用，发现宕机尽快补。</p><p>事发：本地缓存+hystrix限流&amp;服务降级，保证DB正常运行</p><p>事后：利用持久化机制尽快恢复缓存</p><hr><h3 id="Redis可实现功能"><a href="#Redis可实现功能" class="headerlink" title="Redis可实现功能"></a>Redis可实现功能</h3><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>…</p><h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><p><strong>加锁</strong></p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">tryGetDistributedLock</span><span class="hljs-params">(</span></span><span class="hljs-function"><span class="hljs-params">    String lockKey, String requestId, <span class="hljs-keyword">int</span> expireTime)</span> </span>&#123;String result = jedis.set(        <span class="hljs-comment">// key， value为请求id 解锁还需要这个用这个id， setnx 不存在才set， 失效时间</span>        lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime);    <span class="hljs-keyword">if</span> (LOCK_SUCCESS.equals(result)) &#123;        <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;&#125;</code></pre><p><strong>解锁</strong>：要注意不能释放别人的锁，所以需要CAS操作，这个操作需要利用lua脚本</p><blockquote><p>redis在执行lua脚本相当于执行cpu原语，是个原子操作。  详见 [Lua 脚本 原子执行](#Lua 脚本 原子执行)  </p></blockquote><h5 id="你以为lua脚本就稳了吗？"><a href="#你以为lua脚本就稳了吗？" class="headerlink" title="你以为lua脚本就稳了吗？"></a>你以为lua脚本就稳了吗？</h5><p>Redis 单点的情况确实没问题。</p><p>如果是在<a href="#%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F">哨兵模式</a>中, A 拿到锁 <code>set lockKey lockValue</code>命令只在 master 节点执行完成，还没有同步到 slave 的时候， master 挂了，集群将重新选举 master ， 然后 B 再试图拿锁， 也会成功。  这就出错了…   </p><h5 id="解决-RedLock"><a href="#解决-RedLock" class="headerlink" title="解决 - RedLock"></a>解决 - RedLock</h5><p>redlock算法 ， 用于多个 redis 实例的场景， <a href="https://blog.brickgao.com/2018/05/06/distributed-lock-with-redlock/">https://blog.brickgao.com/2018/05/06/distributed-lock-with-redlock/</a></p><blockquote><p><strong>加锁</strong>：向多半的节点发送 <code>setnx lockKey lockValue</code> 命令， 过半节点成功才算加锁成功</p></blockquote><blockquote><p><strong>解锁</strong>：向全部节点发送 <code>del</code> 命令</p></blockquote><blockquote><p>这是一种基于【大多数都同意】的一种机制      又想起了 paxos？<a href="https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95">https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95</a></p></blockquote><p>已有的 RedLock 开源实现：python: redlock-py，  java: <strong>Redisson</strong></p><h4 id="附近的人-空间搜索"><a href="#附近的人-空间搜索" class="headerlink" title="附近的人-空间搜索"></a>附近的人-空间搜索</h4><p><a href="https://developer.aliyun.com/article/515466">https://developer.aliyun.com/article/515466</a></p><blockquote><p>GeoHash是一种地址编码方式。能够把<strong>二维空间经纬度</strong>数据编码成一个<strong>字符串</strong>。  <strong>redis3.2新增</strong></p><ol><li>字符串越长，表示的范围越精确。编码长度为8时，精度在19米左右，而当编码长度为9时，精度在2米左右。</li><li>字符串相似的表示距离相近，利用字符串的前缀匹配，可以查询附近的地理位置。这样就实现了快速查询某个坐标附近的地理位置。</li><li>geohash计算的字符串，可以反向解码出原来的经纬度。</li></ol><p>当所需存储的对象数量过多时，可通过设置多key(如一个省一个key)的方式对对象集合变相做sharding，避免单集合数量过多。</p><p>Redis内部使用有序集合(zset)保存位置对象，元素的score值为其经纬度对应的52位的geohash值。</p></blockquote><h4 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h4><p><strong>geoadd</strong> key longitude latitude member [longitude latitude member] []…</p><p>添加地理位置，返回integer    [经度 维度 成员]</p><pre><code class="hljs shell">127.0.0.1:6379&gt; geoadd BeiJing-area 116.2161254883 39.8865577059 ShiJingShan 116.1611938477 39.7283134103 FangShan</code></pre><p><strong>geopos</strong> key member [member] []…</p><p>获取地理位置的坐标，可以批量</p><pre><code class="hljs shell">127.0.0.1:6379&gt; geopos Beijing-areas ShiJingShan FangShan1)  1) &quot;116.21612817049026489&quot;2) &quot;39.88655846536294547&quot;2)  1) &quot;116.16119652986526489&quot;2) &quot;39.72831328866426048&quot;</code></pre><p><strong>geodist</strong>  key member1 member2 [unit]</p><p>计算两个位置之间的距离，通过已存在的KEY下的2个位置计算距离，单位的距离有：m米 km千米 mi英里 ft英尺</p><pre><code class="hljs shell">127.0.0.1:6379&gt; geopos Beijing-areas ShiJingShan FangShan km1)  12313123232</code></pre><p><strong>geohash</strong> key member [member] [] …</p><p>该命令返回11个字符的 Geohash 字符串，没有任何精度损失。缩短删除右侧的字符。它会失去精确度，但仍会指向同一区域。</p><pre><code class="hljs shell">127.0.0.1:6379&gt; GEORADIUS Sicily 15 37 200 km WITHCOORD WITHDIST # Sicily[15,37] 半径200km 打印坐标 打印距离1) [&quot;Palermo&quot;,&quot;190.4424&quot;,[&quot;13.361389338970184&quot;,&quot;38.115556395496299&quot;]]</code></pre><p>**georadius ** key [longitude] [latitude] [radius] [m|km|ft|mi] [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]</p><p>当前位置附近的所有位置 georadius</p><pre><code class="hljs accesslog"><span class="hljs-number">127.0.0.1:6379</span>&gt; geopos Beijing-areas ShiJingShan FangShan km<span class="hljs-number">1</span>)  <span class="hljs-number">12313123232</span></code></pre><p>**georadiusbymember ** [key] [member] [半径] [单位]</p><p>显示已添加的某个位置 为中心点的距离多少范围内的信息</p><blockquote><p>**georadiusbymember ** [key] [member] [半径] [单位] COUNT 1 DESC —withcoord(显示经纬度) –withdist(展示距离)</p><p>count 1 desc 展示最近的一个</p></blockquote><pre><code class="hljs shell">127.0.0.1:6379&gt; georadiusbymember beijing shijingshan 50000 m #beijing shijingshan 50km内的所有位置1) &quot;shijingshan&quot;2) &quot;tongzhou&quot;3) &quot;fangshan&quot;4) &quot;daxing&quot;</code></pre><h4 id="签到记录-PV-UV"><a href="#签到记录-PV-UV" class="headerlink" title="签到记录 / PV / UV"></a>签到记录 / PV / UV</h4><h5 id="利用-string-bitmap-结构"><a href="#利用-string-bitmap-结构" class="headerlink" title="利用 string - bitmap 结构"></a>利用 string - bitmap 结构</h5><p><a href="https://oss.redislabs.com/redisbloom/">https://oss.redislabs.com/redisbloom/</a>  这里有一个实现</p><blockquote><p>位图不是实际的数据类型，而是在字符串类型上定义的一组面向位的操作，最大512M，所以最多存储<code>2^32</code>位</p><p>内存占用：(最大偏移量$offset/8/1024/1024)MB        bit-&gt;byte-&gt;kb-&gt;Mb</p></blockquote><p><code>setbit [key] [offset] [value]</code></p><p><code>getbit [key] [offset]</code></p><p><code>bitcount [key]</code></p><p><code>bitop</code></p><blockquote><ul><li><p>用户签到，日期是主维度</p><p>key:<code>prefix_活动名称_日期</code>，offset：<code>用户id</code>，value：<code>是否已签到</code></p><p>用一个bitmap代表一天的签到情况，将用户ID作为偏移量，通过<code>setBit</code>设置该位置的值为1，bitmap的key用<code>prefix+活动名称+时间</code>表示</p><p><code>getBit</code>查询该位置是否为1，代表用户是否签到了</p><p><code>bitCount</code>今日签到数量</p></li><li><p>用户签到，用户是主维度</p><p>key：用户ID，offset：日期，value：是否已签到</p><blockquote><p>这样用户太多，key很多，value倒是没多少位</p></blockquote></li></ul></blockquote><h4 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h4><p>还需要自己准备好点的hash算法</p><p>拓展一下：布谷鸟过滤器 CuckooFilter   <a href="https://juejin.cn/post/6844903861749055502">https://juejin.cn/post/6844903861749055502</a></p><h4 id="做消息队列"><a href="#做消息队列" class="headerlink" title="做消息队列"></a>做消息队列</h4><p>利用list结构，redis本身就提供了 两端的push和pop操作 和 列表的操作 </p><p>和MQ的区别：</p><blockquote><p>api不同；</p><p>redis不能分组，不想kafka可以达到负载均衡的效果</p><p>MQ中 rocketMQ和rabbitMQ满足AMQP，RocketMQ支持事务消息</p><p>毕竟不是消息队列，可靠性啥的一点都没得谈。</p></blockquote><h4 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h4><p>直接自增自减  Semaphore</p><hr><h2 id="集群策略"><a href="#集群策略" class="headerlink" title="集群策略"></a>集群策略</h2><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><p>master可以读、写；   slave只提供读服务，并接受master同步过来的数据。</p><blockquote><p>slave启动之后发送sync请求到master，master在后台保存快照和保存快照期间的命令，发送给slave。</p></blockquote><p>master无需配置，只需修改slave节点的配置：</p><pre><code class="hljs properties"><span class="hljs-attr">slaveof</span> <span class="hljs-string">[masterIP] [masterPort]</span><span class="hljs-attr">masterauth</span> <span class="hljs-string">[masterPassword]</span></code></pre><p>连接成功后可以使用<code>info replication</code>查看其他节点的信息</p><p>如果master宕机，不能自动将slave转换成master，还得手动修改。客户端配置的redis地址可不一定方便修改。</p><h3 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h3><p>哨兵进程<code>sentinel</code>是一个独立的进程，负责监控多个redis实例</p><blockquote><ul><li>sentinel监控master和slave是否正常运行</li><li>master出现故障就将slave转化为master</li><li>多个sentinel互相监控</li><li>只有一个master</li><li>客户端需要连接sentinel集群获取master实例</li></ul></blockquote><p>哨兵配置  sentinel.conf</p><pre><code class="hljs properties"><span class="hljs-comment"># 设置主机名称 地址 端口 选举所需票数</span><span class="hljs-attr">sentinel</span> <span class="hljs-string">monitor [master-name] [ip] [port] [quorum]</span><span class="hljs-comment"># demo</span><span class="hljs-attr">sentinel</span> <span class="hljs-string">monitor mymaster 192.168.0.107 6379 1</span></code></pre><p>启动哨兵节点</p><pre><code class="hljs sh">bin/redis-server etc/sentinel.conf --sentinel &amp;</code></pre><p>查看指定哨兵节点信息</p><pre><code class="hljs sh"><span class="hljs-comment">#可以在任何一台服务器上查看指定哨兵节点信息：</span>bin/redis-cli -h 192.168.0.110 -p 26379 info Sentinel</code></pre><p>故障切换过程</p><blockquote><p>如果被ping的节点超时未回复，哨兵则认为其<strong>主观下线</strong>，如果是master下线，哨兵会询问其他哨兵是否也认为该master<strong>主观下线</strong>，如果达到（配置文件中的）<code>quorum</code>个投票，哨兵会认为该master<strong>客观下线</strong>，并选举出领头哨兵节点，领头哨兵发起故障恢复。</p></blockquote><p>选举领头哨兵 raft算法</p><blockquote><p>发现master下线的A节点向其他哨兵发送消息要求选自己为领头哨兵</p><p>如果目标节点没有选过其他人（没有接收到其他哨兵的相同要求），就选A为领头哨兵</p><p>若<strong>超过一半的哨兵同意</strong>选A为领头，则A当选</p><p>如果多个哨兵同时参与了领头，可能一轮投票无人当选，A就会等待随机事件后再次发起请求</p><blockquote><p>选出新master之后，会发送消息到其他slave使其接受新master，最后更新数据。</p><p>已停止的旧master会降为slave，恢复服务之后继续运行。</p></blockquote></blockquote><p>领头哨兵挑选新master的规则</p><blockquote><p>优先级最高（slave-priority配置）；复制偏移量最大；id最小</p></blockquote><h3 id="Cluster集群-☆"><a href="#Cluster集群-☆" class="headerlink" title="Cluster集群 ☆"></a>Cluster集群 ☆</h3><p>为了保证高可用，使用主从模式。master宕机就启用slave。如果一个节点的主从都宕机，则集群不可用。</p><blockquote><p>多个master(最少3个)，  多个slaver</p></blockquote><p>配置 redis.conf</p><pre><code class="hljs properties"><span class="hljs-comment">#开启cluster模式</span><span class="hljs-meta">cluster-enable</span> <span class="hljs-string">yes</span><span class="hljs-comment">#集群模式下的集群配置文件</span><span class="hljs-meta">cluster-config-file</span> <span class="hljs-string">nodes-6379.conf</span><span class="hljs-comment">#集群内节点之间最长响应时间  默认15s 关系到集群节点通信占用的带宽</span><span class="hljs-meta">cluster-node-timeout</span> <span class="hljs-string">15000</span><span class="hljs-comment"># 还会在加一个端口号用来集群之间节点的通讯  6379+10000  16379</span></code></pre><p>启动集群 (需要Ruby版本 &gt; 2.2)</p><blockquote><p><code>redis-trib.rb create --replicas 1 [ip]:6380 [...] [ip]:6381 [ip]:6385 </code></p></blockquote><p>查看集群中的节点</p><pre><code class="hljs sh">[root@buke107 src]\<span class="hljs-comment"># redis-cli -c -h 192.168.0.107 -p 6381 # 连接任一节点</span>192.168.0.107:6381&gt; cluster nodes <span class="hljs-comment"># 查看集群节点</span><span class="hljs-comment"># nodeId | ip:port | nodeType | masterId | 0？ | ？ | 连接数 | 节点对应的槽位slots(master节点才有)</span>868456121fa4e6c8e7abe235a88b51d354a944b5 192.168.0.107:6382 master - 0 1523609792598 3 connected 10923-16383d6d01fd8f1e5b9f8fc0c748e08248a358da3638d 192.168.0.107:6385 slave 868456121fa4e6c8e7abe235a88b51d354a944b5 0 1523609795616 6 connected5cd3ed3a84ead41a765abd3781b98950d452c958 192.168.0.107:6380 master - 0 1523609794610 1 connected 0-5460b8e047aeacb9398c3f58f96d0602efbbea2078e2 192.168.0.107:6383 slave 5cd3ed3a84ead41a765abd3781b98950d452c958 0 1523609797629 1 connected68cf66359318b26df16ebf95ba0c00d9f6b2c63e 192.168.0.107:6384 slave 90b4b326d579f9b5e181e3df95578bceba29b204 0 1523609796622 5 connected90b4b326d579f9b5e181e3df95578bceba29b204 192.168.0.107:6381 myself,master - 0 0 2 connected 5461-10922<span class="hljs-comment"># 节点类型还会展示的信息  myself:当前节点   fail:节点下线</span></code></pre><p>关于cluster的其他操作:   <a href="https://www.cnblogs.com/kevingrace/p/7910692.html">https://www.cnblogs.com/kevingrace/p/7910692.html</a></p><blockquote><p><code>添加主/从节点</code>、<code>重新分配slot</code>、<code>查看集群状态信息</code>、<code>改变slave的master</code>、<code>删除主/从节点</code></p><p><code>复制迁移</code>(登录到slave并更换其follow的master)、<code>cluster集群节点升级</code>(升级redis版本)</p><p><code>缓存清理</code>(在集群中删除指定的key需要链接到对应的节点…)，节点太多就用脚本吧</p><blockquote><p>查看cluster信息找到所有master</p><p>遍历master（连接该master，执行del key）直到del成功，结束遍历</p><p><code>再搜吧...</code></p></blockquote></blockquote><h4 id="工作机制-原理"><a href="#工作机制-原理" class="headerlink" title="工作机制 原理"></a>工作机制 原理</h4><p>先了解一下分布式数据分布方案。</p><blockquote><p>分布式 数据分布方案(寻址算法)：</p><ul><li><p>节点取余</p><p>根据数据(或数据的某一特征)计算hash并取余节点数量得到数据所在位置，比如Java的HashMap(强行举例…)。</p><blockquote><p>缺点：当节点数量变化(扩容/缩容)时，数据节点映射关系需要重新计算，会导致大量数据的迁移(HashMap优化：翻倍扩容，可以使数据迁移从80%降到50%)</p></blockquote></li><li><p>一致性哈希</p><p>指定范围内（比如0-2^32^）所有数字首尾相连形成一个哈希环，并为每个节点分配一个该范围内的值，寻址时计算key的hash值，然后在环上找到第一个<code>token &gt;= hash(key)</code>的节点。</p><blockquote><p>优点：节点数量变化时，只影响（相邻的）一个节点。</p><p>缺点：很可能会分布不均匀（负载不均衡）</p></blockquote></li><li><p>虚拟槽分区（<strong>cluster采用</strong>）</p><p>用hash函数把数据分散到<strong>固定范围</strong>内的整数集合中，每个整数定义为槽<code>slot</code>。</p><p>slot数量远大于节点数，每个节点负责一部分slot，这样更方便数据的拆分和集群扩容（增加节点）</p><blockquote><p>与一致性哈希的不同：</p><blockquote><p>一致性哈希直接根据数据的hash值找对应的节点；</p><p>虚拟槽分区是先根据数据的hash找到节点，再去该节点进行操作。</p></blockquote></blockquote><blockquote><p>优点：</p><ul><li>节点负载均衡</li><li>解耦数据和节点的关系，方便数据的拆分和集群扩容；</li><li>节点自身维护节点和slot的映射关系，无需客户端运算；</li></ul></blockquote><img alt="redis cluster slots" src="https://raw.githubusercontent.com/melopoz/pics/master/img/redis%20cluster%20slots.png" style="zoom:40%;" /></li></ul><p>数据分布存储的集群模式<strong>都</strong>会有的缺点：</p><ul><li>key批量操作受限。mset、mget等操作，key可能存在于多个节点上，所以不可用(报错)；(<a href="#%E9%9B%86%E7%BE%A4%E5%B0%8F%E6%8A%80%E5%B7%A7">集群小技巧</a>可以解决)</li><li>key事务操作受限。伪事务，本来也不用…；</li><li>不支持多数据库。（本来也鸡肋）单机redis可支持16个数据库，集群模式下只能使用一个数据库空间，即db0。</li></ul><p>还有一些不算缺点，算是不足之处的</p><ul><li>key作为数据的最小粒度，可能value还是比较大，集群也无法将一个大的键值对象（如hash、list等）映射到不同的节点。</li></ul></blockquote><p>redis cluster 的数据分布方案采用的是<code>虚拟槽分区(16384个slot)</code>方案（+虚拟节点）</p><p>所以 redis cluster 的节点处理请求会先计算key对应的slot</p><ul><li>如果对应的节点是自身，直接执行命令并返回结果；</li><li>否则返回<code>MOVED重定向错误</code>通知客户端访问正确的节点（<code>MOVED</code>带有key所在slot信息 和 对应节点的地址信息）。</li></ul><p>客户端收到<code>MOVED</code>再去对应的节点请求执行。</p><blockquote><p>连接集群的客户端需要处理<code>MOVED</code>命令，比如使用redis-cli连接集群需要加参数 <code>-c</code>，<code>redis-cli -c -p 7001</code>；或者用Redisson</p></blockquote><h5 id="集群内节点通信"><a href="#集群内节点通信" class="headerlink" title="集群内节点通信"></a>集群内节点通信</h5><blockquote><p>Redis Cluster 采用P2P的<code>Gossip</code>(流言/八卦)协议，原理就是：节点彼此不断交换信息，一段时间后所有节点都会知道集群所有节点的信息。</p></blockquote><p>集群内节点的通信的消息头都是使用的<code>clusterMsg</code>这个结构（下边有源码），包含id、myslots、消息类型、节点标识等等。</p><h6 id="Gossip消息类型"><a href="#Gossip消息类型" class="headerlink" title="Gossip消息类型"></a>Gossip消息类型</h6><ul><li>meet：<code>通知新节点加入</code>（“加入我们吧”），meet通信完成后，接收方会周期进行ping-pong；</li><li>ping：每秒发送给多个其他节点，用于<code>检测节点是否在线并进行信息交换</code>，封装了<code>自身和部分其他节点的状态数据</code>；</li><li>pong：回应<code>meet</code>和<code>ping</code>，封装了<code>自己的状态数据</code>。也可用来向集群广播自己的状态信息来<code>通知整个集群更新&quot;我&quot;的状态</code>。</li><li>fail：（”xx下线了”）判断集群内另一个节点下线后，就广播fail消息，接收方把该节点的状态置为下线。</li></ul><blockquote><p>Gossip特点：</p><p>扩展性：节点可任意增减，状态信息最终都会和其他节点同步；</p><p>最终一致性：只保证最终一致性</p><p>容错性：每个节点都有数据，宕机一部分也没事</p><p>健壮性：去中心化，每个节点都有持有数据</p></blockquote><h6 id="Redis-Cluster-消息-数据结构"><a href="#Redis-Cluster-消息-数据结构" class="headerlink" title="Redis Cluster 消息 数据结构"></a>Redis Cluster 消息 数据结构</h6><p>消息头：clusterMsgData + <a href="#redis%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF16384%E4%B8%AA%E6%A7%BD">redis为什么是16384个槽</a> 里边的源码</p><p>消息体：meet、ping、pong等类型的消息采用MsgDataGossip数组作为消息体。</p><h6 id="发送消息的规则"><a href="#发送消息的规则" class="headerlink" title="发送消息的规则"></a>发送消息的规则</h6><ul><li>每秒随机选取5个节点，找出其中最久没有通信的节点发送ping消息  ——1个</li><li>每100毫秒(1秒10次)都会扫描本地节点列表，如果发现节点最近一次接受pong消息的时间大于<code>cluster-node-timeout / 2</code>则立刻发送ping消息</li></ul><p>所以每个节点每秒需要发送ping消息的数量 = <code>1 + 10 * num (node.pong_received &gt; cluster_node_timeout / 2)</code></p><blockquote><p><code>node</code>：本地节点列表的每个节点</p><p><code>node.pong_received</code>：上次收到<code>该node</code>的<code>pong</code>消息已经过去多久</p><p><code>cluster_node_timeout</code>：配置节点超时时间，默认 <code>15s</code> </p><blockquote><p>当我们的带宽资源紧张时，可以适当调大这个参数，如从默认15秒改为30秒来降低集群通信的带宽占用率。</p><p>调得太大了也不行，会影响消息交换的频率，从而影响<code>故障转移</code>、<code>槽信息更新</code>、<code>新节点发现的速度</code>。</p><p>需要根据业务容忍度和资源消耗进行平衡，节点数越多集群的总消息量就越大。<a href="#redis%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF16384%E4%B8%AA%E6%A7%BD">redis为什么是16384个槽</a></p></blockquote></blockquote><p>ps: 集群中的每个节点都会单独开辟一个TCP通道用于节点之间彼此通信，通信端口号 = 基础端口 + 10000，比如16379</p><h4 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h4><p>rehash重新分片，每增加一个节点只会影响到一个旧节点，就是从旧节点上分一些slot到新节点。</p><p>是通过<code>redis-trib</code>命令来实现。</p><p><code>redis-trib.rb</code>，这个Ruby脚本 就129行代码，可以看看。。<a href="https://github.com/redis/redis/blob/unstable/src/redis-trib.rb">https://github.com/redis/redis/blob/unstable/src/redis-trib.rb</a></p><h4 id="集群高可用-amp-故障转移-amp-新master选举"><a href="#集群高可用-amp-故障转移-amp-新master选举" class="headerlink" title="集群高可用 &amp; 故障转移 &amp; 新master选举"></a>集群高可用 &amp; 故障转移 &amp; 新master选举</h4><p>Cluster保证集群高可用和Sentinel类似。</p><p>某节点认为<code>master1</code>宕机，就会广播<code>fail</code>消息，此时<code>master1</code>是主观宕机状态，如果集群内<code>超过半数节点</code>都认为<code>master1</code>主观宕机，就会标记<code>master1</code>为客观宕机。</p><p>然后就要开始进行故障转移：</p><p>集群中<code>正常的master</code>进行投票，从<code>master1</code>的<code>slave</code>中选出一个，当某个slave获得了<code>半数以上的选票</code>，升为master。</p><p>新master会<code>停止复制master1</code>节点，并将<code>master1负责的所有slot</code>分配给自己，然后广播<code>pong</code>消息。</p><h4 id="集群小技巧-amp-优化点"><a href="#集群小技巧-amp-优化点" class="headerlink" title="集群小技巧 &amp; 优化点"></a>集群小技巧 &amp; 优化点</h4><ul><li><p>hash_tag：一举两得  （注意不要过度使用，<a href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C">数据倾斜</a>）</p><ul><li>可以利用{}给不同的key命名，以达到不同的key对应相同的槽的效果，这样还可以在集群中会用mget，mset等命令，（否则报错）</li><li>Redis IO 优化：Pipeline</li></ul><blockquote><p>redis计算槽的时候如果key的内容有<code>&#123;...&#125;</code>，会使用<code>&#123;&#125;</code>里边的内容，这里<code>...</code>称为<code>hash_tag</code>，可以让不同的key映射到相同的slot。</p><pre><code class="hljs c"><span class="hljs-function">def <span class="hljs-title">key_hash_slot</span><span class="hljs-params">(key)</span>:</span><span class="hljs-function">    <span class="hljs-keyword">int</span> keylen </span>= key.length();    <span class="hljs-keyword">for</span> (s = <span class="hljs-number">0</span>; s &lt; keylen; s++):        <span class="hljs-keyword">if</span> (key[s] == <span class="hljs-string">&#x27;&#123;&#x27;</span>):            <span class="hljs-keyword">break</span>;        <span class="hljs-keyword">if</span> (s == keylen) <span class="hljs-keyword">return</span> crc16(key,keylen) &amp; <span class="hljs-number">16383</span>;        <span class="hljs-keyword">for</span> (e = s+<span class="hljs-number">1</span>; e &lt; keylen; e++):            <span class="hljs-keyword">if</span> (key[e] == <span class="hljs-string">&#x27;&#125;&#x27;</span>) <span class="hljs-keyword">break</span>;            <span class="hljs-keyword">if</span> (e == keylen || e == s+<span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> crc16(key,keylen) &amp; <span class="hljs-number">16383</span>;    <span class="hljs-comment">/* 使用&#123;和&#125;之间的有效部分计算槽 */</span>    <span class="hljs-keyword">return</span> crc16(key+s+<span class="hljs-number">1</span>,e-s<span class="hljs-number">-1</span>) &amp; <span class="hljs-number">16383</span>;</code></pre><p>由于Pipeline只能向一个节点批量发送执行命令，相同的hash_tag对应相同的slot，而相同slot必然会对应到唯一的节点</p><p>这样一来….不就可以用pipeline了嘛</p></blockquote></li></ul><h4 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h4><h5 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h5><ul><li>节点和槽的分配不均【不常见】 ，可以使用redis-trib.rb rebalance命令进行平衡；</li><li>不同槽对应键数量差异过大。注意不能过度使用hashtag；</li><li>可能包含big key，一般不能有太大的key ，需要找到大集合后根据业务场景进行拆分</li></ul><h5 id="请求倾斜"><a href="#请求倾斜" class="headerlink" title="请求倾斜"></a>请求倾斜</h5><blockquote><p>集群内特定节点请求量 / 流量过大 导致节点之间负载不均</p></blockquote><p>对于热点key: 避免bigkey ,不要使用hash_tag，本地缓存+MQ</p><h5 id="redis为什么是16384个槽"><a href="#redis为什么是16384个槽" class="headerlink" title="redis为什么是16384个槽"></a>redis为什么是16384个槽</h5><blockquote><ol><li><p>正常的心跳包携带一个节点的全部配置信息，其中就包含<code>myslots</code>信息，16384bit = 2048byte  2k了，如果用65536bit的话，就需要8k</p></li><li><p>集群是每秒ping-pong，一旦集群的节点数量多了就会占用大量带宽</p><blockquote><p>集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。</p><p>因此，redis作者不建议redis cluster节点数量超过1000个。而对于节点数在1000以内的redis cluster集群，16384个槽位够用了。</p></blockquote></li><li><p>槽位越小，节点少的情况下，压缩比高</p><blockquote><p>Redis Cluster master的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的。</p><p>在传输过程中，会对bitmap进行压缩，如果bitmap的填充率slots / N很高的话(N表示集群节点总数)，bitmap的压缩率就会变低。</p><p>如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。</p></blockquote></li></ol><p>再<code>考虑到负载均衡和扩展，槽位也不能太少</code>，折中考虑，作者决定取16384个槽</p><p>消息头的源码：</p><pre><code class="hljs c"><span class="hljs-comment">// https://github.com/redis/redis/blob/unstable/src/cluster.h</span><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> CLUSTER_SLOTS 16384  <span class="hljs-comment">// 这里声明常量</span></span><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span>    <span class="hljs-keyword">char</span> sig[<span class="hljs-number">4</span>];        <span class="hljs-comment">/* Signature &quot;RCmb&quot; (Redis Cluster message bus). 消息总线*/</span>    <span class="hljs-keyword">uint32_t</span> totlen;    <span class="hljs-comment">/* Total length of this message 消息总长度*/</span>    <span class="hljs-keyword">uint16_t</span> ver;       <span class="hljs-comment">/* Protocol version, currently set to 1. 协议版本号*/</span>    <span class="hljs-keyword">uint16_t</span> port;      <span class="hljs-comment">/* TCP base port number. */</span>    <span class="hljs-keyword">uint16_t</span> type;      <span class="hljs-comment">/* Message type 消息类型：meet、ping、pong*/</span>    <span class="hljs-keyword">uint16_t</span> count;     <span class="hljs-comment">/* Only used for some kind of messages. 某些信息会用...*/</span>    <span class="hljs-keyword">uint64_t</span> currentEpoch;  <span class="hljs-comment">/* The epoch accordingly to the sending node. */</span>    <span class="hljs-keyword">uint64_t</span> configEpoch;   <span class="hljs-comment">/* The config epoch if it&#x27;s a master, or the last</span><span class="hljs-comment">                               epoch advertised by its master if it is a</span><span class="hljs-comment">                               slave. */</span>    <span class="hljs-keyword">uint64_t</span> offset;    <span class="hljs-comment">/* Master replication offset if node is a master or 主节点的已复制偏移量 或</span><span class="hljs-comment">                           processed replication offset if node is a slave. 从节点已处理的复制偏移量 */</span>    <span class="hljs-keyword">char</span> sender[CLUSTER_NAMELEN]; <span class="hljs-comment">/* Name of the sender node 发送者name*/</span>    <span class="hljs-comment">// 这里这里这里！！！</span>    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> myslots[CLUSTER_SLOTS/<span class="hljs-number">8</span>]; <span class="hljs-comment">// 发送节点负责的slot，这个数组大小是16384/8=2048 byte，2kb</span>    <span class="hljs-keyword">char</span> slaveof[CLUSTER_NAMELEN];    <span class="hljs-keyword">char</span> myip[NET_IP_STR_LEN];    <span class="hljs-comment">/* Sender IP, if not all zeroed. 不全为0就是发送方的ip*/</span>    <span class="hljs-keyword">char</span> notused1[<span class="hljs-number">34</span>];  <span class="hljs-comment">/* 34 bytes reserved for future usage. 保留字节*/</span>    <span class="hljs-keyword">uint16_t</span> cport;      <span class="hljs-comment">/* Sender TCP cluster bus port 发送方tcp总线端口*/</span>    <span class="hljs-keyword">uint16_t</span> flags;      <span class="hljs-comment">/* Sender node flags 发送方的flags 这里这里这里！！！*/</span>    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> state; <span class="hljs-comment">/* Cluster state from the POV of the sender */</span>    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> mflags[<span class="hljs-number">3</span>]; <span class="hljs-comment">/* Message flags: CLUSTERMSG_FLAG[012]_... */</span>    <span class="hljs-class"><span class="hljs-keyword">union</span> <span class="hljs-title">clusterMsgData</span> <span class="hljs-title">data</span>;</span>&#125; clusterMsg;</code></pre><p>消息体的源码：</p><pre><code class="hljs plain">。。算了哥  下次一定</code></pre><pre><code class="hljs c"><span class="hljs-comment">// https://github.com/redis/redis/blob/unstable/src/cluster.h </span><span class="hljs-comment">// 特么太多了</span>clusterMsgDataGossipclusterMsgData 消息体</code></pre></blockquote><h1 id="redis源码"><a href="#redis源码" class="headerlink" title="redis源码"></a>redis源码</h1><table><thead><tr><th>src文件名</th><th>干啥的</th></tr></thead><tbody><tr><td>ae.c 、 ae.h 、 ae_epoll.c 、 ae_evport.c 、 ae_kqueue.c 、 ae_select.c</td><td>事件处理器，以及各个具体实现。</td></tr><tr><td>redis.h</td><td>Redis 的主要头文件，记录了 Redis 中的大部分数据结构， 包括服务器状态和客户端状态。</td></tr><tr><td>zmalloc.c 、 zmalloc.h</td><td>内存管理程序。</td></tr><tr><td>sds.c 、 sds.h</td><td>SDS 数据结构的实现，SDS 为 Redis 的默认字符串表示。</td></tr><tr><td>adlist.c 、 adlist.h</td><td>双端链表数据结构的实现。</td></tr><tr><td>dict.c 、 dict.h</td><td>字典数据结构的实现</td></tr><tr><td>bio.c 、 bio.h</td><td>Redis 的后台 I/O 程序，用于将 I/O 操作放到子线程里面执行， 减少 I/O 操作对主线程的阻塞。</td></tr><tr><td>rdb.c 、 rdb.h</td><td>RDB 持久化功能的实现。</td></tr><tr><td>aof.c</td><td>AOF 功能的实现。</td></tr><tr><td>cluster.c 、 cluster.h</td><td>Redis Cluster 的集群实现。</td></tr><tr><td>sentinel.c</td><td>Redis Sentinel 的实现。</td></tr><tr><td>crc16.c 、 crc64.c 、 crc64.h</td><td>计算 CRC 校验和。 crc16算法</td></tr><tr><td>redis-trib.rb</td><td>Redis 集群的管理程序。Ruby脚本</td></tr></tbody></table><h1 id="Lua-脚本-原子执行"><a href="#Lua-脚本-原子执行" class="headerlink" title="Lua 脚本 原子执行"></a>Lua 脚本 原子执行</h1><p>Lua 脚本在 Redis 中是原子执行的，Redis 在执行<code>EVAL</code>命令的时候，一直到执行完毕并返回结果之前，会阻塞所有其他客户端的命令，所以Lua脚本中要写逻辑特别复杂的脚本， 必须保证 Lua 脚本的效率。</p><h4 id="SCRIPT-LOAD"><a href="#SCRIPT-LOAD" class="headerlink" title="SCRIPT LOAD"></a>SCRIPT LOAD</h4><p>加载脚本到缓存，以复用</p><pre><code class="hljs jboss-cli"><span class="hljs-string">...</span><span class="hljs-function">:6379</span>&gt; SCRIPT LOAD <span class="hljs-string">&quot;return &#x27;abc&#x27;&quot;</span>“1b936e3fe509bcbc9<span class="hljs-keyword">cd</span>0664897bbe8fd0cac101b”<span class="hljs-string">...</span><span class="hljs-function">:6379</span>&gt; EVALSHA 1b936e3fe509bcbc9<span class="hljs-keyword">cd</span>0664897bbe8fd0cac101b 0<span class="hljs-string">&quot;abc&quot;</span></code></pre><h4 id="SCRIPT-FLUSH"><a href="#SCRIPT-FLUSH" class="headerlink" title="SCRIPT FLUSH"></a>SCRIPT FLUSH</h4><p>清除所有缓存， 不能筛选， 只能全删</p><h4 id="SCRIPT-EXISTS"><a href="#SCRIPT-EXISTS" class="headerlink" title="SCRIPT EXISTS"></a>SCRIPT EXISTS</h4><pre><code class="hljs jboss-cli"><span class="hljs-string">...</span><span class="hljs-function">:6379</span>&gt; SCRIPT EXISTS 1b936e3fe509bcbc9<span class="hljs-keyword">cd</span>0664897bbe8fd0cac101b  1b936e3fe509bcbc9<span class="hljs-keyword">cd</span>0664897bbe8fd0cac10121) <span class="hljs-params">(integer)</span> 12) <span class="hljs-params">(integer)</span> 0</code></pre><h4 id="SCRIPT-KILL"><a href="#SCRIPT-KILL" class="headerlink" title="SCRIPT KILL"></a>SCRIPT KILL</h4><p>终止正在执行的脚本，如果脚本中已经执行了一部分写命令，则 kill 命令无效</p><p>若不对数据进行持久化， 可通过 shutdown nosave 来终止脚本…</p><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><ul><li>Lua 脚本执行异常也不会回滚， 所以脚本逻辑要有较高的健壮性</li><li>Lua 脚本执行是原子性的，会阻塞其他客户端的命令，所有效率要高</li><li>在集群中使用 Lua 脚本的话要确保脚本中用到的 key 都在相同机器(相同的插槽slot)中，可用 Redis Hash Tags 技术</li><li>不要在脚本中用全局变量， 局部变量效率会高</li></ul><h5 id="Lua脚本-释放锁"><a href="#Lua脚本-释放锁" class="headerlink" title="Lua脚本 释放锁"></a>Lua脚本 释放锁</h5><pre><code class="hljs lua"><span class="hljs-keyword">if</span> redis.call(<span class="hljs-string">&#x27;get&#x27;</span>, KEYS[<span class="hljs-number">1</span>]) == ARGV[<span class="hljs-number">1</span>]     <span class="hljs-keyword">then</span>     <span class="hljs-keyword">return</span> redis.call(<span class="hljs-string">&#x27;del&#x27;</span>, KEYS[<span class="hljs-number">1</span>]) <span class="hljs-keyword">else</span>     <span class="hljs-keyword">return</span> <span class="hljs-number">0</span> <span class="hljs-keyword">end</span></code></pre><h5 id="java实现"><a href="#java实现" class="headerlink" title="java实现"></a>java实现</h5><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> Long lockReleaseOK = <span class="hljs-number">1L</span>;<span class="hljs-comment">// lua脚本，用来释放分布式锁</span><span class="hljs-keyword">static</span> String luaScript = <span class="hljs-string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;,KEYS[1]) else return 0 end&quot;</span>; <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">releaseLock</span><span class="hljs-params">(String key ,String lockValue)</span></span>&#123;<span class="hljs-keyword">if</span>(key == <span class="hljs-keyword">null</span> || lockValue == <span class="hljs-keyword">null</span>) &#123;<span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;&#125;<span class="hljs-keyword">try</span> &#123;Jedis jedis = getJedisPool().getResource();Object res =jedis.eval(luaScript,Collections.singletonList(key),Collections.singletonList(lockValue));jedis.close();<span class="hljs-keyword">return</span> res!=<span class="hljs-keyword">null</span> &amp;&amp; res.equals(lockReleaseOK);&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;&#125;&#125;</code></pre><h1 id="一些小坑"><a href="#一些小坑" class="headerlink" title="一些小坑"></a>一些小坑</h1><pre><code class="hljs java"><span class="hljs-comment">// 错误用法 .. 第三个参数不是timeout...</span>stringRedisTemplate.opsForValue().set(<span class="hljs-string">&quot;hashkey:key1&quot;</span>,<span class="hljs-string">&quot;value&quot;</span>,<span class="hljs-number">60</span>*<span class="hljs-number">60</span>*<span class="hljs-number">1000</span>);<span class="hljs-comment">// api源码</span><span class="hljs-meta">@Override</span><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">set</span><span class="hljs-params">(K key, V value, <span class="hljs-keyword">long</span> offset)</span> </span>&#123;    <span class="hljs-keyword">byte</span>[] rawKey = rawKey(key);    <span class="hljs-keyword">byte</span>[] rawValue = rawValue(value);    execute(connection -&gt; &#123;        connection.setRange(rawKey, rawValue, offset);<span class="hljs-comment">// 用指定的字符串覆盖给定key所储存的字符串值，覆盖的位置从偏移量offset开始</span>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;    &#125;, <span class="hljs-keyword">true</span>);&#125;<span class="hljs-comment">// 正确用法：（key, value, offset, timeout）</span>stringRedisTemplate.opsForValue().set(<span class="hljs-string">&quot;hashkey:key1&quot;</span>,<span class="hljs-string">&quot;value&quot;</span>,<span class="hljs-number">60</span>*<span class="hljs-number">60</span>*<span class="hljs-number">1000</span>,TimeUnit.MILLISECONDS);</code></pre><img alt="redisTemplate.opsForValue().set(k, v, offset)" src="https://raw.githubusercontent.com/melopoz/pics/master/img/20210330005146.png" style="zoom:50%;" />]]></content>
    
    
    <categories>
      
      <category>NoSQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>位图</tag>
      
      <tag>缓存</tag>
      
      <tag>分布式锁</tag>
      
      <tag>一致性hash+虚拟槽slot</tag>
      
      <tag>选举策略</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HashMap &amp; ConcurrentHashMap</title>
    <link href="/blog/2021/01/01/Java_HashMap&amp;ConcurrentHashMap/"/>
    <url>/blog/2021/01/01/Java_HashMap&amp;ConcurrentHashMap/</url>
    
    <content type="html"><![CDATA[<h1 id="java-util-Map"><a href="#java-util-Map" class="headerlink" title="java.util.Map"></a>java.util.Map</h1><img alt="Map接口结构，图在github" src="https://raw.githubusercontent.com/melopoz/pics/master/img/java-util-map.png" style="zoom:50%;" /><h2 id="常用实现"><a href="#常用实现" class="headerlink" title="常用实现"></a>常用实现</h2><ol><li><p>HashMap</p><p>根据hashCode存储数据，访问速度快，遍历顺序不确定，允许一个key为null，允许任意value为null，非线程安全，同一时刻多个线程同时对一个hashMap进行put，可能会导致数据不一致。</p><blockquote><p>可用Collections#synchronizedMap方法得到一个线程安全的map（该类直接是对map对象加锁）或者用ConcurrentHashMap</p></blockquote></li><li><p>HashTable</p><p>遗留类，不建议用，一般也不用这玩意了。常用功能和HashMap类似，不过HashTable是<code>extends Dictionary implements Map</code>，线程安全，但并发性不如ConcurrentHashMap，他的方法都是synchronized的。</p></li><li><p>LinkedHashMap</p><p>继承自HashMap，记录了key的插入顺序</p><blockquote><p>accessOrder参数：默认false，是根据第一次插入该key的顺序排序；true：每次访问都更新排序，也就是get(k)、再put(k,v)都会将k放到最后。</p></blockquote></li><li><p>TreeMap</p><p>实现NavigableMap接口(navigable:可导航的)，NavigableMap继承SortedMap接口。</p><p>红黑树结构，Entry根据key排序，默认按照key升序排序，也可以在构造函数中指定用于排序的比较器Comparator。</p><blockquote><p>使用TreeMap时，key必须实现Comparable接口或者在TreeMap的构造函数中传入自定义的Comparator，否则运行时会throw ClassCastException。</p></blockquote></li></ol><h2 id="HashMap内部实现"><a href="#HashMap内部实现" class="headerlink" title="HashMap内部实现"></a>HashMap内部实现</h2><h3 id="数据结构-amp-属性"><a href="#数据结构-amp-属性" class="headerlink" title="数据结构 &amp; 属性"></a>数据结构 &amp; 属性</h3><p>数组 + 链表 / 红黑树(1.8增加红黑树)</p><img alt="HashMap数据结构，图在github" src="https://raw.githubusercontent.com/melopoz/pics/master/img/HashMap%E7%BB%93%E6%9E%84.png" style="zoom:50%;" /><h4 id="hash数组：Node-lt-K-V-gt-table"><a href="#hash数组：Node-lt-K-V-gt-table" class="headerlink" title="hash数组：Node&lt;K, V&gt;[] table"></a>hash数组：<code>Node&lt;K, V&gt;[] table</code></h4><p>哈希桶数组，每个元素都是一个键值对：<code>Node&lt;K,V&gt; implements Map.Entry</code>。并维护下一个节点的引用<code>next</code>。</p><pre><code class="hljs java"><span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Node</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title">Map</span>.<span class="hljs-title">Entry</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; </span>&#123;    <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> hash;    <span class="hljs-keyword">final</span> K key;    V value;    Node&lt;K,V&gt; next;    Node(<span class="hljs-keyword">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123;        <span class="hljs-keyword">this</span>.hash = hash;        <span class="hljs-keyword">this</span>.key = key;        <span class="hljs-keyword">this</span>.value = value;        <span class="hljs-keyword">this</span>.next = next;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> K <span class="hljs-title">getKey</span><span class="hljs-params">()</span>        </span>&#123; <span class="hljs-keyword">return</span> key; &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> V <span class="hljs-title">getValue</span><span class="hljs-params">()</span>      </span>&#123; <span class="hljs-keyword">return</span> value; &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> String <span class="hljs-title">toString</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> key + <span class="hljs-string">&quot;=&quot;</span> + value; &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> <span class="hljs-title">hashCode</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-comment">// hashCode函数如果参数是null，都返回0，所以key=null的都是存到table[0]</span>        <span class="hljs-keyword">return</span> Objects.hashCode(key) ^ Objects.hashCode(value);    &#125;    ...&#125;</code></pre><blockquote><p>hash可能会冲突，可以采用开放地址法、链地址法。HashMap采用链地址法。</p><blockquote><p>开放地址法：每当目标位置不是空的，就向下寻找(index+1)，直到找到空位置。</p></blockquote><p>数组size小了，再好的hash函数也会很容易冲突，这种结构必然要权衡空间成本和时间成本，需要用好的hash算法和扩容机制来让table占据空间小，又不容易发生hash碰撞。</p></blockquote><h4 id="数组容量：table-length-默认16"><a href="#数组容量：table-length-默认16" class="headerlink" title="数组容量：table.length 默认16"></a>数组容量：table.length 默认16</h4><p>负载因子<code>loadFactor</code>默认为<code>0.75</code></p><p>阈值<code>threshold</code> = <code>length * loadFactor</code>，table中的元素个数超过threshold之后就要扩容<code>resize()</code>。</p><blockquote><p>时间效率要求极高就<strong>减小threshold</strong>，容量大了hash冲突就少了，时间复杂度更趋向于O(1)；</p><p>内存紧张就<strong>调大threshold</strong>，减少table使用的空间。</p></blockquote><h4 id="table-length-必须为2的n次方"><a href="#table-length-必须为2的n次方" class="headerlink" title="table.length 必须为2的n次方"></a>table.length 必须为2的n次方</h4><p>扩容(resize)就 *2，<strong>也是1.8HashMap的一个优化</strong>。更多见下文<a href="#%E7%A1%AE%E5%AE%9Anode%E5%9C%A8table%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95%E4%BD%8D%E7%BD%AE"><strong>确定node在table中的索引位置</strong></a></p><p>因为这种根据hash在table中找位置都是用位运算<code>hash值 &amp; (length-1)</code>，所以这个掩码的1越多，hash值的有效位就越多，结果就越均匀。</p><blockquote><p>对比HashTable扩容是<code>* 2 - 1</code>，初始容量是个素数<code>11</code>，但是HashTable扩容后的数字并不理想，扩容后的length二进制标识就三个1:</p><blockquote><p>11=8+2+1   <code>0000 1011</code></p><p>21=16+4+1   <code>0001 0101</code>，相当于每次把高位的<code>101</code>左移一位</p><p>41=32+8+1   <code>0010 1001</code>，找hash对应位置的时候还要把最低位的1减掉..</p><p>81=64+16+1   <code>0101 0001</code></p></blockquote><p>本来mask取素数应该是为了取余(flag&amp;mask)的时候，mask有更多的1，相当于让flag有更多有效位，结果1.7的实现并不理想。</p></blockquote><p>HashMap中length必须是2的n次方，<code>16</code>binaryStr: <code>0001 0000</code>，减1就直接把唯一一个高电平位<code>1</code>置为<code>0</code>，再把其右边全置为<code>1</code>：<code>16-1</code>binaryStr：<code>0000 1111</code>，这样hash值的有效位最多，node在table中的分配就更均匀了。</p><h4 id="结构变化次数：modCount"><a href="#结构变化次数：modCount" class="headerlink" title="结构变化次数：modCount"></a>结构变化次数：modCount</h4><p>记录hashMap内部结构发生变化的次数，主要用于迭代时的快速失败（<strong>fail-fast</strong>）。</p><blockquote><p>put新Entry算，put已存在的key(覆盖)不算。</p></blockquote><blockquote><p>可以看<code>java.util.HashMap.HashIterator#nextNode</code>的代码，很简单。</p><pre><code class="hljs java"><span class="hljs-keyword">abstract</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HashIterator</span> </span>&#123;    Node&lt;K,V&gt; next;        <span class="hljs-comment">// next entry to return</span>    Node&lt;K,V&gt; current;     <span class="hljs-comment">// current entry</span>    <span class="hljs-keyword">int</span> expectedModCount;  <span class="hljs-comment">// for fast-fail</span>    <span class="hljs-keyword">int</span> index;             <span class="hljs-comment">// current slot</span>    HashIterator() &#123;        expectedModCount = modCount;<span class="hljs-comment">// 开始迭代的时候 map实例的修改次数(其实可以理解为版本号嘛)</span>        Node&lt;K,V&gt;[] t = table;        current = next = <span class="hljs-keyword">null</span>;        index = <span class="hljs-number">0</span>;        <span class="hljs-keyword">if</span> (t != <span class="hljs-keyword">null</span> &amp;&amp; size &gt; <span class="hljs-number">0</span>) &#123; <span class="hljs-comment">// advance to first entry</span>            <span class="hljs-keyword">do</span> &#123;&#125; <span class="hljs-keyword">while</span> (index &lt; t.length &amp;&amp; (next = t[index++]) == <span class="hljs-keyword">null</span>);        &#125;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">hasNext</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> next != <span class="hljs-keyword">null</span>;    &#125;    <span class="hljs-function"><span class="hljs-keyword">final</span> Node&lt;K,V&gt; <span class="hljs-title">nextNode</span><span class="hljs-params">()</span> </span>&#123;        Node&lt;K,V&gt;[] t;        Node&lt;K,V&gt; e = next;        <span class="hljs-keyword">if</span> (modCount != expectedModCount)<span class="hljs-comment">// 迭代的时候如果map的结构被改动过</span>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> ConcurrentModificationException();<span class="hljs-comment">// 熟悉的exception</span>        <span class="hljs-keyword">if</span> (e == <span class="hljs-keyword">null</span>)            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NoSuchElementException();        <span class="hljs-keyword">if</span> ((next = (current = e).next) == <span class="hljs-keyword">null</span> &amp;&amp; (t = table) != <span class="hljs-keyword">null</span>) &#123;            <span class="hljs-keyword">do</span> &#123;&#125; <span class="hljs-keyword">while</span> (index &lt; t.length &amp;&amp; (next = t[index++]) == <span class="hljs-keyword">null</span>);        &#125;        <span class="hljs-keyword">return</span> e;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">remove</span><span class="hljs-params">()</span> </span>&#123;<span class="hljs-comment">// 所以推荐用iter.remove()</span>        Node&lt;K,V&gt; p = current;        <span class="hljs-keyword">if</span> (p == <span class="hljs-keyword">null</span>)            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> IllegalStateException();        <span class="hljs-keyword">if</span> (modCount != expectedModCount)            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> ConcurrentModificationException();        current = <span class="hljs-keyword">null</span>;        K key = p.key;        removeNode(hash(key), key, <span class="hljs-keyword">null</span>, <span class="hljs-keyword">false</span>, <span class="hljs-keyword">false</span>);        expectedModCount = modCount;<span class="hljs-comment">// 会更新期望版本号</span>    &#125;&#125;</code></pre><p><code>java.util.ListIterator</code>的代码也是如此，调用迭代器的iterator的remove()方法会更新<code>modCount</code>和<code>expectedModCount</code>，不会<code>throw new ConcurrentModificationException()</code>。</p></blockquote><h3 id="功能-amp-实现"><a href="#功能-amp-实现" class="headerlink" title="功能 &amp; 实现"></a>功能 &amp; 实现</h3><h4 id="确定node在table中的索引位置"><a href="#确定node在table中的索引位置" class="headerlink" title="确定node在table中的索引位置"></a>确定node在table中的索引位置</h4><p>确定元素在table中的位置总的来说，就是hash值对table.length取余，得到一个[0,length)的值，就是那个位置咯。</p><p>位运算<code>hash值 &amp; (length-1)</code>，也是得到一个[0,length)的值，位运算效率肯定比数学运算要高。</p><p>先看看1.7的代码（jdk1.8没有这个方法）</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">indexFor</span><span class="hljs-params">(<span class="hljs-keyword">int</span> h, <span class="hljs-keyword">int</span> length)</span> </span>&#123;     <span class="hljs-keyword">return</span> h &amp; (length-<span class="hljs-number">1</span>);  <span class="hljs-comment">// 直接取模运算</span>&#125;</code></pre><p>再看1.8的优化：hash值 ^ hash值的高16位，这样能在容量比较小的情况下hash值的高位也能影响到node在table中的位置</p><pre><code class="hljs java"><span class="hljs-comment">// 1.求key的hash时，让高位也参与了运算</span><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> <span class="hljs-title">hash</span><span class="hljs-params">(Object key)</span> </span>&#123;    <span class="hljs-keyword">int</span> h;                                     <span class="hljs-comment">// key.hash值 异或 hash值的高16位</span>    <span class="hljs-keyword">return</span> (key == <span class="hljs-keyword">null</span>) ? <span class="hljs-number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="hljs-number">16</span>);    <span class="hljs-comment">// &gt;&gt;&gt;:逻辑右移，忽略符号位，移动完第一位符号位肯定是0，是个正整数了</span>&#125;<span class="hljs-comment">// Object#hashCode</span><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">native</span> <span class="hljs-keyword">int</span> <span class="hljs-title">hashCode</span><span class="hljs-params">()</span></span>;<span class="hljs-comment">// int 32位</span><span class="hljs-comment">// 2.确定位置：flag&amp;mask（hash&amp;(length-1)）  掩码mask:length是2的n次方，减1之后原来的1变为0，右边的位都是1，结果就是[0,length)范围内的数</span><span class="hljs-comment">// 比如resize()方法重新计算位置的时候的代码,前边有介绍了</span>newTab[e.hash &amp; (newCap - <span class="hljs-number">1</span>)] = e;</code></pre><blockquote><p><code>%</code> 取余是个数学运算， 而<code>&amp;</code> 与运算是位运算，效率更高。</p></blockquote><p>相关的优化还有一个，就是<code>resize()</code>扩容时的 <strong>oldCap作mask 重hash优化</strong>，key的<code>newIndex</code>只可能是<code>oldIndex</code>或<code>oldIndex+oldCap</code>，决定因素就是oldCap这个位<code>1 还是 0</code>。见下方[扩容 resize()](#扩容 resize())</p><h4 id="put-K-V-方法"><a href="#put-K-V-方法" class="headerlink" title="put(K, V)方法"></a>put(K, V)方法</h4><p>流程：</p><ol><li>是否需要初始化？需要就扩容；</li><li><code>table[hash&amp;(length-1)] </code>是不是<code>null</code>？<ul><li>是<code>null</code>：直接插入；</li><li>有<code>node</code>：key相同吗？<ul><li>相同：覆盖</li><li>不同：<code>instance of TreeNode</code> ？<code>红黑树插入</code> : <code>遍历链表覆盖或加到tail.next</code>,并判断是否需要转红黑树<code>treeifyBin()</code>；</li></ul></li></ul></li><li>最后<strong>都</strong>要再判断size是否超过阈值<code>threshold</code>，超过就扩容(扩容会<code>rehash</code>哦)。</li></ol><img alt="put()流程图，图在github" src="https://raw.githubusercontent.com/melopoz/pics/master/img/HashMap" style="zoom:40%;" /><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> V <span class="hljs-title">put</span><span class="hljs-params">(K key, V value)</span> </span>&#123;    <span class="hljs-keyword">return</span> putVal(hash(key), key, value, <span class="hljs-keyword">false</span>, <span class="hljs-keyword">true</span>);&#125;<span class="hljs-function"><span class="hljs-keyword">final</span> V <span class="hljs-title">putVal</span><span class="hljs-params">(<span class="hljs-keyword">int</span> hash, K key, V value, <span class="hljs-keyword">boolean</span> onlyIfAbsent, <span class="hljs-keyword">boolean</span> evict)</span> </span>&#123;    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="hljs-keyword">int</span> n, i;    <span class="hljs-keyword">if</span> ((tab = table) == <span class="hljs-keyword">null</span> || (n = tab.length) == <span class="hljs-number">0</span>) <span class="hljs-comment">// table是空的 扩容(初始化扩容)</span>        n = (tab = resize()).length;    <span class="hljs-keyword">if</span> ((p = tab[i = (n - <span class="hljs-number">1</span>) &amp; hash]) == <span class="hljs-keyword">null</span>)<span class="hljs-comment">// key不存在 直接放到对应索引位</span>        tab[i] = newNode(hash, key, value, <span class="hljs-keyword">null</span>);    <span class="hljs-keyword">else</span> &#123;        Node&lt;K,V&gt; e; K k;<span class="hljs-comment">// p: table[i]处的head节点</span>        <span class="hljs-keyword">if</span> (p.hash == hash &amp;&amp;              ((k = p.key) == key || (key != <span class="hljs-keyword">null</span> &amp;&amp; key.equals(k))))<span class="hljs-comment">// 要插入的节点对应table[i]处链表的head 直接走后边的覆盖逻辑</span>            e = p;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (p <span class="hljs-keyword">instanceof</span> TreeNode)<span class="hljs-comment">// 是树节点</span>            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class="hljs-keyword">this</span>, tab, hash, key, value);        <span class="hljs-keyword">else</span> &#123;<span class="hljs-comment">// 否则就遍历链表，找到key相同的节点或者加到tail后边</span>            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> binCount = <span class="hljs-number">0</span>; ; ++binCount) &#123;                <span class="hljs-keyword">if</span> ((e = p.next) == <span class="hljs-keyword">null</span>) &#123;<span class="hljs-comment">// table[i]处就一个节点</span>                    p.next = newNode(hash, key, value, <span class="hljs-keyword">null</span>);                    <span class="hljs-keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="hljs-number">1</span>) <span class="hljs-comment">// -1 for 1st  </span>                        treeifyBin(tab, hash); <span class="hljs-comment">// TREEIFY_THRESHOLD=8，所以如果当前节点是第8个就会转换成红黑树</span>                    <span class="hljs-keyword">break</span>;                &#125;                <span class="hljs-keyword">if</span> (e.hash == hash &amp;&amp;                    ((k = e.key) == key || (key != <span class="hljs-keyword">null</span> &amp;&amp; key.equals(k)))) <span class="hljs-comment">// 如果key已经存在 就覆盖</span>                    <span class="hljs-keyword">break</span>;                p = e;            &#125;        &#125;                <span class="hljs-keyword">if</span> (e != <span class="hljs-keyword">null</span>) &#123; <span class="hljs-comment">// existing mapping for key</span>            V oldValue = e.value;            <span class="hljs-keyword">if</span> (!onlyIfAbsent || oldValue == <span class="hljs-keyword">null</span>)                e.value = value;            afterNodeAccess(e);<span class="hljs-comment">// LinkedHashMap重写了这个方法进行排序，如果设置了accessOrder=true，则访问节点之后节点要放到最后</span>            <span class="hljs-keyword">return</span> oldValue;        &#125;    &#125;    ++modCount;    <span class="hljs-keyword">if</span> (++size &gt; threshold) <span class="hljs-comment">// 超过阈值就扩容</span>        resize();    afterNodeInsertion(evict); <span class="hljs-comment">// 插入节点之后 同上边 afterNodeAccess..</span>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;&#125;</code></pre><h4 id="resize-扩容"><a href="#resize-扩容" class="headerlink" title="resize() 扩容"></a>resize() 扩容</h4><p>table是数组，不能扩容，所以肯定开辟新空间，再复制过去。</p><p>由于扩容是旧容量*2：<code>newCap = oldCap &lt;&lt; 1</code>，key的hash值是固定的，举个例子：(就只看后八位了)</p><blockquote><p>假设  hash(key1) = <code>0000 0101</code>，hash(key2) = <code>0001 0101</code></p><p>oldCap= 16（15的二进制：<code>0000 1111</code>）</p><p>这两个key通过<code>hash(key)&amp;(length-1)</code>运算得到的位置都是<strong>5</strong> <code>0101</code>。</p><p>key1对应的位置：<code>0000 0101</code> &amp; <code>0000 1111</code> = 5（ <code>0000 0101</code>）</p><p>key2对应的位置：<code>0001 0101</code> &amp; <code>0000 1111</code> = <strong>5</strong>（ <code>0000 0101</code>）</p></blockquote><p>扩容之后：</p><blockquote><p>newCap：32（31的二进制：<code>0001 1111</code>）</p><p>key1对应的位置：<code>0000 0101</code> &amp; <code>0001 1111</code> = 5（ <code>0000 0101</code>）</p><p>key2对应的位置：<code>0001 0101</code> &amp; <code>0001 1111</code> = <strong>21</strong>（ <code>0001 0101</code>）</p></blockquote><img alt="rehash demo，图在github" src="https://raw.githubusercontent.com/melopoz/pics/master/img/resize-key%E7%9A%84%E6%96%B0%E7%B4%A2%E5%BC%95%E4%BD%8D%E7%BD%AE.png" style="zoom: 50%;" /><p>这么看来key在新table中的位置只有两种可能：<code>oldIndex</code>或者<code>oldIndex + oldCap</code>。</p><p>其决定因素就是<code>hash(key)</code>在<code>mask的高位新增位(上图红色的1)</code> 对应的bit是1还是0，这个<code>binaryStr只有一个1的</code>mask(<code>0001 0000</code>)正是<code>oldCap</code>。所以</p><blockquote><p><code>hash &amp; oldCap == </code><strong>0</strong>：<code>newIndex = oldIndex  </code></p><p><code>hash &amp; oldCap == </code><strong>1</strong>：<code>newIndex = oldIndex + oldCap</code></p></blockquote><blockquote><p>Ctrl+F 搜索<code>&quot;oldCap作mask 重hash优化&quot;</code>找到对应的代码  :)</p></blockquote><h5 id="resize-源码"><a href="#resize-源码" class="headerlink" title="resize()源码"></a>resize()源码</h5><pre><code class="hljs java"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">4</span>; <span class="hljs-comment">// aka 16 // 初始化容量</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> MAXIMUM_CAPACITY = <span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">30</span>;<span class="hljs-comment">// 最大容量</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">float</span> DEFAULT_LOAD_FACTOR = <span class="hljs-number">0.75f</span>;<span class="hljs-comment">// 默认负载因子</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> TREEIFY_THRESHOLD = <span class="hljs-number">8</span>;<span class="hljs-comment">// 树化的阈值，链表超过8个，就转为红黑树（条件一）</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> UNTREEIFY_THRESHOLD = <span class="hljs-number">6</span>;<span class="hljs-comment">// 红黑树的节点个数小于6就转为链表</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="hljs-number">64</span>;<span class="hljs-comment">// table的容量低于64不会树化（条件二）</span><span class="hljs-keyword">final</span> Node&lt;K,V&gt;[] resize() &#123;    Node&lt;K,V&gt;[] oldTab = table;    <span class="hljs-keyword">int</span> oldCap = (oldTab == <span class="hljs-keyword">null</span>) ? <span class="hljs-number">0</span> : oldTab.length;    <span class="hljs-keyword">int</span> oldThr = threshold;    <span class="hljs-keyword">int</span> newCap, newThr = <span class="hljs-number">0</span>;    <span class="hljs-comment">// 上来先 base case ..</span>    <span class="hljs-keyword">if</span> (oldCap &gt; <span class="hljs-number">0</span>) &#123;        <span class="hljs-keyword">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;<span class="hljs-comment">// MAXIMUM_CAPACITY = 1 &lt;&lt; 30;</span>            threshold = Integer.MAX_VALUE;<span class="hljs-comment">// 容量超过最大值，把阈值也搞大，这样以后就不用resize()了</span>            <span class="hljs-keyword">return</span> oldTab;        &#125;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((newCap = oldCap &lt;&lt; <span class="hljs-number">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp;<span class="hljs-comment">// 容量 *2</span>                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)<span class="hljs-comment">// DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 16</span>            newThr = oldThr &lt;&lt; <span class="hljs-number">1</span>; <span class="hljs-comment">// double threshold // 阈值也 *2</span>    &#125;    <span class="hljs-keyword">else</span><span class="hljs-comment">/*oldCap==0*/</span> <span class="hljs-keyword">if</span> (oldThr &gt; <span class="hljs-number">0</span>) <span class="hljs-comment">// initial capacity was placed in threshold</span>        newCap = oldThr;<span class="hljs-comment">// 初始容量设置为阈值</span>    <span class="hljs-keyword">else</span><span class="hljs-comment">/*oldCap==0 &amp;&amp; oldThr == 0*/</span> &#123; <span class="hljs-comment">// zero initial threshold signifies using defaults</span>        <span class="hljs-comment">// 没有设置初始阈值，就使用默认值</span>        newCap = DEFAULT_INITIAL_CAPACITY;        newThr = (<span class="hljs-keyword">int</span>)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);    &#125;    <span class="hljs-keyword">if</span> (newThr == <span class="hljs-number">0</span>) &#123; <span class="hljs-comment">// 如果newThr为0，那直接设置容量为Integer.MAX</span>        <span class="hljs-keyword">float</span> ft = (<span class="hljs-keyword">float</span>)newCap * loadFactor;        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class="hljs-keyword">float</span>)MAXIMUM_CAPACITY ?                  (<span class="hljs-keyword">int</span>)ft : Integer.MAX_VALUE);    &#125;    <span class="hljs-comment">// 从这里开始</span>    threshold = newThr;    <span class="hljs-meta">@SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;)</span>    Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])<span class="hljs-keyword">new</span> Node[newCap];<span class="hljs-comment">// 开辟newTab空间</span>    table = newTab;    <span class="hljs-keyword">if</span> (oldTab != <span class="hljs-keyword">null</span>) &#123;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; oldCap; ++j) &#123;<span class="hljs-comment">// 遍历oldTable</span>            Node&lt;K,V&gt; e;            <span class="hljs-keyword">if</span> ((e = oldTab[j]) != <span class="hljs-keyword">null</span>) &#123;                oldTab[j] = <span class="hljs-keyword">null</span>;<span class="hljs-comment">// 去掉以前的引用 help GC</span>                <span class="hljs-keyword">if</span> (e.next == <span class="hljs-keyword">null</span>)<span class="hljs-comment">// 说明这个位置原本只有一个node</span>                    newTab[e.hash &amp; (newCap - <span class="hljs-number">1</span>)] = e;<span class="hljs-comment">// 放到newTable对应的位置即可</span>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (e <span class="hljs-keyword">instanceof</span> TreeNode)<span class="hljs-comment">// 是红黑树节点</span>                    ((TreeNode&lt;K,V&gt;)e).split(<span class="hljs-keyword">this</span>, newTab, j, oldCap);<span class="hljs-comment">// todo 红黑树操作 </span>                <span class="hljs-keyword">else</span> <span class="hljs-comment">/*这个位置是链表*/</span>&#123; <span class="hljs-comment">// preserve order</span>                    Node&lt;K,V&gt; loHead = <span class="hljs-keyword">null</span>, loTail = <span class="hljs-keyword">null</span>;<span class="hljs-comment">// 假设容量是从16扩容到32，loHead就是newTable[15]这个head节点</span>                    Node&lt;K,V&gt; hiHead = <span class="hljs-keyword">null</span>, hiTail = <span class="hljs-keyword">null</span>;<span class="hljs-comment">// 那么hiHead就是newTable[31]这个head节点</span>                    Node&lt;K,V&gt; next;                    <span class="hljs-keyword">do</span> &#123;<span class="hljs-comment">// 遍历这个链表</span>                        next = e.next;<span class="hljs-comment">// 先留一份当前node的next的指针,while的时候用</span>                        <span class="hljs-comment">// 这里就是&quot;oldCap作mask 重hash优化&quot;中对 newIndex只有两种可能 的处理</span>                        <span class="hljs-keyword">if</span> ((e.hash &amp; oldCap) == <span class="hljs-number">0</span>) &#123;<span class="hljs-comment">// 在newTable中的位置还是 oldIndex</span>                            <span class="hljs-keyword">if</span> (loTail == <span class="hljs-keyword">null</span>)<span class="hljs-comment">// 第一次来newTable[j]这个位置肯定是null</span>                                loHead = e;<span class="hljs-comment">// loHead指针直接指向这个新node</span>                            <span class="hljs-keyword">else</span>                                loTail.next = e;<span class="hljs-comment">// 第二次之后插入到table[j]对应链表的tail之后，可见1.8这里是用的尾插法。</span>                            loTail = e;<span class="hljs-comment">// 无论如何总是要更新tail节点指向新的node</span>                        &#125;                        <span class="hljs-keyword">else</span> &#123;<span class="hljs-comment">// 在newTable中的位置是 oldIndex + oldCap，同上</span>                            <span class="hljs-keyword">if</span> (hiTail == <span class="hljs-keyword">null</span>)                                hiHead = e;                            <span class="hljs-keyword">else</span>                                hiTail.next = e;                            hiTail = e;                        &#125;                    &#125; <span class="hljs-keyword">while</span> ((e = next) != <span class="hljs-keyword">null</span>);                    <span class="hljs-comment">// do-while结束，newTable[j]和newTable[j+oldCap]对应的链表已经生成，放到newTable即可</span>                    <span class="hljs-keyword">if</span> (loTail != <span class="hljs-keyword">null</span>) &#123;<span class="hljs-comment">// 说明newTable[j]这个位置有节点</span>                        loTail.next = <span class="hljs-keyword">null</span>;                        newTab[j] = loHead;<span class="hljs-comment">// loHead放到newTable的低索引位</span>                    &#125;                    <span class="hljs-keyword">if</span> (hiTail != <span class="hljs-keyword">null</span>) &#123;                        hiTail.next = <span class="hljs-keyword">null</span>;                        newTab[j + oldCap] = hiHead;<span class="hljs-comment">// hiHead放到newTable的高索引位</span>                    &#125;                &#125;            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> newTab;&#125;</code></pre><p>再来看看1.7的源码</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">transfer</span> <span class="hljs-params">(Entry[] newTable)</span></span>&#123;    Entry[] src = table;<span class="hljs-comment">//old table</span>    <span class="hljs-keyword">int</span> newCapacity = newTable.length;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; src.length; j++) &#123;        Entry&lt;K, V&gt; e = src[j];<span class="hljs-comment">// e就是旧table lo索引位的 head节点</span>        <span class="hljs-keyword">if</span> (e != <span class="hljs-keyword">null</span>) &#123;            src[j] = <span class="hljs-keyword">null</span>;<span class="hljs-comment">//释放旧Entry数组的对象引用 help GC</span>            <span class="hljs-keyword">do</span> &#123;                Entry&lt;K, V&gt; next = e.next;<span class="hljs-comment">// 持有一份当前node的next指针</span>                <span class="hljs-keyword">int</span> i = indexFor(e.hash, newCapacity); <span class="hljs-comment">// 重新计算每个元素在数组中的位置 还是用的 e.hash &amp; (newCapacity-1)</span>                e.next = newTable[i]; <span class="hljs-comment">// 将newTable[i]处的链表接到当前node(新head)后边。  - 头插法！死循环</span>                newTable[i] = e;      <span class="hljs-comment">// 将当前node放到newTable[i]处</span>                e = next;            &#125; <span class="hljs-keyword">while</span> (e != <span class="hljs-keyword">null</span>);        &#125;    &#125;&#125;<span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">indexFor</span><span class="hljs-params">(<span class="hljs-keyword">int</span> h, <span class="hljs-keyword">int</span> length)</span> </span>&#123;     <span class="hljs-keyword">return</span> h &amp; (length-<span class="hljs-number">1</span>);&#125;</code></pre><p>1.8用的是尾插法，链表元素不会倒置，1.7的代码中用的是头插法，元素位置会倒置，而且可能死循环</p><h4 id="treeifyBin-转红黑树-两个条件"><a href="#treeifyBin-转红黑树-两个条件" class="headerlink" title="treeifyBin() 转红黑树 - 两个条件"></a>treeifyBin() 转红黑树 - 两个条件</h4><p>如果<code>hash槽的node个数&gt;=8</code>，就会调用treeifyBin(..)方法进行树化。</p><pre><code class="hljs java"><span class="hljs-keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD)    treeifyBin(tab, i);</code></pre><p>treeifyBin(..)方法中会再次判断，<strong>只有table的容量<code>table.length</code>&gt;=64</strong>，才会转为红黑树，否则只是扩容<code>resize()</code>。</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">treeifyBin</span><span class="hljs-params">(Node&lt;K,V&gt;[] tab, <span class="hljs-keyword">int</span> hash)</span> </span>&#123;    <span class="hljs-keyword">int</span> n, index; Node&lt;K,V&gt; e;    <span class="hljs-keyword">if</span> (tab == <span class="hljs-keyword">null</span> || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) <span class="hljs-comment">// 如果元素个数 &lt; 64 会扩容而不是转换成红黑树。</span>        resize();    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((e = tab[index = (n - <span class="hljs-number">1</span>) &amp; hash]) != <span class="hljs-keyword">null</span>) &#123;        TreeNode&lt;K,V&gt; hd = <span class="hljs-keyword">null</span>, tl = <span class="hljs-keyword">null</span>;        <span class="hljs-keyword">do</span> &#123;            TreeNode&lt;K,V&gt; p = replacementTreeNode(e, <span class="hljs-keyword">null</span>);            <span class="hljs-keyword">if</span> (tl == <span class="hljs-keyword">null</span>)                hd = p;            <span class="hljs-keyword">else</span> &#123;                p.prev = tl;                tl.next = p;            &#125;            tl = p;        &#125; <span class="hljs-keyword">while</span> ((e = e.next) != <span class="hljs-keyword">null</span>);        <span class="hljs-keyword">if</span> ((tab[index] = hd) != <span class="hljs-keyword">null</span>)            hd.treeify(tab);    &#125;&#125;<span class="hljs-function">TreeNode&lt;K,V&gt; <span class="hljs-title">replacementTreeNode</span><span class="hljs-params">(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next)</span> </span>&#123;    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> TreeNode&lt;&gt;(p.hash, p.key, p.value, next);&#125;</code></pre><pre><code class="hljs ebnf"><span class="hljs-attribute">replacementTreeNode</span></code></pre><h3 id="常见问题："><a href="#常见问题：" class="headerlink" title="常见问题："></a>常见问题：</h3><h6 id="扩容的时间复杂度是多少"><a href="#扩容的时间复杂度是多少" class="headerlink" title="扩容的时间复杂度是多少"></a>扩容的时间复杂度是多少</h6><blockquote><p>O(logn) ~ O(n)</p><p>肯定要要遍历所有node，如果每个节点都是红黑树，那就是cap*log(n)，去掉常量就是O(logn)，如果都是链表，相当于遍历cap次。</p><p>(注意不会因为for嵌套do-while就是O(²))。</p></blockquote><h6 id="一些细节-特点"><a href="#一些细节-特点" class="headerlink" title="一些细节 特点"></a>一些细节 特点</h6><blockquote><p>扩容非常耗时，尽量初始化的时候预估容量。</p><p>负载因子loadFactor是可以指定的，不是特殊情况不要改。</p></blockquote><h6 id="1-8做了哪些优化"><a href="#1-8做了哪些优化" class="headerlink" title="1.8做了哪些优化"></a>1.8做了哪些优化</h6><blockquote><ol><li>加入红黑树；</li><li>头插法换成尾插法，和红黑树结构均能防止死循环；</li><li>求key对应的索引位置时用 oldCap 做mask 直接判断 node 对应的索引是 oldIndex 还是 oldIndex + oldCap。</li></ol></blockquote><h6 id="为啥用红黑树？"><a href="#为啥用红黑树？" class="headerlink" title="为啥用红黑树？"></a>为啥用红黑树？</h6><blockquote><p>如果hash函数结构够均匀，性能大概是提升15%。</p></blockquote><blockquote><p>如果hash函数很垃圾，比如极端情况所有hash(key)都相同。那每次都要遍历table[j]处对应的链表，1.7在这种情况下时间复杂度直接变成O(n)，1.8引入红黑树，在这种情况下节点越多查询节点可能越小，时间复杂度下降为O(logn)。</p></blockquote><h6 id="怎么解决1-7那个死循环的？"><a href="#怎么解决1-7那个死循环的？" class="headerlink" title="怎么解决1.7那个死循环的？"></a>怎么解决1.7那个死循环的？</h6><blockquote><p>1.7是把node放到newTable[j]处的head（头插法），1.8是放到newTable[j]的tail.next（尾插法）。即使线程不安全，出问题也就是可能node会有重复</p></blockquote><h1 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h1><h2 id="JDK1-7"><a href="#JDK1-7" class="headerlink" title="JDK1.7"></a>JDK1.7</h2><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><img alt="jdk1.7-ConcurrentHashMap数据结构，图在github" src="https://raw.githubusercontent.com/melopoz/pics/master/img/926638-20170809132445011-2033999443.png" style="zoom: 67%;" /><h4 id="Segment数组-amp-HashEntry数组"><a href="#Segment数组-amp-HashEntry数组" class="headerlink" title="Segment数组 &amp; HashEntry数组"></a>Segment数组 &amp; HashEntry数组</h4><p>每个Segment是一个HashEntry数组，每个HashEntry的结构和HashMap相同。</p><blockquote><p>用分段锁把锁的粒度变细，以提高并发性。</p></blockquote><p>Segment数组和HashEntry数组的容量都是2的n次方；</p><p><code>segment数组初始容量16</code>，只能用16位二进制标识，所以<code>最大值65536</code>；</p><p>HashEntry<code>初始容量为1，最小容量为2</code>。</p><h3 id="功能-amp-实现-1"><a href="#功能-amp-实现-1" class="headerlink" title="功能 &amp; 实现"></a>功能 &amp; 实现</h3><pre><code class="hljs java"><span class="hljs-comment">// Segment是继承自ReentrantLock的</span><span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Segment</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">ReentrantLock</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Serializable</span> </span>&#123;...&#125;</code></pre><h4 id="put-K-V"><a href="#put-K-V" class="headerlink" title="put(K, V)"></a>put(K, V)</h4><ol><li><p>如果该Segment还未初始化，就CAS进行初始化；</p></li><li><p>二次hash，从HashEntry数组中找到key对应的HashEntry</p><p>用tryLock()加锁，失败会自旋，自旋超过指定次数就挂起当前线程，等待被唤醒。</p></li></ol><h4 id="get-K"><a href="#get-K" class="headerlink" title="get(K)"></a>get(K)</h4><p>和HashMap的区别就是需要两次hash，并对Segment加锁</p><h4 id="size"><a href="#size" class="headerlink" title="size()"></a>size()</h4><p>在thread1计算size的时候，其他线程可能在thread1计算过的segment插入过数据。</p><ol><li>先不加锁，多次计算size，比较计算的结果和前一次的结果，如果一致就返回（最多三次）</li><li>如果不一致就把所有segment加锁再计算</li></ol><p>代码如下：</p><pre><code class="hljs java"><span class="hljs-keyword">try</span> &#123;    <span class="hljs-keyword">for</span> (;;) &#123;        <span class="hljs-keyword">if</span> (retries++ == RETRIES_BEFORE_LOCK) &#123;<span class="hljs-comment">// RETRIES_BEFORE_LOCK 加锁之前重试次数 3</span>            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; segments.length; ++j)                ensureSegment(j).lock(); <span class="hljs-comment">// force creation</span>        &#125;        sum = <span class="hljs-number">0L</span>;        size = <span class="hljs-number">0</span>;<span class="hljs-comment">// size</span>        overflow = <span class="hljs-keyword">false</span>;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; segments.length; ++j) &#123;            Segment&lt;K,V&gt; seg = segmentAt(segments, j);            <span class="hljs-keyword">if</span> (seg != <span class="hljs-keyword">null</span>) &#123;                sum += seg.modCount;                 <span class="hljs-keyword">int</span> c = seg.count;                 <span class="hljs-keyword">if</span> (c &lt; <span class="hljs-number">0</span> || (size += c) &lt; <span class="hljs-number">0</span>)                overflow = <span class="hljs-keyword">true</span>;<span class="hljs-comment">// 溢出</span>            &#125;        &#125;        <span class="hljs-keyword">if</span> (sum == last)<span class="hljs-comment">// 计算过程中结构没有变过</span>            <span class="hljs-keyword">break</span>;<span class="hljs-comment">// 只有锁定所有segment 或者 真的没有别的线程改变过map的结构，才会到这里</span>        last = sum;<span class="hljs-comment">// 保存本次计算size 的结果，用于下次计算完size的比较 </span>    &#125;&#125; <span class="hljs-keyword">finally</span> &#123;    <span class="hljs-keyword">if</span> (retries &gt; RETRIES_BEFORE_LOCK) &#123;<span class="hljs-comment">// 如果重试次数超过3，肯定都加上锁再计算的</span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; segments.length; ++j)<span class="hljs-comment">// 所有segment都解锁</span>            segmentAt(segments, j).unlock();    &#125;&#125;</code></pre><h2 id="JDK1-8"><a href="#JDK1-8" class="headerlink" title="JDK1.8"></a>JDK1.8</h2><h3 id="数据结构-amp-属性-1"><a href="#数据结构-amp-属性-1" class="headerlink" title="数据结构 &amp; 属性"></a>数据结构 &amp; 属性</h3><p>取消了segments字段，直接使用<code>transient volatile Node&lt;K,V&gt;[] table</code>保存数据，与JDK1.8的HashMap类似。</p><blockquote><p>保留了Segment的数据结构，但是简化了属性，只是兼容旧版本</p></blockquote><h5 id="Node-lt-K-V-gt-table"><a href="#Node-lt-K-V-gt-table" class="headerlink" title="Node&lt;K,V&gt;[]  table"></a>Node&lt;K,V&gt;[]  table</h5><pre><code class="hljs java"><span class="hljs-comment">// 存放node的数组</span><span class="hljs-keyword">transient</span> <span class="hljs-keyword">volatile</span> Node&lt;K,V&gt;[] table;<span class="hljs-comment">// 和HashMap的Node有些差异，不允许修改Node的value了</span><span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Node</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title">Map</span>.<span class="hljs-title">Entry</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; </span>&#123;    ...    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> V <span class="hljs-title">setValue</span><span class="hljs-params">(V value)</span> </span>&#123;        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> UnsupportedOperationException();<span class="hljs-comment">// 和HashMap的Node相似但是只允许查找，不允许修改</span>    &#125;&#125;</code></pre><h5 id="int-sizeCtl-控制标识符"><a href="#int-sizeCtl-控制标识符" class="headerlink" title="int sizeCtl   -控制标识符"></a>int sizeCtl   -控制标识符</h5><p>用来控制table的初始化和扩容的操作，不同的值有不同的含义。</p><ul><li>当为负数时：-1代表正在初始化；-N代表有N-1个线程正在 进行扩容</li><li>当为0时：代表当时的table还没有被初始化</li><li>当为正数时：表示<code>初始化时/触发扩容时</code>的阈值（size达到这个值就要扩容）</li></ul><blockquote><p>也可以只分为<code>&lt;0</code>和<code>&gt;=0</code>两种情况，因为=0的时候也相当于是个阈值，触发扩容，不过这个扩容是初始化</p></blockquote><pre><code class="hljs java"><span class="hljs-comment">// 扩容时sizeCtl有两部分组成，第一部分是扩容戳，占据sizeCtl的高16位;第二部分是参与扩容的线程数，占低16位。</span><span class="hljs-comment">// 每个新线程协助扩容时sizeCtl+1，直到所有的低有效位被占满，低有效位默认占16位（最高位为符号位），所以扩容线程数默认最大为65535。</span><span class="hljs-keyword">private</span> <span class="hljs-keyword">transient</span> <span class="hljs-keyword">volatile</span> <span class="hljs-keyword">int</span> sizeCtl;</code></pre><h5 id="long-baseCount-基础计数器"><a href="#long-baseCount-基础计数器" class="headerlink" title="long baseCount  -基础计数器"></a>long baseCount  -基础计数器</h5><pre><code class="hljs java"><span class="hljs-comment">// 代表Map中元素个数的的基础计数器，当无竞争时直接使用CAS方式更新该数值 </span><span class="hljs-keyword">transient</span> <span class="hljs-keyword">volatile</span> <span class="hljs-keyword">long</span> baseCount;<span class="hljs-comment">// 存储Map中元素的计数器，当并发量较高时`baseCount`竞争较为激烈，更新效率较低，所以把变化的数值更新到`counterCells`中的某个节点上</span><span class="hljs-comment">// 计算size()时需要统计每个`counterCells`的大小再加上`baseCount`的数值。</span><span class="hljs-keyword">transient</span> <span class="hljs-keyword">volatile</span> CounterCell[] counterCells;<span class="hljs-comment">// 扩容或者创建CounterCells时使用的自旋锁（使用CAS实现）；</span><span class="hljs-keyword">transient</span> <span class="hljs-keyword">volatile</span> <span class="hljs-keyword">int</span> cellsBusy;</code></pre><h5 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h5><pre><code class="hljs java"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> MOVED     = -<span class="hljs-number">1</span>; <span class="hljs-comment">// hash for forwarding nodes 转移节点的hash都是-1</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> TREEBIN   = -<span class="hljs-number">2</span>; <span class="hljs-comment">// hash for roots of trees  红黑树节点hash都是-2</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> RESERVED  = -<span class="hljs-number">3</span>; <span class="hljs-comment">// hash for transient reservations</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> HASH_BITS = <span class="hljs-number">0x7fffffff</span>; <span class="hljs-comment">// usable bits of normal node hash 普通hash的有效位 相当于最基本的掩码吧</span></code></pre><h5 id="扩容相关的变量-属性"><a href="#扩容相关的变量-属性" class="headerlink" title="扩容相关的变量/属性"></a>扩容相关的变量/属性</h5><pre><code class="hljs java"><span class="hljs-comment">// 也就是newTable（仅在扩容的时候不为null）</span><span class="hljs-keyword">private</span> <span class="hljs-keyword">transient</span> <span class="hljs-keyword">volatile</span> Node&lt;K,V&gt;[] nextTable;<span class="hljs-comment">// 扩容子任务对应的table的索引位</span><span class="hljs-keyword">transient</span> <span class="hljs-keyword">volatile</span> <span class="hljs-keyword">int</span> transferIndex; <span class="hljs-comment">// 参与扩容的线程领取扩容子任务时，要减去的扩容步长，如果能减成功,则成功领取一个扩容子任务</span><span class="hljs-comment">// transferIndex = transferIndex - stride(扩容步长)</span><span class="hljs-comment">// transferIndex减到0时,代表没有可以领取的扩容子任务</span><span class="hljs-comment">// 每个线程一次转移一个区间段的数据，一个区间段（转移步长）的默认长度是16，实际运行过程中会动态计算(最小16)</span><span class="hljs-comment">// 最小转移步长：由于在扩容过程中，会把一个待转移的数组分为多个区间段（转移步长-stride）</span><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> MIN_TRANSFER_STRIDE = <span class="hljs-number">16</span>;<span class="hljs-comment">// 可用处理器数量 用来计算扩容任务的步长</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> NCPU = Runtime.getRuntime().availableProcessors();<span class="hljs-comment">// 因为要使用乐观的cas更新变量来保证线程安全性，肯定需要Unsafe(根据内存偏移量 直接从内存中读取修改对象属性）</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> sun.misc.Unsafe U;</code></pre><h4 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h4><h5 id="ForwardingNode-转发节点"><a href="#ForwardingNode-转发节点" class="headerlink" title="ForwardingNode 转发节点"></a>ForwardingNode 转发节点</h5><p>在扩容时用来标记这个节点已经处理过了。这类节点的hash值为  -1</p><pre><code class="hljs java"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ForwardingNode</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">Node</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; </span>&#123;    <span class="hljs-keyword">final</span> Node&lt;K,V&gt;[] nextTable;<span class="hljs-comment">// 扩容时新table的引用</span>    ForwardingNode(Node&lt;K,V&gt;[] tab) &#123;        <span class="hljs-comment">// 常量MOVED = -1</span>        <span class="hljs-keyword">super</span>(<span class="hljs-comment">/*hash*/</span>MOVED, <span class="hljs-comment">/*k*/</span><span class="hljs-keyword">null</span>, <span class="hljs-comment">/*v*/</span><span class="hljs-keyword">null</span>, <span class="hljs-comment">/*next*/</span><span class="hljs-keyword">null</span>);        <span class="hljs-keyword">this</span>.nextTable = tab;    &#125;    ...&#125;</code></pre><h5 id="TreeNode-红黑树节点"><a href="#TreeNode-红黑树节点" class="headerlink" title="TreeNode 红黑树节点"></a>TreeNode 红黑树节点</h5><p>继承自 Map.Node  维护了二叉树节点的属性</p><pre><code class="hljs java"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TreeNode</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">Node</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; </span>&#123;    TreeNode&lt;K,V&gt; parent;  <span class="hljs-comment">// red-black tree links</span>    TreeNode&lt;K,V&gt; prev;    <span class="hljs-comment">// needed to unlink next upon deletion</span>    TreeNode&lt;K,V&gt; left, right;    <span class="hljs-keyword">boolean</span> red;<span class="hljs-comment">// 节点颜色</span>    <span class="hljs-function"><span class="hljs-keyword">final</span> TreeNode&lt;K,V&gt; <span class="hljs-title">findTreeNode</span><span class="hljs-params">(<span class="hljs-keyword">int</span> h, Object k, Class&lt;?&gt; kc)</span> </span>&#123;        ...    &#125;&#125;</code></pre><h5 id="TreeBin-存储树的容器"><a href="#TreeBin-存储树的容器" class="headerlink" title="TreeBin 存储树的容器"></a>TreeBin 存储树的容器</h5><p>封装 TreeNode 的容器，它提供转换黑红树的一些条件和锁的控制</p><pre><code class="hljs java"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TreeBin</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">Node</span>&lt;<span class="hljs-title">K</span>,<span class="hljs-title">V</span>&gt; </span>&#123;    TreeNode&lt;K,V&gt; root;    <span class="hljs-keyword">volatile</span> TreeNode&lt;K,V&gt; first;    <span class="hljs-keyword">volatile</span> Thread waiter;    <span class="hljs-keyword">volatile</span> <span class="hljs-keyword">int</span> lockState;<span class="hljs-comment">// 锁状态</span>    <span class="hljs-comment">// values for lockState </span>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> WRITER = <span class="hljs-number">1</span>; <span class="hljs-comment">// set while holding write lock</span>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> WAITER = <span class="hljs-number">2</span>; <span class="hljs-comment">// set when waiting for write lock</span>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> READER = <span class="hljs-number">4</span>; <span class="hljs-comment">// increment value for setting read lock</span>        <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">lockRoot</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">if</span> (!U.compareAndSwapInt(<span class="hljs-keyword">this</span>, LOCKSTATE, <span class="hljs-number">0</span>, WRITER)) <span class="hljs-comment">// 如果cas失败就去 竞争锁</span>            contendedLock(); <span class="hljs-comment">// offload to separate method</span>    &#125;    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">unlockRoot</span><span class="hljs-params">()</span> </span>&#123;        lockState = <span class="hljs-number">0</span>;    &#125;    <span class="hljs-comment">// 阻塞等待root锁</span>    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">contendedLock</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">boolean</span> waiting = <span class="hljs-keyword">false</span>;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> s;;) &#123;            <span class="hljs-keyword">if</span> (((s = lockState) &amp; ~WAITER) == <span class="hljs-number">0</span>) &#123;                <span class="hljs-keyword">if</span> (U.compareAndSwapInt(<span class="hljs-keyword">this</span>, LOCKSTATE, s, WRITER)) &#123;                    <span class="hljs-keyword">if</span> (waiting)                        waiter = <span class="hljs-keyword">null</span>;                    <span class="hljs-keyword">return</span>;                &#125;            &#125;            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((s &amp; WAITER) == <span class="hljs-number">0</span>) &#123;                <span class="hljs-keyword">if</span> (U.compareAndSwapInt(<span class="hljs-keyword">this</span>, LOCKSTATE, s, s | WAITER)) &#123;                    waiting = <span class="hljs-keyword">true</span>;                    waiter = Thread.currentThread();                &#125;            &#125;            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (waiting)                LockSupport.park(<span class="hljs-keyword">this</span>);<span class="hljs-comment">// 挂起当前线程</span>        &#125;    &#125;</code></pre><h3 id="线程安全机制"><a href="#线程安全机制" class="headerlink" title="线程安全机制"></a>线程安全机制</h3><p>synchronized、 CAS</p><p>通过一系列对volatile变量的Unsafe操作来保证读到最新的数据</p><pre><code class="hljs java"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> &lt;K,V&gt; <span class="hljs-function">Node&lt;K,V&gt; <span class="hljs-title">tabAt</span><span class="hljs-params">(Node&lt;K,V&gt;[] tab, <span class="hljs-keyword">int</span> i)</span> </span>&#123;    <span class="hljs-keyword">return</span> (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((<span class="hljs-keyword">long</span>)i &lt;&lt; ASHIFT) + ABASE);<span class="hljs-comment">// JDK源码中好多都是记录该值相对于当前对象的偏移量</span>&#125;<span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> &lt;K,V&gt; <span class="hljs-function"><span class="hljs-keyword">boolean</span> <span class="hljs-title">casTabAt</span><span class="hljs-params">(Node&lt;K,V&gt;[] tab, <span class="hljs-keyword">int</span> i,</span></span><span class="hljs-function"><span class="hljs-params">                                    Node&lt;K,V&gt; c, Node&lt;K,V&gt; v)</span> </span>&#123;    <span class="hljs-keyword">return</span> U.compareAndSwapObject(tab, ((<span class="hljs-keyword">long</span>)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125;<span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> &lt;K,V&gt; <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">setTabAt</span><span class="hljs-params">(Node&lt;K,V&gt;[] tab, <span class="hljs-keyword">int</span> i, Node&lt;K,V&gt; v)</span> </span>&#123;    U.putObjectVolatile(tab, ((<span class="hljs-keyword">long</span>)i &lt;&lt; ASHIFT) + ABASE, v);&#125;</code></pre><h3 id="功能-amp-实现-2"><a href="#功能-amp-实现-2" class="headerlink" title="功能 &amp; 实现"></a>功能 &amp; 实现</h3><h4 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h4><p>构造函数中没有任何操作，即使是有参数的构造函数，也只是设置<code>sizeCtl</code>等一些字段的值。</p><p>除非参数中有Map实例，会调用<code>putAll(map)</code>。 真正的初始化是在put()方法里。</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ConcurrentHashMap</span><span class="hljs-params">()</span> </span>&#123;&#125;<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ConcurrentHashMap</span><span class="hljs-params">(<span class="hljs-keyword">int</span> initialCapacity)</span> </span>&#123;    <span class="hljs-keyword">if</span> (initialCapacity &lt; <span class="hljs-number">0</span>)        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> IllegalArgumentException();    <span class="hljs-keyword">int</span> cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; <span class="hljs-number">1</span>)) ?               MAXIMUM_CAPACITY :               tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; <span class="hljs-number">1</span>) + <span class="hljs-number">1</span>));    <span class="hljs-keyword">this</span>.sizeCtl = cap;&#125;<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ConcurrentHashMap</span><span class="hljs-params">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;    <span class="hljs-keyword">this</span>.sizeCtl = DEFAULT_CAPACITY;    putAll(m);<span class="hljs-comment">// 只有传入map实例，才会调用put而真正初始化ConcurrentHashMap</span>&#125;</code></pre><h4 id="三个原子操作"><a href="#三个原子操作" class="headerlink" title="三个原子操作"></a>三个原子操作</h4><pre><code class="hljs java"><span class="hljs-comment">// 获取tab在i位置上的节点</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> &lt;K,V&gt; <span class="hljs-function">Node&lt;K,V&gt; <span class="hljs-title">tabAt</span><span class="hljs-params">(Node&lt;K,V&gt;[] tab, <span class="hljs-keyword">int</span> i)</span> </span>&#123;    <span class="hljs-keyword">return</span> (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((<span class="hljs-keyword">long</span>)i &lt;&lt; ASHIFT) + ABASE);&#125;<span class="hljs-comment">// CAS更新tab[i]</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> &lt;K,V&gt; <span class="hljs-function"><span class="hljs-keyword">boolean</span> <span class="hljs-title">casTabAt</span><span class="hljs-params">(Node&lt;K,V&gt;[] tab, <span class="hljs-keyword">int</span> i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v)</span> </span>&#123;    <span class="hljs-keyword">return</span> U.compareAndSwapObject(tab, ((<span class="hljs-keyword">long</span>)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125;<span class="hljs-comment">// 设置节点位置的值，只在持有锁的时候被调用</span><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> &lt;K,V&gt; <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">setTabAt</span><span class="hljs-params">(Node&lt;K,V&gt;[] tab, <span class="hljs-keyword">int</span> i, Node&lt;K,V&gt; v)</span> </span>&#123;    U.putObjectVolatile(tab, ((<span class="hljs-keyword">long</span>)i &lt;&lt; ASHIFT) + ABASE, v);&#125;</code></pre><h4 id="get-K-1"><a href="#get-K-1" class="headerlink" title="get(K)"></a>get(K)</h4><blockquote><p>使用volatile修饰变量，直接get，不会获取到旧值。</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> V <span class="hljs-title">get</span><span class="hljs-params">(Object key)</span> </span>&#123;  Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; <span class="hljs-keyword">int</span> n, eh; K ek;  <span class="hljs-keyword">int</span> h = spread(key.hashCode());<span class="hljs-comment">//散列 得到key在数组中的位置</span>  <span class="hljs-keyword">if</span> ((tab = table) != <span class="hljs-keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="hljs-number">0</span> &amp;&amp;      (e = tabAt(tab, (n - <span class="hljs-number">1</span>) &amp; h)) != <span class="hljs-keyword">null</span>) &#123;<span class="hljs-comment">// table不为空，table[i]不为空</span>      <span class="hljs-keyword">if</span> ((eh = e.hash) == h) &#123;          <span class="hljs-keyword">if</span> ((ek = e.key) == key || (ek != <span class="hljs-keyword">null</span> &amp;&amp; key.equals(ek)))              <span class="hljs-keyword">return</span> e.val;<span class="hljs-comment">// table[i]就是要找的 直接返回</span>      &#125;      <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (eh &lt; <span class="hljs-number">0</span>)<span class="hljs-comment">// 是转发节点 forwardingNode(正在扩容)，去新table中寻找</span>          <span class="hljs-keyword">return</span> (p = e.find(h, key)) != <span class="hljs-keyword">null</span> ? p.val : <span class="hljs-keyword">null</span>;      <span class="hljs-keyword">while</span> ((e = e.next) != <span class="hljs-keyword">null</span>) &#123;<span class="hljs-comment">// 遍历</span>          <span class="hljs-keyword">if</span> (e.hash == h &amp;&amp;              ((ek = e.key) == key || (ek != <span class="hljs-keyword">null</span> &amp;&amp; key.equals(ek))))              <span class="hljs-keyword">return</span> e.val;      &#125;  &#125;  <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;&#125;</code></pre></blockquote><h4 id="put-K-V-1"><a href="#put-K-V-1" class="headerlink" title="put(K, V)"></a>put(K, V)</h4><p>使用乐观锁cas + synchronized实现并发插入/更新，如果有锁竞争才synchronized锁定<code>head</code> / <code>root</code>，大致流程：</p><blockquote><ol><li><p>如果还没有初始化：先调用<code>initTable()</code>方法来进行初始化；</p></li><li><p>如果没有 hash 冲突：直接 CAS 插入；（即table[i]就一个node 或 table[i]还没有node）</p></li><li><p>如果正在进行扩容：就协助扩容；</p></li><li><p>如果存在 hash 冲突：</p><p>synchronized锁定table[i]处的节点 来保证线程安全，并根据链表当前的结构进行插入</p><ul><li>链表：直接遍历到尾端插入；</li><li>红黑树：按照红黑树结构插入；</li></ul></li><li><p>如果链表的长度&gt;=8，就再次调用<code>treeifyBin()</code>，尝试转换成红黑树；</p></li><li><p>最后调用<code>addCount()</code>方法统计<code>size</code>，并且检查是否需要扩容</p></li></ol></blockquote><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> V <span class="hljs-title">put</span><span class="hljs-params">(K key, V value)</span> </span>&#123;    <span class="hljs-keyword">return</span> putVal(key, value, <span class="hljs-keyword">false</span>);&#125;<span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> <span class="hljs-title">spread</span><span class="hljs-params">(<span class="hljs-keyword">int</span> h)</span> </span>&#123;<span class="hljs-comment">// 其实就是取hash值</span>    <span class="hljs-keyword">return</span> (h ^ (h &gt;&gt;&gt; <span class="hljs-number">16</span>)) &amp; HASH_BITS;<span class="hljs-comment">// HASH_BITS = 0x7fffffff</span>&#125;<span class="hljs-comment">/** Implementation for put and putIfAbsent */</span><span class="hljs-function"><span class="hljs-keyword">final</span> V <span class="hljs-title">putVal</span><span class="hljs-params">(K key, V value, <span class="hljs-keyword">boolean</span> onlyIfAbsent)</span> </span>&#123;    <span class="hljs-keyword">if</span> (key == <span class="hljs-keyword">null</span> || value == <span class="hljs-keyword">null</span>) <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NullPointerException();    <span class="hljs-keyword">int</span> hash = spread(key.hashCode());    <span class="hljs-keyword">int</span> binCount = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span> (Node&lt;K,V&gt;[] tab = table;;) &#123;        Node&lt;K,V&gt; f; <span class="hljs-keyword">int</span> n, i, fh;        <span class="hljs-keyword">if</span> (tab == <span class="hljs-keyword">null</span> || (n = tab.length) == <span class="hljs-number">0</span>)<span class="hljs-comment">// 1：还未初始化</span>            tab = initTable();        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((f = tabAt(tab, i = (n - <span class="hljs-number">1</span>) &amp; hash)) == <span class="hljs-keyword">null</span>) &#123;<span class="hljs-comment">// 2：对应的位置没有node</span>            <span class="hljs-keyword">if</span> (casTabAt(tab, i, <span class="hljs-keyword">null</span>, <span class="hljs-keyword">new</span> Node&lt;K,V&gt;(hash, key, value, <span class="hljs-keyword">null</span>)))                <span class="hljs-keyword">break</span>;<span class="hljs-comment">// no lock when adding to empty bin（添加到空容器中不加锁）</span>            <span class="hljs-comment">// CAS成功才会break，否则接着for循环</span>        &#125;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((fh = f.hash) == MOVED)<span class="hljs-comment">// 3：正在扩容（table[i]这个节点是个forwardingNode）</span>            tab = helpTransfer(tab, f);<span class="hljs-comment">// 协助扩容</span>        <span class="hljs-keyword">else</span> &#123;<span class="hljs-comment">// 4：存在hash冲突</span>            V oldVal = <span class="hljs-keyword">null</span>;            <span class="hljs-keyword">synchronized</span> (f) &#123;<span class="hljs-comment">// 锁定 table[i]链表的头结点</span>                <span class="hljs-keyword">if</span> (tabAt(tab, i) == f) &#123;                    <span class="hljs-keyword">if</span> (fh &gt;= <span class="hljs-number">0</span>) &#123;<span class="hljs-comment">// hash值正常</span>                        binCount = <span class="hljs-number">1</span>;<span class="hljs-comment">// 记录链表有多少个node</span>                        <span class="hljs-keyword">for</span> (Node&lt;K,V&gt; e = f;; ++binCount) &#123;                            K ek;                            <span class="hljs-keyword">if</span> (e.hash == hash &amp;&amp;                                ((ek = e.key) == key || (ek != <span class="hljs-keyword">null</span> &amp;&amp; key.equals(ek)))) &#123;                                oldVal = e.val;                                <span class="hljs-comment">//onlyIfAbsent:只在不存在的时候执行 true:不覆盖旧value; false:覆盖旧value</span>                                <span class="hljs-keyword">if</span> (!onlyIfAbsent)                                    e.val = value;<span class="hljs-comment">// 覆盖value</span>                                <span class="hljs-keyword">break</span>;<span class="hljs-comment">// 完事</span>                            &#125;                            Node&lt;K,V&gt; pred = e;<span class="hljs-comment">// 保留当前node的指针，e指向下一个node</span>                            <span class="hljs-keyword">if</span> ((e = e.next) == <span class="hljs-keyword">null</span>) &#123;<span class="hljs-comment">// 没有下一个就加到tail</span>                                pred.next = <span class="hljs-keyword">new</span> Node&lt;K,V&gt;(hash, key, value, <span class="hljs-keyword">null</span>);                                <span class="hljs-keyword">break</span>;                            &#125;                        &#125;                    &#125;                    <span class="hljs-comment">// fh&lt;0（红黑树节点的hash都是-2）</span>                    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (f <span class="hljs-keyword">instanceof</span> TreeBin) &#123;<span class="hljs-comment">// 红黑树结构 </span>                        Node&lt;K,V&gt; p;                        binCount = <span class="hljs-number">2</span>;<span class="hljs-comment">// 最少有两个node</span>                        <span class="hljs-keyword">if</span> ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != <span class="hljs-keyword">null</span>) &#123;                            <span class="hljs-comment">// put红黑树节点，可能是插入一个节点，可能是替换一个节点的val，这个方法返回对应的节点</span>                            oldVal = p.val;                            <span class="hljs-keyword">if</span> (!onlyIfAbsent) <span class="hljs-comment">// 决定是否覆盖oldValue</span>                                p.val = value;                        &#125;                    &#125;                &#125;            &#125;            <span class="hljs-comment">// 最后计算数量</span>            <span class="hljs-keyword">if</span> (binCount != <span class="hljs-number">0</span>) &#123;                <span class="hljs-keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD)                    treeifyBin(tab, i);<span class="hljs-comment">// 节点数&gt;=8 申请转化为红黑树</span>                <span class="hljs-keyword">if</span> (oldVal != <span class="hljs-keyword">null</span>)                    <span class="hljs-keyword">return</span> oldVal; <span class="hljs-comment">// 返回非空oldValue</span>                <span class="hljs-keyword">break</span>;            &#125;        &#125;    &#125;    addCount(<span class="hljs-number">1L</span>, binCount);<span class="hljs-comment">// 统计size</span>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;&#125;</code></pre><h4 id="initTable-初始化table"><a href="#initTable-初始化table" class="headerlink" title="initTable() 初始化table"></a>initTable() 初始化table</h4><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Node&lt;K,V&gt;[] initTable() &#123;    Node&lt;K,V&gt;[] tab; <span class="hljs-keyword">int</span> sc;    <span class="hljs-keyword">while</span> ((tab = table) == <span class="hljs-keyword">null</span> || tab.length == <span class="hljs-number">0</span>) &#123;        <span class="hljs-keyword">if</span> ((sc = sizeCtl) &lt; <span class="hljs-number">0</span>)<span class="hljs-comment">// 说明有其他线程正在扩容</span>            Thread.yield(); <span class="hljs-comment">// lost initialization race; just spin   自旋等待初始化完成。</span>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (U.compareAndSwapInt(<span class="hljs-keyword">this</span>, SIZECTL, sc, -<span class="hljs-number">1</span>)) &#123;<span class="hljs-comment">// cas设置sc为-1，表示正在初始化</span>            <span class="hljs-keyword">try</span> &#123;                <span class="hljs-keyword">if</span> ((tab = table) == <span class="hljs-keyword">null</span> || tab.length == <span class="hljs-number">0</span>) &#123;                    <span class="hljs-keyword">int</span> n = (sc &gt; <span class="hljs-number">0</span>) ? sc : DEFAULT_CAPACITY;<span class="hljs-comment">// sc为正数标识阈值</span>                    <span class="hljs-meta">@SuppressWarnings(&quot;unchecked&quot;)</span>                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="hljs-keyword">new</span> Node&lt;?,?&gt;[n];                    table = tab = nt;                    sc = n - (n &gt;&gt;&gt; <span class="hljs-number">2</span>);<span class="hljs-comment">// 并设置阈值。size达到sc就扩容。</span>                    <span class="hljs-comment">// &gt;&gt;&gt;2就是/4,  n-n/4就是n=n*0.75呗</span>                &#125;            &#125; <span class="hljs-keyword">finally</span> &#123;                sizeCtl = sc;<span class="hljs-comment">// 更新sizeCtl属性</span>            &#125;            <span class="hljs-keyword">break</span>;        &#125;    &#125;    <span class="hljs-keyword">return</span> tab;&#125;</code></pre><h4 id="helpTransfer-协助扩容"><a href="#helpTransfer-协助扩容" class="headerlink" title="helpTransfer() 协助扩容"></a>helpTransfer() 协助扩容</h4><pre><code class="hljs java"><span class="hljs-keyword">final</span> Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123;    Node&lt;K,V&gt;[] nextTab; <span class="hljs-keyword">int</span> sc;    <span class="hljs-keyword">if</span> (tab != <span class="hljs-keyword">null</span> &amp;&amp; (f <span class="hljs-keyword">instanceof</span> ForwardingNode) &amp;&amp; <span class="hljs-comment">// f是正在转化的node</span>        (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != <span class="hljs-keyword">null</span>) &#123;<span class="hljs-comment">// 并且 newTable已经存在</span>        <span class="hljs-keyword">int</span> rs = resizeStamp(tab.length);        <span class="hljs-keyword">while</span> (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; <span class="hljs-comment">// 验证newTable和oldTable</span>               (sc = sizeCtl) &lt; <span class="hljs-number">0</span>) &#123;<span class="hljs-comment">// 并且sc是正在扩容</span>            <span class="hljs-keyword">if</span> ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + <span class="hljs-number">1</span> ||                sc == rs + MAX_RESIZERS || transferIndex &lt;= <span class="hljs-number">0</span>)                <span class="hljs-keyword">break</span>;            <span class="hljs-keyword">if</span> (U.compareAndSwapInt(<span class="hljs-keyword">this</span>, SIZECTL, sc, sc + <span class="hljs-number">1</span>)) &#123;                transfer(tab, nextTab);<span class="hljs-comment">// 调用扩容方法</span>                <span class="hljs-keyword">break</span>;            &#125;        &#125;        <span class="hljs-keyword">return</span> nextTab;    &#125;    <span class="hljs-keyword">return</span> table;&#125;</code></pre><h4 id="transfer-扩容"><a href="#transfer-扩容" class="headerlink" title="transfer() 扩容"></a>transfer() 扩容</h4><blockquote><p>参与扩容的线程领取扩容子任务时，要减去的扩容步长，如果能减成功,则成功领取一个扩容子任务<br>transferIndex = transferIndex - stride(扩容步长)<br>transferIndex减到0时,代表没有可以领取的扩容子任务<br>每个线程一次转移一个区间段的数据，一个区间段（转移步长）的默认长度是16，实际运行过程中会动态计算(最小16)</p></blockquote><h5 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h5><blockquote><ol><li><p>开辟新table空间：<code>nextTable</code></p></li><li><p>遍历table，计算当前线程的步长(拿到自己的子任务)  —– 每个线程都会计算自己能拿到的任务，以此方式协作！</p></li><li><p>执行自己的任务，从后往前遍历（table[15]-&gt;table[0]）</p><blockquote><p>比如16扩容到32，就是从15遍历到0，不会有其他线程再参与扩容了(因为最小步长16)</p></blockquote><p>对table[i]的 链表 / 红黑树 进行遍历</p><ul><li><p>链表（两次for遍历）</p><blockquote><ol><li><p>找到链表尾端(newindex都相同的)最长子链表(图1的678)，并设置下次遍历的终点<code>lastRun</code>为这个子链表的head(图1的6)</p></li><li><p>再次遍历table[i]，for [head,  <code>lastRun</code>) （lastRun就比如图1的6）</p><blockquote><p>使用<strong>头插法</strong>把node都插入到新low链表/新high链表的前边。</p></blockquote><p>结果会是有一个新链表的顺序会倒置（不是第一次for拿出的子链表）（图1的结果：5123 和 4678）</p></li></ol></blockquote></li><li><p>红黑树</p></li></ul></li><li><p>把新链表放到新table对应的索引位</p></li></ol></blockquote><h5 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h5><pre><code class="hljs java"><span class="hljs-comment">// Moves and/or copies the nodes in each bin to new table. 将所有node移动到新table中</span><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">transfer</span><span class="hljs-params">(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab)</span> </span>&#123;    <span class="hljs-comment">// ---------------- 1：给当前线程分配任务</span>    <span class="hljs-keyword">int</span> n = tab.length, stride;<span class="hljs-comment">// stride：步长，每个线程负责table中一步之内的所有链表</span>    <span class="hljs-keyword">if</span> ((stride = (NCPU &gt; <span class="hljs-number">1</span>) ? (n &gt;&gt;&gt; <span class="hljs-number">3</span>) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)        stride = MIN_TRANSFER_STRIDE; <span class="hljs-comment">// subdivide range 细分范围  </span>    <span class="hljs-comment">// 最少16，也就是从16扩容到32的时候只会有一个线程参与扩容</span>    <span class="hljs-keyword">if</span> (nextTab == <span class="hljs-keyword">null</span>) &#123;            <span class="hljs-comment">// initiating</span>        <span class="hljs-keyword">try</span> &#123;            <span class="hljs-meta">@SuppressWarnings(&quot;unchecked&quot;)</span>            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="hljs-keyword">new</span> Node&lt;?,?&gt;[n &lt;&lt; <span class="hljs-number">1</span>];<span class="hljs-comment">// newTable容量为原来的两倍</span>            nextTab = nt;        &#125; <span class="hljs-keyword">catch</span> (Throwable ex) &#123;      <span class="hljs-comment">// try to cope with OOME ..尝试处理OOM</span>            sizeCtl = Integer.MAX_VALUE;            <span class="hljs-keyword">return</span>;        &#125;        nextTable = nextTab;        transferIndex = n;<span class="hljs-comment">// 当前线程的扩容任务是从 n开始</span>    &#125;    <span class="hljs-comment">// ---------------- 2：执行当前线程的扩容子任务（遍历当前线程负责的一步范围内所有的链表）</span>    <span class="hljs-keyword">int</span> nextn = nextTab.length;    ForwardingNode&lt;K,V&gt; fwd = <span class="hljs-keyword">new</span> ForwardingNode&lt;K,V&gt;(nextTab);<span class="hljs-comment">// 创建forward节点</span>    <span class="hljs-keyword">boolean</span> advance = <span class="hljs-keyword">true</span>;    <span class="hljs-keyword">boolean</span> finishing = <span class="hljs-keyword">false</span>; <span class="hljs-comment">// to ensure sweep before committing nextTab 确保在提交nextTab之前扫描</span>    <span class="hljs-comment">// i 指当前处理的槽位序号， bound 指需要处理的槽位边界，先处理槽位15的节点</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>, bound = <span class="hljs-number">0</span>;;) &#123;<span class="hljs-comment">// 遍历当前线程负责的一步范围内所有的链表</span>        Node&lt;K,V&gt; f; <span class="hljs-keyword">int</span> fh;        <span class="hljs-comment">// ---------------- 2.1：自旋设置transferIndex的值 并初始化i 和 bound</span>        <span class="hljs-keyword">while</span> (advance) &#123;            <span class="hljs-keyword">int</span> nextIndex, nextBound;            <span class="hljs-keyword">if</span> (--i &gt;= bound || finishing)                advance = <span class="hljs-keyword">false</span>;            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((nextIndex = transferIndex) &lt;= <span class="hljs-number">0</span>) &#123;                i = -<span class="hljs-number">1</span>;                advance = <span class="hljs-keyword">false</span>;            &#125;            <span class="hljs-comment">// cas设置transferIndex属性的值</span>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (U.compareAndSwapInt (<span class="hljs-keyword">this</span>, TRANSFERINDEX, nextIndex,                      nextBound = (nextIndex &gt; stride ? nextIndex - stride : <span class="hljs-number">0</span>))                    ) &#123;                bound = nextBound;                i = nextIndex - <span class="hljs-number">1</span>;<span class="hljs-comment">// 初始化 i 和 bound</span>                advance = <span class="hljs-keyword">false</span>;            &#125;        &#125;        <span class="hljs-comment">// ----------------↓↓ todo ??</span>        <span class="hljs-keyword">if</span> (i &lt; <span class="hljs-number">0</span> || i &gt;= n || i + n &gt;= nextn) &#123;<span class="hljs-comment">// todo ??</span>            <span class="hljs-keyword">int</span> sc;            <span class="hljs-keyword">if</span> (finishing) &#123;<span class="hljs-comment">// 如果已经复制完所有节点</span>                nextTable = <span class="hljs-keyword">null</span>;                table = nextTab;<span class="hljs-comment">// table变量 指向新table</span>                sizeCtl = (n &lt;&lt; <span class="hljs-number">1</span>) - (n &gt;&gt;&gt; <span class="hljs-number">1</span>);<span class="hljs-comment">// sc= n*2 - n/2 相当于 sc=n*1.5，阈值变为oldCap的1.5倍</span>                <span class="hljs-keyword">return</span>;            &#125;            <span class="hljs-keyword">if</span> (U.compareAndSwapInt(<span class="hljs-keyword">this</span>, SIZECTL, sc = sizeCtl, sc - <span class="hljs-number">1</span>)) &#123;<span class="hljs-comment">// cas替换sc的值，通知其他线程 多了一个线程参与扩容</span>                <span class="hljs-keyword">if</span> ((sc - <span class="hljs-number">2</span>) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)                    <span class="hljs-keyword">return</span>;                finishing = advance = <span class="hljs-keyword">true</span>;                i = n; <span class="hljs-comment">// recheck before commit</span>            &#125;        &#125;        <span class="hljs-comment">// ----------------↑↑ todo ??</span>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((f = tabAt(tab, i)) == <span class="hljs-keyword">null</span>)<span class="hljs-comment">// 如果节点为null，通过cas将forward节点放到该位置</span>            advance = casTabAt(tab, i, <span class="hljs-keyword">null</span>, fwd);        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((fh = f.hash) == MOVED) <span class="hljs-comment">// 如果该节点已经是forward节点</span>            advance = <span class="hljs-keyword">true</span>; <span class="hljs-comment">// already processed</span>        <span class="hljs-keyword">else</span> &#123; <span class="hljs-comment">// ---------------- 2.2：执行任务，把table[i]这个链表 转移到nextTable</span>            <span class="hljs-keyword">synchronized</span> (f) &#123;<span class="hljs-comment">// 对节点加锁</span>                <span class="hljs-keyword">if</span> (tabAt(tab, i) == f) &#123;                    Node&lt;K,V&gt; ln, hn;<span class="hljs-comment">// newIndex两种可能：oldIndex 或 oldIndex+oldCap</span>                    <span class="hljs-comment">// ---------------- 2.2.0：链表</span>                    <span class="hljs-keyword">if</span> (fh &gt;= <span class="hljs-number">0</span>) &#123;                        <span class="hljs-comment">//n:oldCap，unBit是否为0 表示这个节点是在low还是high</span>                        <span class="hljs-keyword">int</span> runBit = fh &amp; n;                        Node&lt;K,V&gt; lastRun = f;<span class="hljs-comment">// 记录最后需要处理的节点</span>                        <span class="hljs-comment">// ---------------- 2.2.1：遍历链表</span>                        <span class="hljs-keyword">for</span> (Node&lt;K,V&gt; p = f.next; p != <span class="hljs-keyword">null</span>; p = p.next) &#123;                            <span class="hljs-keyword">int</span> b = p.hash &amp; n;<span class="hljs-comment">// mask之后是否为0</span>                            <span class="hljs-keyword">if</span> (b != runBit) &#123;<span class="hljs-comment">// 如果节点p和节点f 的newIndex不同 如图1，p是节点4时才会第一次进入这个if</span>                                runBit = b;<span class="hljs-comment">// 更新runBit</span>                                lastRun = p;<span class="hljs-comment">// 更新要处理的节点</span>                            &#125;                        &#125;                        <span class="hljs-comment">// 这次for结束后，lastRun及其后所有节点newIndex均一致，如&#x27;图1&#x27;中的678，6是lastRun</span>                        <span class="hljs-keyword">if</span> (runBit == <span class="hljs-number">0</span>) &#123;<span class="hljs-comment">// 将lastRun截下来放到新table中对应的槽</span>                            ln = lastRun;                            hn = <span class="hljs-keyword">null</span>;                        &#125;                        <span class="hljs-keyword">else</span> &#123;                            hn = lastRun;                            ln = <span class="hljs-keyword">null</span>;                        &#125;                        <span class="hljs-comment">// ---------------- 2.2.1：再次遍历链表，范围：[head, lastRun)</span>                        <span class="hljs-keyword">for</span> (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123;                            <span class="hljs-keyword">int</span> ph = p.hash; K pk = p.key; V pv = p.val;                            <span class="hljs-comment">// 正向遍历，头插法，所以另一个newIndex的链表(图1中的蓝色)节点会倒置</span>                            <span class="hljs-keyword">if</span> ((ph &amp; n) == <span class="hljs-number">0</span>)                                ln = <span class="hljs-keyword">new</span> Node&lt;K,V&gt;(ph, pk, pv, <span class="hljs-comment">/*next*/</span>ln);<span class="hljs-comment">// 构造函数第四个参数是next，懂了吧。头插法</span>                            <span class="hljs-keyword">else</span>                                hn = <span class="hljs-keyword">new</span> Node&lt;K,V&gt;(ph, pk, pv, hn);                        &#125;                        <span class="hljs-comment">// ---------------- 2.2.2：放到newTab中对应的index，完活</span>                        setTabAt(nextTab, i, ln);                        setTabAt(nextTab, i + n, hn);                        setTabAt(tab, i, fwd);<span class="hljs-comment">// 在table i 位置处插上ForwardingNode 表示该节点已经处理过了</span>                        advance = <span class="hljs-keyword">true</span>;                    &#125;                    <span class="hljs-comment">// ---------------- 2.2.0：红黑树 </span>                    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (f <span class="hljs-keyword">instanceof</span> TreeBin) &#123;                        TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;                        TreeNode&lt;K,V&gt; lo = <span class="hljs-keyword">null</span>, loTail = <span class="hljs-keyword">null</span>;<span class="hljs-comment">// newIndex为low的槽 对应的root和tail</span>                        TreeNode&lt;K,V&gt; hi = <span class="hljs-keyword">null</span>, hiTail = <span class="hljs-keyword">null</span>;<span class="hljs-comment">// newIndex为high的槽 对应的root和tail</span>                        <span class="hljs-keyword">int</span> lc = <span class="hljs-number">0</span>, hc = <span class="hljs-number">0</span>;<span class="hljs-comment">// 记录新table中 low槽和high槽的节点数，后边会检查是否需要转为链表结构</span>                        <span class="hljs-keyword">for</span> (Node&lt;K,V&gt; e = t.first; e != <span class="hljs-keyword">null</span>; e = e.next) &#123;                            <span class="hljs-keyword">int</span> h = e.hash;                            TreeNode&lt;K,V&gt; p = <span class="hljs-keyword">new</span> TreeNode&lt;K,V&gt;                                (h, e.key, e.val, <span class="hljs-comment">/*next*/</span><span class="hljs-keyword">null</span>, <span class="hljs-comment">/*parent*/</span><span class="hljs-keyword">null</span>);                            <span class="hljs-keyword">if</span> ((h &amp; n) == <span class="hljs-number">0</span>) &#123;<span class="hljs-comment">// low槽</span>                                <span class="hljs-keyword">if</span> ((p.prev = loTail) == <span class="hljs-keyword">null</span>)                                    lo = p;                                <span class="hljs-keyword">else</span>                                    loTail.next = p;                                loTail = p;                                ++lc;                            &#125;                            <span class="hljs-keyword">else</span> &#123;<span class="hljs-comment">// high槽</span>                                <span class="hljs-keyword">if</span> ((p.prev = hiTail) == <span class="hljs-keyword">null</span>)                                    hi = p;                                <span class="hljs-keyword">else</span>                                    hiTail.next = p;                                hiTail = p;                                ++hc;                            &#125;                        &#125;                        <span class="hljs-comment">// 如果扩容后节点数&lt;6 转为链表</span>                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :                        (hc != <span class="hljs-number">0</span>) ? <span class="hljs-keyword">new</span> TreeBin&lt;K,V&gt;(lo) : t;                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :                        (lc != <span class="hljs-number">0</span>) ? <span class="hljs-keyword">new</span> TreeBin&lt;K,V&gt;(hi) : t;                        <span class="hljs-comment">// 放到新table对应的槽，完活</span>                        setTabAt(nextTab, i, ln);                        setTabAt(nextTab, i + n, hn);                        setTabAt(tab, i, fwd);                        advance = <span class="hljs-keyword">true</span>;                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;</code></pre><blockquote><p>图1：</p><img alt="节点newIndex不同的链表，图在github" src="https://raw.githubusercontent.com/melopoz/pics/master/img/%E8%8A%82%E7%82%B9newIndex%E4%B8%8D%E5%90%8C%E7%9A%84%E9%93%BE%E8%A1%A8.png" style="zoom:50%;" /><p>这个链表最后会变成  <code>5-&gt;3-&gt;2-&gt;1</code> 和 <code>4-&gt;6-&gt;7-&gt;8</code></p></blockquote><h4 id="addCount-统计size"><a href="#addCount-统计size" class="headerlink" title="addCount()  统计size"></a>addCount()  统计size</h4><pre><code class="hljs java"><span class="hljs-meta">@sun</span>.misc.Contended <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CounterCell</span> </span>&#123;    <span class="hljs-keyword">volatile</span> <span class="hljs-keyword">long</span> value;    CounterCell(<span class="hljs-keyword">long</span> x) &#123; value = x; &#125;&#125;<span class="hljs-function"><span class="hljs-keyword">final</span> <span class="hljs-keyword">long</span> <span class="hljs-title">sumCount</span><span class="hljs-params">()</span> </span>&#123;    CounterCell[] as = counterCells; CounterCell a;    <span class="hljs-keyword">long</span> sum = baseCount;    <span class="hljs-keyword">if</span> (as != <span class="hljs-keyword">null</span>) &#123;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; as.length; ++i) &#123;            <span class="hljs-keyword">if</span> ((a = as[i]) != <span class="hljs-keyword">null</span>)                sum += a.value;        &#125;    &#125;    <span class="hljs-keyword">return</span> sum;&#125;<span class="hljs-meta">@sun</span>.misc.Contended <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CounterCell</span> </span>&#123;    <span class="hljs-keyword">volatile</span> <span class="hljs-keyword">long</span> value;    CounterCell(<span class="hljs-keyword">long</span> x) &#123; value = x; &#125;&#125;<span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">addCount</span><span class="hljs-params">(<span class="hljs-keyword">long</span> x, <span class="hljs-keyword">int</span> check)</span> </span>&#123;    CounterCell[] as; <span class="hljs-keyword">long</span> b, s;    <span class="hljs-comment">// 初始化时counterCells为空，在并发量很高时，如果存在两个线程同时执行CAS修改baseCount值，</span>    <span class="hljs-comment">// 则失败的线程会继续执行方法体中的逻辑，使用CounterCell记录元素个数的变化</span>    <span class="hljs-keyword">if</span> ((as = counterCells) != <span class="hljs-keyword">null</span> ||        !U.compareAndSwapLong(<span class="hljs-keyword">this</span>, BASECOUNT, b = baseCount, s = b + x)) &#123;        <span class="hljs-comment">// 使用CounterCell记录元素个数的变化</span>        CounterCell a; <span class="hljs-keyword">long</span> v; <span class="hljs-keyword">int</span> m;        <span class="hljs-keyword">boolean</span> uncontended = <span class="hljs-keyword">true</span>;        <span class="hljs-comment">// 如果CounterCell数组counterCells为空，调用fullAddCount()方法进行初始化，</span>        <span class="hljs-comment">// 并插入对应的记录数，通过CAS设置cellsBusy字段，只有设置成功的线程才能初始化CounterCell数组</span>        <span class="hljs-keyword">if</span> (as == <span class="hljs-keyword">null</span> || (m = as.length - <span class="hljs-number">1</span>) &lt; <span class="hljs-number">0</span> ||            (a = as[ThreadLocalRandom.getProbe() &amp; m]) == <span class="hljs-keyword">null</span> ||            !(uncontended =              U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123;            fullAddCount(x, uncontended);            <span class="hljs-keyword">return</span>;        &#125;        <span class="hljs-keyword">if</span> (check &lt;= <span class="hljs-number">1</span>)            <span class="hljs-keyword">return</span>;        s = sumCount();    &#125;    <span class="hljs-keyword">if</span> (check &gt;= <span class="hljs-number">0</span>) &#123;        Node&lt;K,V&gt;[] tab, nt; <span class="hljs-keyword">int</span> n, sc;        <span class="hljs-keyword">while</span> (s &gt;= (<span class="hljs-keyword">long</span>)(sc = sizeCtl) &amp;&amp; (tab = table) != <span class="hljs-keyword">null</span> &amp;&amp;               (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123;            <span class="hljs-keyword">int</span> rs = resizeStamp(n);            <span class="hljs-keyword">if</span> (sc &lt; <span class="hljs-number">0</span>) &#123;                <span class="hljs-keyword">if</span> ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + <span class="hljs-number">1</span> ||                    sc == rs + MAX_RESIZERS || (nt = nextTable) == <span class="hljs-keyword">null</span> ||                    transferIndex &lt;= <span class="hljs-number">0</span>)                    <span class="hljs-keyword">break</span>;                <span class="hljs-keyword">if</span> (U.compareAndSwapInt(<span class="hljs-keyword">this</span>, SIZECTL, sc, sc + <span class="hljs-number">1</span>))                    transfer(tab, nt);            &#125;            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (U.compareAndSwapInt(<span class="hljs-keyword">this</span>, SIZECTL, sc,                                         (rs &lt;&lt; RESIZE_STAMP_SHIFT) + <span class="hljs-number">2</span>))                transfer(tab, <span class="hljs-keyword">null</span>);            s = sumCount();        &#125;    &#125;&#125;</code></pre><p>todo addCount       T.T </p><p>图1来自  <a href="https://www.jianshu.com/p/0e435f39e796">https://www.jianshu.com/p/0e435f39e796</a>  ，正好看看dalao对addCount怎么说的，还有红黑树</p><p>todo 红黑树 <a href="https://blog.csdn.net/v_july_v/article/details/6105630">https://blog.csdn.net/v_july_v/article/details/6105630</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="1-7和1-8区别（1-8的优化）"><a href="#1-7和1-8区别（1-8的优化）" class="headerlink" title="1.7和1.8区别（1.8的优化）"></a>1.7和1.8区别（1.8的优化）</h3><ol><li><p>1.8 的结构和HashMap大致相同（1.7的ConcurrentHashMap其实就和1.8的HashMap差不多了）；</p></li><li><p>1.8 取消segment分段锁，不用ReentrantLock了，而是使用很多乐观锁-自旋CAS，</p><p>乐观失败就用synchronized锁定table[i]的链表的head。锁粒度更细，并发性高；</p><blockquote><p>锁粒度降低，synchronized并不比ReentrantLock差了。</p><p>本来ReentrantLock的Condition可以在粗粒度的场景中提高性能（我觉得算是变相降低锁粒度吧）。</p><p>锁粒度降下来之后，ReentrantLock就没必要了。</p><blockquote><p>而且synchronized可以基于jvm优化，使用关键字比使用api确实更加自然。</p></blockquote><blockquote><p>数据量很大的话，使用基于 api 的 ReentrantLock 会比 synchronized 占用更多的内存</p></blockquote></blockquote></li><li><p>可以协助扩容，扩容的时候1.8用到了头插法，部分node顺序会倒置；</p></li><li><p>高效更新元素个数，类似LongAdder 。。。？todo</p></li></ol><h3 id="HashMap和ConcurrentHashMap的区别"><a href="#HashMap和ConcurrentHashMap的区别" class="headerlink" title="HashMap和ConcurrentHashMap的区别"></a>HashMap和ConcurrentHashMap的区别</h3><ol><li>HashMap线程不安全，..；</li><li>ConcurrentHashMap扩容的时候会先拿当前线程的子任务（步长 <code>stride</code>），HashMap没这么多事；</li><li>ConcurrentHashMap扩容的时候有用到头插法，部分node的顺序会倒置，而HashMap用的尾插法；</li><li>1.7的ConcurrentHashMap的put和get操作都要两次hash</li></ol>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JUC</tag>
      
      <tag>java1.8优化</tag>
      
      <tag>hash优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>I/O base Linux</title>
    <link href="/blog/2020/01/01/OS_Linux_IO%E6%A8%A1%E5%9E%8B/"/>
    <url>/blog/2020/01/01/OS_Linux_IO%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p>I/O 简单点说就是：读取/写入 若干字节 从/到 <strong>单个文件描述符</strong>，用户进程需要调用内核并由内核来完成IO操作。</p><p>用户态的进程调用read()其实是有<a href="https://melopoz.github.io/blog/2021/01/01/OS/#%E7%BC%93%E5%AD%98IO">缓存IO</a>的，会有两次拷贝过程（内核将数据从磁盘/设备拷贝到内核空间，再从内核空间拷贝到用户空间）。</p><ul><li><p>阻塞 / 非阻塞</p><ul><li><p>阻塞：如果文件描述符不处于就绪状态则<strong>阻塞直到其就绪</strong></p></li><li><p>非阻塞：如果文件描述符不处于就绪状态则<strong>返回一个错误码</strong>，比如 <code>EAGAIN</code></p></li></ul></li><li><p>同步 / 异步</p><blockquote><p>同步和异步 是指 函数返回之时， 能不能保证任务完成。</p><p>比如调用了read()直接返回了一个Future对象，你需要再调Future的函数来获取read()的结果。</p></blockquote><ul><li>同步 IO 操作将导致请求的进程一直被阻塞，直到 IO 操作完成。从这个层次来，阻塞 IO、非阻塞 IO 操作、IO 多路复用都是同步 IO</li><li>异步 IO 操作不会导致请求的进程被阻塞。当发出 IO 操作请求，直接返回，等待 IO 操作完成后，再通知调用进程。</li></ul></li></ul><h1 id="Linux-五种-IO模型"><a href="#Linux-五种-IO模型" class="headerlink" title="Linux 五种 IO模型"></a>Linux 五种 IO模型</h1><img alt="IO模型时序图" src="https://raw.githubusercontent.com/melopoz/pics/master/img/IO%E6%A8%A1%E5%9E%8B%E6%97%B6%E5%BA%8F%E5%9B%BE.png" style="zoom:33%;" /><h3 id="同步阻塞-BIO"><a href="#同步阻塞-BIO" class="headerlink" title="同步阻塞-BIO"></a>同步阻塞-BIO</h3><blockquote><p>blocking IO，用户进程 阻塞等待 kernel 返回结果，kernel 阻塞等待 fd读写完毕再返回结果。</p></blockquote><ul><li>在IO执行的两个阶段都被block了；</li><li>只需要一次系统调用（read）；</li><li>一个线程（进程）只能处理一个fd的IO；</li><li>数据处理最及时；</li><li>内核实现简单。</li></ul><h3 id="同步非阻塞-NIO"><a href="#同步非阻塞-NIO" class="headerlink" title="同步非阻塞 -NIO"></a>同步非阻塞 -NIO</h3><blockquote><p>  non-blocking IO</p></blockquote><blockquote><p>用户态调用内核会直接得到结果，因为内核不等待读真正完成就返回结果（未完成就返回ERROR）。</p><p>用户态得到的结果如果并不是已完成，就不断轮询，轮询期间也可以做别的事情。</p><blockquote><p>非阻塞将<code>大整片时间的阻塞</code>分成<code>N 多的小片时间的阻塞</code>，所以进程不断地有机会拿到CPU时间片。</p></blockquote><p>当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error。用户进程可以再次发送 read 操作。</p><p>一旦 kernel 中的数据准备好了，并且再次收到了用户进程的 system call，那么它就将数据（从内核空间）拷贝到了用户内存，然后返回。</p></blockquote><ul><li>需要由用户进程轮询自己关注的fd数据是否准备好了（用户进程调用 kernel 函数 read/recvfrom）；</li><li>只需要一次系统调用（read）；</li><li>一个线程（进程）只能处理一个fd的IO。</li></ul><h3 id="IO多路复用"><a href="#IO多路复用" class="headerlink" title="IO多路复用"></a>IO多路复用</h3><blockquote><p>I/O多路复用（IO multiplexing）是由 <strong>kernel</strong> 监视（轮询）<strong>多个fd</strong>，一旦某个fd就绪（读就绪/写就绪），就通知用户进程进行相应的读写操作。</p><blockquote><p>比如Linux的<a href="#select/poll/epoll">select/poll/epoll</a>，macOS的<code>kqueue</code>。</p></blockquote></blockquote><p>用户进程阻塞在<code>select/poll/epoll</code>函数上，这些函数只用来返回客户进程感兴趣的fd是否IO就绪；</p><p>用户进程得知fd已就绪后，需要再次调用读写操作来进行IO读写。</p><ul><li>需要两次系统调用（而且[IO多路复用 第二步读取 推荐用非阻塞函数](#IO多路复用 第二步读取 推荐用非阻塞函数)）；</li><li>将一个用户进程要处理的多个fd的IO都阻塞在一个函数上（不用创建多个代价高昂的线程就达到了提升性能的目的），而BIO会有n次阻塞；</li><li>系统开销小</li><li>其实也是同步阻塞模型</li></ul><blockquote><p>在网络编程中，如果处理的连接数不是很高的话，使用<code>select/epoll</code>的不一定比使用<code>多线程 + blocking IO</code>性能更好（线程上下文切换带来的开销因为线程数量少所以可以忽略），可能延迟还更大。</p></blockquote><p>IO多路复用优势并不是对于单个连接能处理得更快，而是在于能用少量线程处理大量的连接。</p><h3 id="异步IO-AIO"><a href="#异步IO-AIO" class="headerlink" title="异步IO -AIO"></a>异步IO -AIO</h3><blockquote><p>Asynchronous IO，要注意都是 异步IO并不会顺序执行。</p></blockquote><p>用户进程发起<code>aio_read</code>操作之后，kernel会立刻返回，所以不会对用户进程产生任何block。</p><p>然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，拷贝完成后，kernel会给用户进程发送一个<code>signal</code>或<code>执行一个基于线程的回调函数</code>来完成这次 IO 处理过程，以通知用户进程 <code>IO操作完成了</code>。</p><blockquote><p>如果 kernel 发送<code>signal</code>给用户进程时，</p><ul><li><p>用户进程正在执行任务，就会打断用户进程，调用事先注册的<code>信号处理函数</code>(跟中断处理程序一样)，这个函数可以决定何时以及如何处理这个异步任务；</p><blockquote><p>一般是把事件 “登记” 一下放进队列，然后返回该进程原来在做的事。</p></blockquote></li><li><p>如果用户进程调用内核态函数并阻塞（例如以同步阻塞方式读写磁盘），那就把这个通知挂起，等到它快要回到用户态的时候，再触发信号通知；</p></li><li><p>如果用户进程是 被挂起 / sleep 的，就唤醒它，等他被调度拿到CPU，就会处理信号通知。</p></li></ul></blockquote><ul><li>内核实现比较难</li></ul><h5 id="异步阻塞模型"><a href="#异步阻塞模型" class="headerlink" title="异步阻塞模型"></a>异步阻塞模型</h5><p>异步但是需要顺序调用几个IO操作的时候，就需要用异步阻塞方式，一般都是<code>实时系统</code>或者<code>延迟敏感的事务</code>。</p><h3 id="信号驱动IO"><a href="#信号驱动IO" class="headerlink" title="信号驱动IO"></a>信号驱动IO</h3><blockquote><p>signal-driven I/O</p></blockquote><ol><li>用户进程调用系统函数，系统函数直接返回；</li><li>内核在数据拷贝到用户空间之后，向用户进程发送信号；</li><li>用户进程收到信号之后调用<code>recvfrom</code>（阻塞）（由内核）将数据从内核空间复制到用户空间。</li></ol><blockquote><p>和IO多路复用也很类似，不过IO多路复用可以处理多个fd，而且IO多路复用的第一步也是阻塞的（看最上方的图）。</p></blockquote><p>异步IO和信号驱动IO的区别</p><blockquote><p>异步 I/O 的信号是<strong>通知应用进程 I/O 完成</strong>，而信号驱动 I/O 的信号是<strong>通知应用进程可以开始 I/O</strong></p></blockquote><hr><h1 id="select-poll-epoll"><a href="#select-poll-epoll" class="headerlink" title="select/poll/epoll"></a>select/poll/epoll</h1><p>Linux中IO多路复用的实现</p><h4 id="select"><a href="#select" class="headerlink" title="select"></a>select</h4><p><code>select</code>是<code>POSIX</code>规定的，一般操作系统都有实现。</p><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;winsock.h&gt;</span></span><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> __FD_SETSIZE    1024</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">select</span><span class="hljs-params">(</span></span><span class="hljs-function"><span class="hljs-params">    <span class="hljs-keyword">int</span> nfds, <span class="hljs-comment">// 本参数忽略，仅起到兼容作用</span></span></span><span class="hljs-function"><span class="hljs-params">    fd_set* readfds, <span class="hljs-comment">// （可选）指针，指向一组等待可读性检查的套接口fd</span></span></span><span class="hljs-function"><span class="hljs-params">    fd_set* writefds, <span class="hljs-comment">// （可选）指针，指向一组等待可写性检查的套接口fd</span></span></span><span class="hljs-function"><span class="hljs-params">    fd_set* exceptfds, <span class="hljs-comment">// （可选）指针，指向一组等待错误检查的套接口fd</span></span></span><span class="hljs-function"><span class="hljs-params">    <span class="hljs-keyword">const</span> struct timeval* timeout <span class="hljs-comment">// timeout：select()最多等待时间，对阻塞操作则应为NULL。</span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span>;</code></pre><p>select是通过维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递这些fd时复制开销也随着fd的数量线性增大。也因此单个进程所打开的fd是有一定限制的，它由<code>FD_SETSIZE</code>设置，默认值是<code>1024</code>。</p><blockquote><p>一般来说这个数目和系统内存关系很大，具体数目可以<code>cat /proc/sys/fs/file-max</code>查看。32位机默认是1024个；64位机默认是2048。</p></blockquote><p>而且select对fd进行的是线性扫描，即轮询，效率较低。</p><blockquote><p>当套接字比较多的时候，每次select()都要遍历<code>fd_setsize</code>个fd来完成调度，不管其中fd是否活跃，都遍历一遍。</p><p>这会浪费很多CPU时间。<code>如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询</code>，这正是epoll与kqueue做的优化。</p></blockquote><h5 id="使用select"><a href="#使用select" class="headerlink" title="使用select"></a>使用select</h5><pre><code class="hljs c"><span class="hljs-keyword">while</span> <span class="hljs-literal">true</span> &#123;<span class="hljs-comment">// 循环</span>    fd_set* readfds;    fd_set* writefds;    fd_set* exceptfds;    select(.. readfds, writefds, exceptfds, ...) <span class="hljs-comment">// 这里如果没有就绪的时间就阻塞</span>    <span class="hljs-keyword">for</span> ready_fd in readfds &#123;        <span class="hljs-keyword">if</span> read_fd has data            <span class="hljs-comment">// 这里处理fd的时候还要注意 是不是已经处理过了 如果read()可能会一直阻塞下去，因为可能已经被其他人处理</span>            read(read_fd, timeout) until unavailable    &#125;&#125;</code></pre><h4 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h4><p>和select不同的是存储fd_set使用的链表，理论上没有最大连接数限制，fd_set被整体复制，同样的浪费空间；</p><p>poll是<code>水平触发</code>如果本次报告了fd可用，如果用户进程没有处理，下次还会报告这个fd。</p><h4 id="select-和-poll-的弱点"><a href="#select-和-poll-的弱点" class="headerlink" title="select 和 poll 的弱点"></a>select 和 poll 的弱点</h4><p>都要传入fd数组，内核遍历数组把所有就绪的fd标记为已就绪，然后用户进程再遍历fd数组找到已就绪的fd进行处理。一般同一时间内要处理的fd只有少部分处于就绪状态。如果监控的fd越来越多，性能会线性下降。</p><h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a><strong>epoll</strong></h4><p>epoll 是Linux2.6新增的优化版本，epoll 使用<code>一个fd</code>管理多个fd，将<code>用户进程关注的fd的事件</code>存放到内核的一个<code>事件表</code>中。</p><p>epoll的接口非常简单，一共就三个函数：</p><h6 id="epoll-create-int-size"><a href="#epoll-create-int-size" class="headerlink" title="epoll_create(int size)"></a>epoll_create(int size)</h6><p>创建一个epoll文件描述符 来监听多个fd</p><blockquote><pre><code class="hljs mipsasm">epoll_create() creates a new epoll(<span class="hljs-number">7</span>) <span class="hljs-keyword">instance. </span> Since Linux<span class="hljs-number">2</span>.<span class="hljs-number">6</span>.<span class="hljs-number">8</span>, the size argument is ignored, <span class="hljs-keyword">but </span>must <span class="hljs-keyword">be </span>greater than<span class="hljs-built_in">zero</span><span class="hljs-comment">; see NOTES.</span></code></pre><p>参数size在2.6.8之后已经没什么用了，这个fd的size是内核动态调整的。不过参数size必须&gt;0。</p><p><a href="https://man7.org/linux/man-pages/man2/epoll_create.2.html">https://man7.org/linux/man-pages/man2/epoll_create.2.html</a></p><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">epoll_create</span><span class="hljs-params">(<span class="hljs-keyword">int</span> size)</span></span>;SYSCALL_DEFINE1(epoll_create, <span class="hljs-keyword">int</span>, size)&#123;    <span class="hljs-keyword">if</span> (size &lt;= <span class="hljs-number">0</span>)        <span class="hljs-keyword">return</span> -EINVAL;    <span class="hljs-keyword">return</span> sys_epoll_create1(<span class="hljs-number">0</span>);&#125;<span class="hljs-comment">/*</span><span class="hljs-comment"> * Open an eventpoll file descriptor.</span><span class="hljs-comment"> * 打开一个时间循环文件描述符</span><span class="hljs-comment"> */</span>SYSCALL_DEFINE1(epoll_create1, <span class="hljs-keyword">int</span>, flags)&#123;    <span class="hljs-keyword">int</span> error, fd;    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">eventpoll</span> *<span class="hljs-title">ep</span> =</span> <span class="hljs-literal">NULL</span>;    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">file</span> *<span class="hljs-title">file</span>;</span>    <span class="hljs-comment">/* Check the EPOLL_* constant for consistency.  */</span>    BUILD_BUG_ON(EPOLL_CLOEXEC != O_CLOEXEC);    <span class="hljs-keyword">if</span> (flags &amp; ~EPOLL_CLOEXEC)        <span class="hljs-keyword">return</span> -EINVAL;    <span class="hljs-comment">/*</span><span class="hljs-comment">     * Create the internal data structure (&quot;struct eventpoll&quot;). 内部数据结构</span><span class="hljs-comment">     */</span>    error = ep_alloc(&amp;ep);    <span class="hljs-keyword">if</span> (error &lt; <span class="hljs-number">0</span>)        <span class="hljs-keyword">return</span> error;    <span class="hljs-comment">/*</span><span class="hljs-comment">     * Creates all the items needed to setup an eventpoll file. That is,</span><span class="hljs-comment">     * a file structure and a free file descriptor.</span><span class="hljs-comment">     * 创建描述（监听的fd的时间轮询）的文件描述符</span><span class="hljs-comment">     */</span>    fd = get_unused_fd_flags(O_RDWR | (flags &amp; O_CLOEXEC));    <span class="hljs-keyword">if</span> (fd &lt; <span class="hljs-number">0</span>) &#123;        error = fd;        <span class="hljs-keyword">goto</span> out_free_ep;    &#125;    file = anon_inode_getfile(<span class="hljs-string">&quot;[eventpoll]&quot;</span>, &amp;eventpoll_fops, ep,                 O_RDWR | (flags &amp; O_CLOEXEC));    <span class="hljs-keyword">if</span> (IS_ERR(file)) &#123;        error = PTR_ERR(file);        <span class="hljs-keyword">goto</span> out_free_fd;    &#125;    ep-&gt;file = file;    fd_install(fd, file);    <span class="hljs-keyword">return</span> fd;out_free_fd:    put_unused_fd(fd);out_free_ep:    ep_free(ep);    <span class="hljs-keyword">return</span> error;&#125;</code></pre></blockquote><h6 id="epoll-ctl-…"><a href="#epoll-ctl-…" class="headerlink" title="epoll_ctl(…)"></a>epoll_ctl(…)</h6><p>epoll_ctl()用于向epoll注册事件，而且明确监听的事件类型</p><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">epoll_ctl</span><span class="hljs-params">(<span class="hljs-keyword">int</span> epfd, <span class="hljs-keyword">int</span> op, <span class="hljs-keyword">int</span> fd, struct epoll_event *event)</span></span>;<span class="hljs-comment">// epfd: 返回值（epoll文件描述符）</span><span class="hljs-comment">// op: 动作：有三个宏（类似enum）可选：EPOLL_CTL_ADD,EPOLL_CTL_MOD,EPOLL_CTL_DEL</span><span class="hljs-comment">// fd: 要监听的fd</span><span class="hljs-comment">// *event: 要监听的事件</span></code></pre><p>事件的数据结构</p><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">union</span> <span class="hljs-title">epoll_data</span> &#123;</span>    <span class="hljs-keyword">void</span> *ptr;    <span class="hljs-keyword">int</span> fd;<span class="hljs-comment">// 事件对应的文件描述符</span>    <span class="hljs-keyword">__uint32_t</span> u32;    <span class="hljs-keyword">__uint64_t</span> u64;&#125; <span class="hljs-keyword">epoll_data_t</span>;<span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">epoll_event</span> &#123;</span>    <span class="hljs-keyword">__uint32_t</span> events; <span class="hljs-comment">/* Epoll events */</span>    <span class="hljs-keyword">epoll_data_t</span> data; <span class="hljs-comment">/* User data variable */</span>&#125;;</code></pre><blockquote><ol><li><p>参数 <strong>op</strong> 可选的三个宏：增（EPOLL_CTL_<strong>ADD</strong>），改（EPOLL_CTL_<strong>MOD</strong>），删（EPOLL_CTL_<strong>DEL</strong>）</p></li><li><p>参数 *<strong>event</strong> 有如下选择</p><table><thead><tr><th>event</th><th>描述</th></tr></thead><tbody><tr><td>EPOLLIN</td><td>in,对应的文件描述符<strong>可读</strong>（包括对端 SOCKET 正常关闭）</td></tr><tr><td>EPOLLOUT</td><td>out,对应的文件描述符<strong>可写</strong></td></tr><tr><td>EPOLLPRI</td><td>pri,对应的文件描述符<strong>有紧急的数据可读</strong>（这里应该表示有带外数据到来）</td></tr><tr><td>EPOLLERR</td><td>err,对应的文件描述符<strong>发生错误</strong></td></tr><tr><td>EPOLLHUP</td><td>hup,对应的文件描述符<strong>被挂断</strong></td></tr><tr><td>EPOLLET</td><td>et,将epoll从 水平触发 <strong>LT</strong>(Level Triggered) <strong>设为</strong> 边缘触发 <strong>ET</strong>(Edge Triggered) 模式</td></tr><tr><td>EPOLLONESHOT</td><td>oneshot,只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到epoll队列里</td></tr></tbody></table></li></ol></blockquote><h6 id="epoll-wait-…timeout…"><a href="#epoll-wait-…timeout…" class="headerlink" title="epoll_wait(…timeout…)"></a>epoll_wait(…timeout…)</h6><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">epoll_wait</span><span class="hljs-params">(<span class="hljs-keyword">int</span> epfd, struct epoll_event *events, <span class="hljs-keyword">int</span> maxevents, <span class="hljs-keyword">int</span> timeout)</span></span>;<span class="hljs-comment">// epfd： 方法返回值</span><span class="hljs-comment">// *events： 调用者自己开辟一块事件数组，用于存储就绪的事件</span><span class="hljs-comment">// maxevents： *events size的最大值</span><span class="hljs-comment">// timeout： 等待超时时间（0 表示立即返回;-1 表示永久阻塞,直到有就绪事件）</span></code></pre><h5 id="使用epoll"><a href="#使用epoll" class="headerlink" title="使用epoll"></a>使用epoll</h5><ul><li>调用 create 创建 epoll 描述符（即下文代码中的 epfd 变量）</li><li>调用 ctl： 添加关注的事件</li><li>循环调用wait</li></ul><pre><code class="hljs c"><span class="hljs-comment">// --------------------------- 大致代码框架：</span><span class="hljs-keyword">while</span> <span class="hljs-literal">true</span> &#123;    active_fd[] = epoll_wait(epollfd) <span class="hljs-comment">// 阻塞 直到有事件就绪(epoll_wait只返回已经就绪的事件)</span>    <span class="hljs-keyword">for</span> i in active_fd[] &#123; <span class="hljs-comment">// 遍历所有已就绪的fd</span>        read <span class="hljs-keyword">or</span> write till unavailable <span class="hljs-comment">// 处理对应的事件</span>    &#125;&#125;<span class="hljs-comment">// --------------------------- 具体代码：网上找的一个socket使用epoll的例子</span>epfd = epoll_create(<span class="hljs-number">1</span>);epoll_ctl(epfd, EPPOLL_CTL_ADD, ...);<span class="hljs-keyword">for</span>( ; ; )&#123;    nfds = epoll_wait(epfd,events,<span class="hljs-number">20</span>,<span class="hljs-number">500</span>);<span class="hljs-comment">// 调用epoll_wait,获取有事件发生的fd</span>    <span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; nfds; ++i)    &#123;        <span class="hljs-keyword">if</span>(events[i].data.fd==listenfd) <span class="hljs-comment">//如果是主socket的事件，则表示有新的连接</span>        &#123;            connfd = accept(listenfd,(sockaddr *)&amp;clientaddr, &amp;clilen); <span class="hljs-comment">//accept这个连接</span>            ev.data.fd=connfd;            ev.events=EPOLLIN|EPOLLET;            epoll_ctl(epfd,EPOLL_CTL_ADD,connfd,&amp;ev); <span class="hljs-comment">//将新的fd添加到epoll的监听队列中</span>        &#125;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>( events[i].events&amp;EPOLLIN ) <span class="hljs-comment">//接收到数据，读socket</span>        &#123;            <span class="hljs-keyword">if</span> ( (sockfd = events[i].data.fd) &lt; <span class="hljs-number">0</span>) <span class="hljs-keyword">continue</span>;            n = read(sockfd, line, MAXLINE)) &lt; <span class="hljs-number">0</span>    <span class="hljs-comment">//读</span>                ev.data.ptr = md;     <span class="hljs-comment">//md为自定义类型，添加数据</span>            ev.events=EPOLLOUT|EPOLLET;            epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&amp;ev);<span class="hljs-comment">//修改标识符，等待下一个循环时发送数据，异步处理的精髓</span>        &#125;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(events[i].events&amp;EPOLLOUT) <span class="hljs-comment">//有数据待发送，写socket</span>        &#123;            struct myepoll_data* md = (myepoll_data*)events[i].data.ptr;    <span class="hljs-comment">//取数据</span>            sockfd = md-&gt;fd;            send( sockfd, md-&gt;ptr, <span class="hljs-built_in">strlen</span>((<span class="hljs-keyword">char</span>*)md-&gt;ptr), <span class="hljs-number">0</span> );        <span class="hljs-comment">//发送数据</span>            ev.data.fd=sockfd;            ev.events=EPOLLIN|EPOLLET;            epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&amp;ev); <span class="hljs-comment">//修改标识符，等待下一个循环时接收数据</span>        &#125;        <span class="hljs-keyword">else</span>        &#123;            <span class="hljs-comment">//其他情况的处理</span>        &#125;    &#125;&#125;</code></pre><h5 id="epoll-实现原理"><a href="#epoll-实现原理" class="headerlink" title="epoll 实现原理"></a>epoll 实现原理</h5><blockquote><p>在linux，一切皆文件．</p><p>当调用 <strong>epoll_create</strong> 时，内核给这个 epoll 分配一个特殊的只服务于 epoll 的 file（epoll文件描述符-<strong>epfd</strong>），<strong>epfd</strong> 用来存储用户进程关注的fd(epoll_ctl的参数 int fd，比如<strong>socket</strong>）；</p><p>所以当内核初始化 epoll 时，会开辟一块<strong>内核高速cache区</strong>，用于存放 <strong>epfd</strong>，用户进程关注的fd会以<strong>红黑树</strong>的形式保存在内核的cache(<strong>epfd</strong>)里，同时建立一个<strong>list链表，用于存储准备就绪的事件</strong>。</p><p>执行<strong>epoll_ctl</strong>时，把<strong>socket</strong>放到<strong>epfd</strong>的红黑树上，并<strong>给内核中断处理程序注册一个回调函数</strong>；</p><p>当<strong>socket</strong>上有数据到了，就会触发中断，内核在把网卡上的数据copy到内核中后就会调用该回调函数，把socket插入到<strong>准备就绪链表</strong>里。</p><p>所以调用<strong>epoll_wait</strong>时，只要在timeout时间内，这个list链表有数据则拷贝至用户空间的events数组(参数*<strong>event</strong>)中。</p></blockquote><h4 id="epoll的两种模式"><a href="#epoll的两种模式" class="headerlink" title="epoll的两种模式"></a>epoll的两种模式</h4><p>水平触发(<strong>LT</strong> level trigger) 和 边缘触发 (<strong>ET</strong> edge trigger)。</p><blockquote><p>LT（<strong>默认</strong>）：用户进程<strong>可以不立即处理</strong> epoll_wait 返回的事件，下次调用epoll_wait时，<strong>会再次</strong>响应应用程序并<strong>通知此事件</strong>。</p><blockquote><p>同时支持 <code>block socket</code> 和 <code>no-block socket</code></p></blockquote><p>ET：用户进程<strong>必须立即处理</strong> epoll_wait 返回的事件，如果不处理，下次调用 epoll_wait 时，epoll <strong>不会再次</strong>响应应用程序并<strong>通知此事件</strong>。</p><blockquote><p>只支持非阻塞套接口 <code>no-block socket</code></p></blockquote><p>一个常见问题：谁效率高。。</p><blockquote><p>ET模式减少了fd事件被重复触发的次数，所以只针对这一次epoll调用来说，ET模式<strong>效率更高</strong>。</p><p>但是在ET模式下，为了保证数据都会处理，用户态必须用一个循环，将所有的数据一次性处理结束。所以用户态的逻辑复杂了，write/read 调用增多了，可能性能并不会更高。</p></blockquote></blockquote><h4 id="epoll-和-select-poll-的区别-优化"><a href="#epoll-和-select-poll-的区别-优化" class="headerlink" title="epoll 和 select/poll 的区别/优化"></a>epoll 和 select/poll 的区别/优化</h4><ol><li>epoll 没有fd数量限制，上限是最大可以打开文件的数目，一般远大于2048，1G内存的机器上是大约10万左右；</li><li>epoll 只需在用户空间和内核空间copy一个fd——<strong>epfd</strong>，而且 epfd 占用空间小，使用了CPU高级缓存；</li><li>epoll 只返回已就绪的fd，select / poll 都是返回用户进程关注的全部fd；</li></ol><h1 id="常见问题-amp-拓展"><a href="#常见问题-amp-拓展" class="headerlink" title="常见问题 &amp; 拓展"></a>常见问题 &amp; 拓展</h1><p>Redis 和 Memcache 都是使用了基于IO多路复用的高性能网络库。</p><h2 id="Linux-IO多路复用-使用了mmap？"><a href="#Linux-IO多路复用-使用了mmap？" class="headerlink" title="Linux IO多路复用 使用了mmap？"></a>Linux IO多路复用 使用了mmap？</h2><p>select/poll/epoll 中均并没发现用mmap的痕迹啊，而且我觉得…本身就是在内核空间直接操作文件了，还用啥mmap啊…</p><h2 id="IO多路复用-第二步读取-推荐用非阻塞函数"><a href="#IO多路复用-第二步读取-推荐用非阻塞函数" class="headerlink" title="IO多路复用 第二步读取 推荐用非阻塞函数"></a>IO多路复用 第二步读取 推荐用非阻塞函数</h2><p>问题  <a href="https://www.zhihu.com/question/37271342">https://www.zhihu.com/question/37271342</a></p><blockquote><p>假如我调用了一个 select 函数，并且关注了几个fd， select 函数就会一直阻塞直到我关注的事件发生. 假如当有套接口可读时， select 函数就返回了，告诉我们套接口已经可读，接下来（<strong>IO Multiplexing的第二步系统调用</strong>）客户端进程可以用 <strong>阻塞的read</strong> 或者 <strong>非阻塞的 read</strong>：</p><blockquote><p>阻塞 read 是无数据可读就阻塞进程；</p><p>非阻塞 read是无数据可读就返回一个 EWOULDBLOCK 错误。</p></blockquote><p>那么问题来了：既然 select 都返回可读了，那就表示一定能读了，阻塞函数read也就能读取了也就不会阻塞了，非阻塞read的话，也有数据读了，也不会返回错误了，那么这俩不都一样了？一样直接读取数据知道读完，为什么还得用非阻塞函数？还有 Reactor 模式也是用的 IO 多路复用与非阻塞 IO，这是什么道理呢？</p></blockquote><p>答案</p><blockquote><ol><li><blockquote><p>Under Linux, select() may report a socket file descriptor as “ready for reading”, while nevertheless a subsequent read blocks.  This could for example happen when data has arrived but upon examination has wrong checksum and is discarded.  There may be other circumstances in which a file descriptor is spuriously reported  as ready.  Thus it  may be safer to use O_NONBLOCK on sockets that should not block.</p><p>链接：<a href="https://www.zhihu.com/question/37271342/answer/81808421">https://www.zhihu.com/question/37271342/answer/81808421</a></p></blockquote><p>Linux环境下, select()可能收到socket fd回复的“读就绪”, 紧接着read()会阻塞。这可能因为数据准备完成之后发生了错误被丢弃了。 其他情况下fd可能被错误地报告为“读就绪”。所以在不该阻塞的IO操作中 还是用非阻塞比较安全。</p></li><li><p>select()返回可读之后就直接去read()并不一定能读取到数据，select()内部调用fd是否就绪 和 调用read() 是两次系统调用，这之间是可能有其他事件发生的，</p><p>举个例子： 惊群现象，投一粒米，所有鸽子都来吃，只有一个吃到，然后所有鸽子都得回去睡觉。</p><p>这个可读的数据可能就是已经被其他进程/线程读完了。</p><p>链接：<a href="https://www.zhihu.com/question/37271342/answer/81757593">https://www.zhihu.com/question/37271342/answer/81757593</a></p></li></ol></blockquote><h2 id="Java中的NIO"><a href="#Java中的NIO" class="headerlink" title="Java中的NIO"></a><a href="#https://melopoz.github.io/blog/2021/01/01/Java_IO/#NIO">Java中的NIO</a></h2>]]></content>
    
    
    <categories>
      
      <category>IO</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IO多路复用</tag>
      
      <tag>select</tag>
      
      <tag>poll</tag>
      
      <tag>epoll</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
